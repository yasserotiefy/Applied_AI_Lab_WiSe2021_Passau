{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASY11viGC-CR"
   },
   "source": [
    "### Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update\n",
    "# !apt install nvidia-cuda-toolkit -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 113094,
     "status": "ok",
     "timestamp": 1636221066554,
     "user": {
      "displayName": "Yasser Otiefy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64",
      "userId": "11606645386995589698"
     },
     "user_tz": -60
    },
    "id": "AQD3X56MDC41",
    "outputId": "98a56160-961f-40f1-c157-9853b2ad57b8"
   },
   "outputs": [],
   "source": [
    "# !pip install swifter pandas numpy\n",
    "# !pip uninstall -y tensorflow-gpu keras keras-transformer keras_bert\n",
    "# !pip install tensorflow-gpu==1.14.0 keras==2.2.4 keras-transformer==0.33.0 keras_bert==0.78.0 \n",
    "# !pip install tensorflow-gpu keras keras-transformer keras_bert tensorflow-ranking\n",
    "# !pip install pydot pydotplus\n",
    "# !pip install h5py==2.10.0 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install graphviz -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8GPhl_YBO9X"
   },
   "source": [
    "### Download required embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpdWSjMNR18V"
   },
   "outputs": [],
   "source": [
    "# !wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip data/\n",
    "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip data/\n",
    "# !wget https://nlp.stanford.edu/data/glove.840B.300d.zip data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wI8SduklTKXO"
   },
   "outputs": [],
   "source": [
    "# !unzip data/uncased_L-12_H-768_A-12.zip \n",
    "# !unzip data/crawl-300d-2M.vec.zip\n",
    "# !unzip data/glove.840B.300d.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vp6skypuClUf"
   },
   "source": [
    "### Run Preprocessing File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnDeHDjqCqPX"
   },
   "outputs": [],
   "source": [
    "# !python preprocess.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh7BB7hTBKOs"
   },
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1636209799226,
     "user": {
      "displayName": "Yasser Otiefy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64",
      "userId": "11606645386995589698"
     },
     "user_tz": -60
    },
    "id": "qtsQ8SovAr4v",
    "outputId": "cec16143-f0a5-4dc7-b4e6-85204f1e9bfb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 20:45:42.209545: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-27 20:45:43.400448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8887 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:86:00.0, compute capability: 3.7\n",
      "2021-12-27 20:45:43.401946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10248 MB memory:  -> device: 1, name: Tesla K80, pci bus id: 0000:87:00.0, compute capability: 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_280793/3759682703.py:49: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import choice, seed, shuffle, random, sample\n",
    "import tensorflow as tf\n",
    "# import tensorflow.co as KTF\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, CuDNNGRU as GRU, CuDNNLSTM as LSTM, Dropout, BatchNormalization\n",
    "from keras.layers import Dense, Concatenate, Activation, Embedding, SpatialDropout1D, Bidirectional, Lambda, Conv1D\n",
    "from keras.layers import Add, Average, TimeDistributed, GlobalMaxPooling1D\n",
    "from tensorflow.compat.v1.keras.optimizers import Adam, Nadam\n",
    "# from keras.activations import absolute_import\n",
    "# from keras.legacy import interfaces\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import Callback\n",
    "# from keras.utils import to_categorical\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "# from sklearn.model_selection import KFold\n",
    "# from keras.initializers import he_normal\n",
    "# from keras_bert.bert import get_model\n",
    "from keras_bert.loader import load_trained_model_from_checkpoint\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "# from keras.engine import Layer\n",
    "# from keras.engine import InputSpec\n",
    "# from keras.objectives import categorical_crossentropy\n",
    "# from keras.objectives import sparse_categorical_crossentropy\n",
    "from keras import activations, initializers, regularizers, constraints\n",
    "from keras.models import Model\n",
    "# from tqdm import tqdm\n",
    "# from model_utils import seq_gather, seq_and_vec, seq_maxpool\n",
    "from keras.models import load_model\n",
    "from keras_bert import get_custom_objects\n",
    "from keras_bert import Tokenizer\n",
    "from collections import defaultdict\n",
    "from eval import read_submission, get_ndcg\n",
    "from tqdm import tqdm, trange\n",
    "import pickle\n",
    "import dask.dataframe as dd\n",
    "# import joblib\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# print(gpus)\n",
    "# mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "BERT_PRETRAINED_DIR = \"/root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/uncased_L-12_H-768_A-12\"\n",
    "VAL_ANS_PATH = '/root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/valid_answer.json'\n",
    "LABEL_PATH = '/root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/multimodal_labels.txt'\n",
    "\n",
    "MAX_EPOCH = 20\n",
    "MAX_LEN = 10\n",
    "B_SIZE = 256\n",
    "FOLD_IDS = [-1]\n",
    "FOLD_NUM = 20\n",
    "THRE = 0.5\n",
    "SHUFFLE = True\n",
    "MAX_BOX = 5\n",
    "MAX_CHAR = 5\n",
    "PREFIX = \"[image-bert-concat-query]-wwm_uncased_L12-768_v3_1M_example\"\n",
    "SEED = 2021\n",
    "ACCUM_STEP = int(128 // B_SIZE)\n",
    "SAVE_EPOCHS=[10, 20, 35, 50, 80, 100]\n",
    "IMAGE_LABEM_CONCAT_TOKEN = \"###\"\n",
    "CONCAT_TOKE = \"[unused0]\"\n",
    "\n",
    "cfg = {}\n",
    "cfg[\"verbose\"] = PREFIX\n",
    "cfg[\"base_dir\"] = BERT_PRETRAINED_DIR\n",
    "cfg['maxlen'] = MAX_LEN\n",
    "cfg[\"max_box\"] = MAX_BOX\n",
    "cfg[\"max_char\"] = MAX_CHAR\n",
    "cfg[\"lr\"] = 1e-4\n",
    "cfg['min_lr'] = 6e-8\n",
    "cfg[\"opt\"] = \"nadam\"\n",
    "cfg[\"loss_w\"] =  20.\n",
    "cfg[\"trainable\"] = True\n",
    "cfg[\"bert_trainable\"] = True\n",
    "cfg[\"mix_mode\"] = \"\"   # add concat average\n",
    "cfg[\"unit1_1\"] = 128\n",
    "cfg[\"accum_step\"] = ACCUM_STEP\n",
    "cfg[\"cls_num\"] = 2\n",
    "cfg[\"raw_filename\"] = \"{}_{}oof{}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rqxc8sS8Ar43"
   },
   "outputs": [],
   "source": [
    "def get_vocab():\n",
    "    \n",
    "    if \"albert\"in cfg[\"verbose\"].lower():\n",
    "        dict_path = os.path.join(BERT_PRETRAINED_DIR, 'vocab_chinese.txt')\n",
    "    else:\n",
    "        dict_path = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
    "    with open(dict_path, mode=\"r\", encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [l.strip() for l in lines]\n",
    "\n",
    "    word_index = {v: k  for k, v in enumerate(lines)}\n",
    "    return word_index\n",
    "\n",
    "\n",
    "word_index = get_vocab()\n",
    "cfg[\"x_pad\"] = word_index[\"[PAD]\"]\n",
    "tokenizer = Tokenizer(word_index)\n",
    "\n",
    "\n",
    "def get_label(path):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        label2id = {l.split('\\n')[0].split('\\t')[1]:int(l.split('\\n')[0].split('\\t')[0]) for l in lines[1:]}\n",
    "        id2label = {int(l.split('\\n')[0].split('\\t')[0]):l.split('\\n')[0].split('\\t')[1] for l in lines[1:]}\n",
    "    return label2id, id2label\n",
    "\n",
    "\n",
    "label2id, id2label = get_label(LABEL_PATH)\n",
    "label_set = set(label2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# 全量数据\n",
    "# with open('../data/train_data.pkl', 'rb') as outp:\n",
    "#     train_data= joblib.load(outp)\n",
    "# 100K sample\n",
    "with open('data/sample_train_data.pkl', 'rb') as outp:\n",
    "    train_data = joblib.load(outp)\n",
    "\n",
    "\n",
    "with open('data/val_data.pkl', 'rb') as outp:\n",
    "    val_data = pickle.load(outp)\n",
    "    \n",
    "# print(len(train_data), type(train_data))\n",
    "# train_data.reset_index(drop=True, inplace=True)\n",
    "# train_data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pMZVTqarAr46"
   },
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype=np.float16)\n",
    "\n",
    "\n",
    "def load_embed(path, dim=300, word_index=None):\n",
    "    embedding_index = {}\n",
    "    with open(path, mode=\"r\", encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            l = l.strip().split()\n",
    "            word, arr = l[0], l[1:]\n",
    "            if len(arr) != dim:\n",
    "                print(\"[!] l = {}\".format(l))\n",
    "                continue\n",
    "            if word_index and word not in word_index:\n",
    "                continue\n",
    "            word, arr = get_coefs(word, arr)\n",
    "            embedding_index[word] = arr\n",
    "    return embedding_index\n",
    "\n",
    "\n",
    "def build_matrix(path, word_index=None, max_features=None, dim=300):\n",
    "    embedding_index = load_embed(path, dim=dim, word_index=word_index)\n",
    "    max_features = len(word_index) + 1 if max_features is None else max_features \n",
    "    embedding_matrix = np.zeros((max_features + 1, dim))\n",
    "    unknown_words = []\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i <= max_features:\n",
    "            try:\n",
    "                embedding_matrix[i] = embedding_index[word]\n",
    "            except KeyError:\n",
    "                unknown_words.append(word)\n",
    "    return embedding_matrix, unknown_words\n",
    "\n",
    "\n",
    "def load_word_embed(word_embed_glove=\"data/glove.840B.300d.txt\", \n",
    "                    word_embed_crawl=\"data/crawl-300d-2M.vec\",\n",
    "               save_filename=\"word_embedding_matrix\",\n",
    "               word_index=None):\n",
    "    \"\"\"\n",
    "    (30524, 300) 7590\n",
    "    (30524, 300) 7218\n",
    "    \"\"\"    \n",
    "    if os.path.exists(save_filename + \".npy\"):\n",
    "        word_embedding_matrix = np.load(save_filename + \".npy\").astype(\"float32\")\n",
    "    else:\n",
    "        word_embedding_matrix, tx_unk = build_matrix(word_embed_glove, word_index=word_index, dim=300)\n",
    "\n",
    "        # print(word_embedding_matrix.shape, len(tx_unk))\n",
    "        \n",
    "        word_embedding_matrix_v2, tx_unk = build_matrix(word_embed_crawl, word_index=word_index, dim=300)\n",
    "\n",
    "        # print(word_embedding_matrix_v2.shape, len(tx_unk))\n",
    "        \n",
    "        word_embedding_matrix = np.concatenate([word_embedding_matrix, word_embedding_matrix_v2], axis=1)\n",
    "        \n",
    "        gc.collect()\n",
    "        np.save(save_filename, word_embedding_matrix)\n",
    "    return word_embedding_matrix\n",
    "\n",
    "\n",
    "word_embedding_matrix = load_word_embed(word_index=word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tHoD4ogMAr47"
   },
   "outputs": [],
   "source": [
    "def build_model(cfg, summary=False, word_embedding_matrix=None):\n",
    "    \n",
    "    def _get_model(base_dir, cfg_=None):\n",
    "        config_file = os.path.join(base_dir, 'bert_config.json')\n",
    "        checkpoint_file = os.path.join(base_dir, 'bert_model.ckpt')\n",
    "        if not os.path.exists(config_file):\n",
    "            config_file = os.path.join(base_dir, 'bert_config_large.json')\n",
    "            checkpoint_file = os.path.join(base_dir, 'roberta_l24_large_model')\n",
    "        print(config_file, checkpoint_file)\n",
    "#         model = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True, seq_len=cfg_['maxlen'])\n",
    "        model = load_trained_model_from_checkpoint(config_file, \n",
    "                                           checkpoint_file, \n",
    "                                           training=False, \n",
    "                                           trainable=cfg_[\"bert_trainable\"], \n",
    "                                           output_layer_num=cfg[\"cls_num\"],\n",
    "                                           seq_len=None)\n",
    "        return model\n",
    "    \n",
    "    def get_opt(num_example, warmup_proportion=0.1, lr=2e-5, min_lr=None):\n",
    "        if cfg[\"opt\"].lower() == \"nadam\":\n",
    "            opt = Nadam(lr=lr)\n",
    "        else:\n",
    "            total_steps, warmup_steps = calc_train_steps(\n",
    "                num_example=num_example,\n",
    "                batch_size=B_SIZE,\n",
    "                epochs=MAX_EPOCH,\n",
    "                warmup_proportion=warmup_proportion,\n",
    "            )\n",
    "\n",
    "            opt = AdamWarmup(total_steps, warmup_steps, lr=lr, min_lr=min_lr)\n",
    "\n",
    "        return opt\n",
    "\n",
    "    model1 = _get_model(cfg[\"base_dir\"], cfg)\n",
    "    model1 = Model(inputs=model1.inputs[: 2], outputs=model1.layers[-7].output)\n",
    "\n",
    "    if word_embedding_matrix is not None:\n",
    "        embed_layer = Embedding(input_dim=word_embedding_matrix.shape[0], \n",
    "                                output_dim=word_embedding_matrix.shape[1],\n",
    "                                weights=[word_embedding_matrix],\n",
    "                                trainable=cfg[\"trainable\"],\n",
    "                                name=\"embed_layer\"\n",
    "                         )\n",
    "        \n",
    "    inp_token1 = Input(shape=(None, ), dtype=np.int32, name=\"query_token_input\")\n",
    "    inp_segm1 = Input(shape=(None, ), dtype=np.float32, name=\"query_segm_input\")\n",
    "    \n",
    "#     inp_token2 = Input(shape=(None, ), dtype=np.int32)\n",
    "#     inp_segm2 = Input(shape=(None, ), dtype=np.float32)    \n",
    "    \n",
    "    inp_image = Input(shape=(None, 2048), dtype=np.float32, name=\"image_input\")\n",
    "    inp_image_mask = Input(shape=(None, ), dtype=np.float32, name=\"image_mask_input\")\n",
    "    inp_pos = Input(shape=(None, 5), dtype=np.float32, name=\"image_pos_input\")        \n",
    "    inp_image_char = Input(shape=(None, cfg[\"max_char\"]), dtype=np.int32, name='image_char_input')\n",
    "    \n",
    "    \n",
    "    mask = Lambda(lambda x: K.cast(K.not_equal(x, cfg[\"x_pad\"]), 'float32'), name=\"token_mask\")(inp_token1)\n",
    "    word_embed = embed_layer(inp_token1)\n",
    "    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n",
    "    word_embed = Bidirectional(LSTM(cfg[\"unit1_1\"], return_sequences=True), merge_mode=\"sum\")(word_embed)\n",
    "    word_embed = BatchNormalization()(word_embed)\n",
    "    # word_embed = Dropout(0.3)(word_embed)\n",
    "    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n",
    "\n",
    "    sequence_output = model1([inp_token1, inp_segm1])\n",
    "    sequence_output = Concatenate(axis=-1)([sequence_output, word_embed])\n",
    "    text_pool = Lambda(lambda x: x[:, 0, :])(sequence_output)\n",
    "\n",
    "    # Share weights of character-level embedding for premise and hypothesis\n",
    "    character_embedding_layer = TimeDistributed(Sequential([\n",
    "        embed_layer,\n",
    "        # Embedding(input_dim=100, output_dim=char_embedding_size, input_length=chars_per_word),\n",
    "        Conv1D(filters=128, kernel_size=3, name=\"char_embed_conv1d\"),\n",
    "        GlobalMaxPooling1D()\n",
    "    ]), name='CharEmbedding')\n",
    "    character_embedding_layer.build(input_shape=(None, None, cfg[\"max_char\"]))\n",
    "    image_char_embed  = character_embedding_layer(inp_image_char)    \n",
    "    image_embed = Concatenate(axis=-1)([image_char_embed, inp_image])    \n",
    "    image_embed = Dense(256, activation='relu', name='image_embed')(image_embed)\n",
    "    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n",
    "    pos_embed = Dense(256, activation='relu', name='pos_embed')(inp_pos)\n",
    "    pos_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([pos_embed, inp_image_mask])\n",
    "    embed = Add()([image_embed , pos_embed]) # batch, maxlen(10), 1024+128\n",
    "    \n",
    "    image_embed = Bidirectional(LSTM(512, return_sequences=True), merge_mode=\"sum\")(embed)\n",
    "    image_embed = BatchNormalization()(image_embed)\n",
    "    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n",
    "    \n",
    "    image_pool = Lambda(lambda x: x[:, 0, :])(image_embed)\n",
    "    \n",
    "    pool = Concatenate(axis=-1)([image_pool, text_pool])\n",
    "    pool = Dense(1024, activation=\"relu\")(pool)\n",
    "    pool = Dropout(0.3)(pool)\n",
    "    pool = Dense(512, activation=\"relu\")(pool)\n",
    "    pool = Dense(128, activation=\"relu\")(pool)\n",
    "    \n",
    "    output = Dense(2, activation='softmax', name='output')(pool)\n",
    "\n",
    "    opt = get_opt(num_example=cfg[\"num_example\"], lr=cfg['lr'], min_lr=cfg['min_lr'])\n",
    "    model = Model(inputs=[inp_token1, inp_segm1, \n",
    "                          inp_image, inp_image_mask,\n",
    "                          inp_pos, inp_image_char], outputs=[output])#\n",
    "    \n",
    "    model.compile(optimizer=opt, loss={\n",
    "                'output': 'sparse_categorical_crossentropy'\n",
    "            }, metrics=['accuracy'])\n",
    "    if summary:\n",
    "        model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# cfg[\"num_example\"] = 32\n",
    "# model = build_model(cfg, summary=True, word_embedding_matrix=word_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dWGkWTgbAr48"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import base64\n",
    "\n",
    "\n",
    "def convertBoxes(num_boxes, boxes):\n",
    "    return np.frombuffer(base64.b64decode(boxes), dtype=np.float32).reshape(num_boxes, 4)\n",
    "def convertFeature(num_boxes, features,):\n",
    "    return np.frombuffer(base64.b64decode(features), dtype=np.float32).reshape(num_boxes, 2048)\n",
    "def convertLabel(num_boxes, label):\n",
    "    return np.frombuffer(base64.b64decode(label), dtype=np.int64).reshape(num_boxes)\n",
    "def convertLabelWord(num_boxes, label):\n",
    "    temp = np.frombuffer(base64.b64decode(label), dtype=np.int64).reshape(num_boxes)\n",
    "    return '###'.join([id2label[t] for t in temp])\n",
    "def convertPos(num_boxes, boxes, H, W):\n",
    "    pos_list = []\n",
    "    for i in range(num_boxes):\n",
    "        temp = boxes[i]\n",
    "        pos_list.append([temp[0]/W, \n",
    "                         temp[2]/W, \n",
    "                         temp[1]/H, \n",
    "                         temp[3]/H, \n",
    "                         ((temp[2] - temp[0]) * (temp[3] - temp[1]))/ (W*H),])\n",
    "    return pos_list\n",
    "\n",
    "\n",
    "def load_sample_data(path, frac=0.000001):\n",
    "    ### Data Sampling and decoding\n",
    "    train_data = dd.read_csv(path, sep='\\t', blocksize=25e6, quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "    \n",
    "    sample_train_data = train_data.sample(frac=frac).compute()\n",
    "    sample_train_data['words'] = sample_train_data['query']\n",
    "    sample_train_data['label_words'] = sample_train_data.apply(lambda x: convertLabelWord(x['num_boxes'], x['class_labels']), axis=1,meta= pd.Series([], dtype=str, name='label_words'))\n",
    "    sample_train_data['boxes_convert'] = sample_train_data.apply(lambda x: convertBoxes(x['num_boxes'], x['boxes']), axis=1, meta =pd.Series([], dtype=object, name='boxes_convert'))\n",
    "    sample_train_data['features'] = sample_train_data.apply(lambda x: convertFeature(x['num_boxes'], x['features']), axis=1, meta=pd.Series([], dtype=object, name='features'))\n",
    "    sample_train_data['pos'] = sample_train_data.apply(lambda x: convertPos(x['num_boxes'], x['boxes_convert'], x['image_h'], x['image_w']), axis=1, meta=pd.Series([], dtype=object, name='pos'))\n",
    "    return sample_train_data[['words', 'label_words', 'boxes_convert', 'features', 'pos']].compute()\n",
    "\n",
    "\n",
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            print(len(tokens_a))\n",
    "            tokens_b.pop()\n",
    "\n",
    "\n",
    "def token2id_X(X, x_dict, maxlen=None):\n",
    "    x = tokenizer.tokenize(X)\n",
    "    if maxlen:\n",
    "        x = x[: 1] + list(x)[1: maxlen - 1] + x[-1: ]     \n",
    "    seg = [0 for _ in x]\n",
    "    token = list(x)\n",
    "    x = [x_dict[e] if e in x_dict else x_dict[\"[UNK]\"] for e in token]\n",
    "    assert len(x) == len(seg)\n",
    "    return x, seg\n",
    "\n",
    "\n",
    "def seq_padding(X, maxlen=None, padding_value=None, debug=False):\n",
    "    L = [len(x) for x in X]\n",
    "    if maxlen is None:\n",
    "        maxlen = max(L)\n",
    "\n",
    "    pad_X = np.array([\n",
    "        np.concatenate([x, [padding_value] * (maxlen - len(x))]) if len(x) < maxlen else x[: maxlen] for x in X\n",
    "    ])\n",
    "    if debug:\n",
    "        print(\"[!] before pading {}\\n\".format(X))\n",
    "        print(\"[!] after pading {}\\n\".format(pad_X))\n",
    "    return pad_X\n",
    "    \n",
    "\n",
    "def MyChoice(Myset):\n",
    "    result = []\n",
    "    for i in Myset:\n",
    "        temp_set = set()\n",
    "        temp_set.add(i)\n",
    "        cho = choice(list(Myset - temp_set))\n",
    "        result.append(cho)\n",
    "    return result\n",
    "\n",
    "\n",
    "class data_generator:\n",
    "    \n",
    "    def __init__(self, data, batch_size=B_SIZE, shuffle=SHUFFLE):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = len(self.data) // self.batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        if len(self.data) % self.batch_size != 0:\n",
    "            self.steps += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "    \n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        inp_token1,\n",
    "        inp_segm1,\n",
    "        inp_image,\n",
    "        inp_image_mask,\n",
    "        inp_pos, \n",
    "        inp_image_char\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        while True:\n",
    "            idxs = list(range(len(self.data)))\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(idxs)\n",
    "            T1, T2, Image1, Pos1, label_word_list, image1_mask, image1_char = [], [], [], [], [], [], []\n",
    "            S1, S2, Image2, Pos2, image2_mask, image2_char = [], [], [], [], [], [] # 负样本\n",
    "            Id_set = set()\n",
    "\n",
    "            for i in idxs:\n",
    "                d = self.data.iloc[i]\n",
    "                text = d['words']\n",
    "                label_words = d['label_words']\n",
    "                \n",
    "                t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n",
    "                image = np.array(d['features'], dtype=\"float32\")\n",
    "                image = image[: cfg[\"max_box\"]]\n",
    "                img_mask = [1 for _ in image[: cfg[\"max_box\"]]]\n",
    "                \n",
    "                pos = np.array(d['pos'], dtype=\"float32\")\n",
    "                pos = pos[: cfg[\"max_box\"]]\n",
    "                \n",
    "                image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n",
    "                image_char = image_char[: cfg[\"max_box\"]]\n",
    "                # print(\"image_char\", len(image_char))\n",
    "                image_char = pad_sequences(image_char, \n",
    "                                           maxlen=cfg[\"max_char\"], \n",
    "                                           dtype='int32',\n",
    "                                           padding='post',\n",
    "                                           truncating='post',\n",
    "                                           value=cfg[\"x_pad\"])\n",
    "                \n",
    "                assert image.shape[0] == pos.shape[0]\n",
    "                assert image.shape[0] == cfg[\"max_box\"] or image.shape[0] == len(label_words.split(IMAGE_LABEM_CONCAT_TOKEN))\n",
    "                assert image_char.shape == (image.shape[0], cfg[\"max_char\"])\n",
    "\n",
    "                T1.append(t1)\n",
    "                T2.append(t2)\n",
    "                Image1.append(image)\n",
    "                image1_mask.append(img_mask)  \n",
    "                Pos1.append(pos)\n",
    "                image1_char.append(image_char)\n",
    "                Id_set.add(i)\n",
    "\n",
    "                if len(T1) == self.batch_size//2 or i == idxs[-1]:\n",
    "                    ## 加入负样本\n",
    "                    Id_new = MyChoice(Id_set)\n",
    "#                     print(Id_set, Id_new)\n",
    "                    for i, id_ in enumerate(Id_new):\n",
    "                        d_new = self.data.iloc[id_]\n",
    "                        text = d_new['words']\n",
    "                        t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n",
    "                        S1.append(t1)\n",
    "                        S2.append(t2)\n",
    "                        \n",
    "                        image = Image1[i]\n",
    "                        img_mask = image1_mask[i]\n",
    "                        pos = Pos1[i]\n",
    "                        image_char = image1_char[i]\n",
    "                        \n",
    "                        Image2.append(image)\n",
    "                        Pos2.append(pos)\n",
    "                        image2_mask.append(img_mask)\n",
    "                        image2_char.append(image_char)\n",
    "                    \n",
    "                    Y = [1] * len(T1) + [0] * len(S1)\n",
    "                   \n",
    "                    T1 = seq_padding(T1 + S1, padding_value=cfg[\"x_pad\"]) \n",
    "                    T2 = seq_padding(T2 + S2, padding_value=cfg[\"x_pad\"])\n",
    "                    \n",
    "                    Image1 = seq_padding(Image1 + Image2, \n",
    "                                         padding_value=np.zeros(shape=(2048, ))\n",
    "                                        )\n",
    "                                                         \n",
    "                    Pos1 = seq_padding(Pos1 + Pos2,\n",
    "                                       padding_value=np.zeros(shape=(5, ))\n",
    "                                      )\n",
    "                    image1_mask = seq_padding(image1_mask + image2_mask,\n",
    "                                             padding_value=0)\n",
    "                    \n",
    "                    image1_char = seq_padding(image1_char + image2_char,\n",
    "                                             padding_value=np.zeros(shape=(cfg[\"max_char\"])), debug=False)\n",
    "                    \n",
    "                    Y = np.array(Y).reshape((len(T1), -1))\n",
    "                    \n",
    "                    idx = np.arange(len(T1))\n",
    "                    np.random.shuffle(idx)\n",
    "        \n",
    "                    T1 = T1[idx]\n",
    "                    T2 = T2[idx]\n",
    "                    Image1 = Image1[idx]\n",
    "                    image1_mask = image1_mask[idx]\n",
    "                    Pos1 = Pos1[idx]\n",
    "                    image1_char = image1_char[idx]\n",
    "                    Y = Y[idx]\n",
    "                    \n",
    "                    yield [T1, T2, Image1, image1_mask, Pos1, image1_char], Y\n",
    "                    T1, T2, Image1, Pos1, label_word_list, image1_mask, image1_char = [], [], [], [], [], [], []\n",
    "                    S1, S2, Image2, Pos2, image2_mask, image2_char = [], [], [], [], [], [] # 负样本\n",
    "                    Id_set = set()\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cSFjbRg6Ar5A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# TRAIN_PATH = \"data/train.tsv\"\n",
    "# data = load_sample_data(TRAIN_PATH, frac=0.00001)\n",
    "\n",
    "# print(\"data\", len(data))\n",
    "\n",
    "# train_data = pd.read_pickle(\"data/100K_data.pkl\")\n",
    "\n",
    "train_D = data_generator(train_data)\n",
    "with open(\"data/sample_val.pkl\", \"rb\") as f:\n",
    "    val_D = pickle.load(f)\n",
    "val_D = data_generator(val_data)\n",
    "_i  = 0\n",
    "for d in train_D:\n",
    "    _i += 1\n",
    "    if  _i > 10:\n",
    "        break\n",
    "    print('x',d[0][0].shape, d[0][1].shape,d[0][2].shape, d[0][3].shape, d[0][4].shape, d[0][5].shape, d[1].shape)\n",
    "    # print(d[0][5].sum(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wK6_y8irAr5C"
   },
   "outputs": [],
   "source": [
    "class Evaluate(Callback):\n",
    "    def __init__(self, filename=None):\n",
    "        self.score = []\n",
    "        self.best = 0.\n",
    "        self.filename = filename\n",
    "       \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch ==  0:\n",
    "            print(\"[!] test load&save model\")\n",
    "            f = self.filename + \".h5\"\n",
    "            custom_objects = get_custom_objects()\n",
    "            self.model.save(f, include_optimizer=False, overwrite=True)\n",
    "            if \"bert\" in cfg[\"verbose\"]:\n",
    "                model_ = load_model(f, custom_objects=custom_objects)  \n",
    "            else:\n",
    "                model_ = load_model(f) \n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "#         if epoch + 1 < 5:\n",
    "#             return\n",
    "        score = self.evaluate(self.model)\n",
    "        self.score.append((epoch, score))\n",
    "        \n",
    "        if epoch + 1 in SAVE_EPOCHS:\n",
    "            self.model.save(self.filename + \"_{}.h5\".format(epoch + 1), include_optimizer=False, overwrite=True)             \n",
    "        if score > self.best:\n",
    "            self.model.save(self.filename + \".h5\", include_optimizer=False)\n",
    "            \n",
    "        if score > self.best:\n",
    "            self.best = score\n",
    "            print(\"[!] epoch = {}, new NDCG best score = {}\".format(epoch + 1,  score))\n",
    "        print('[!] epoch = {}, score = {}, NDCG best score: {}\\n'.format(epoch + 1, score, self.best))\n",
    "\n",
    "    def eval_preprocess(self, row):\n",
    "\n",
    "            d = row\n",
    "            # qid = d['query_id']\n",
    "            # pid = d['product_id']\n",
    "            text = d['query']\n",
    "            label_words = d['label_words']\n",
    "            t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n",
    "            \n",
    "            image = np.array(d['feature_convert'], dtype=\"float32\")\n",
    "            image = image[: cfg[\"max_box\"]]\n",
    "            img_mask = [1 for _ in image[: cfg[\"max_box\"]]]                   \n",
    "            pos = np.array(d['pos'], dtype=\"float32\")\n",
    "            pos = pos[: cfg[\"max_box\"]]\n",
    "            \n",
    "            image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n",
    "            image_char = image_char[: cfg[\"max_box\"]]\n",
    "            image_char = pad_sequences(image_char, \n",
    "                                       maxlen=cfg[\"max_char\"], \n",
    "                                       dtype='int32',\n",
    "                                       padding='post',\n",
    "                                       truncating='post',\n",
    "                                       value=cfg[\"x_pad\"])\n",
    "            output = self.model.predict([np.asarray([t1]), np.asarray([t2]), np.asarray([image]), np.asarray([img_mask]), np.asarray([pos]), np.asarray([image_char])])\n",
    "            return output\n",
    "\n",
    "\n",
    "    def evaluate(self, model):\n",
    "        self.model = model\n",
    "        result = defaultdict(list)\n",
    "        val_results = val_data.apply(self.eval_preprocess, axis=1)\n",
    "        # print(val_results)\n",
    "        qid = val_data[\"query_id\"].values\n",
    "        pid = val_data[\"product_id\"].values\n",
    "\n",
    "\n",
    "        # print(val.shape)\n",
    "        \n",
    "\n",
    "        for i in trange(len(val_data)): \n",
    "            result[qid[i]].append((pid[i], val_results[i][0][1]))\n",
    "            \n",
    "        query_id,product1,product2,product3,product4,product5 = [],[],[],[],[],[]\n",
    "        for key in result.keys():\n",
    "            rlist = result[key]\n",
    "            rlist.sort(key=lambda x: x[1], reverse=True)\n",
    "            query_id.append(key)\n",
    "            product1.append(rlist[0][0])\n",
    "            product2.append(rlist[1][0])\n",
    "            product3.append(rlist[2][0])\n",
    "            product4.append(rlist[3][0])\n",
    "            product5.append(rlist[4][0])\n",
    "        sub = pd.DataFrame({'query-id':query_id,\n",
    "                            'product1':product1,\n",
    "                            'product2':product2,\n",
    "                            'product3':product3,\n",
    "                            'product4':product4,\n",
    "                            'product5':product5,\n",
    "\n",
    "        })\n",
    "        sub.to_csv('result/val_submission.csv',index=0)\n",
    "        \n",
    "        reference = json.load(open(VAL_ANS_PATH))\n",
    "        \n",
    "        # read predictions\n",
    "        k = 5\n",
    "        predictions = read_submission('result/val_submission.csv', reference, k)\n",
    "\n",
    "        # compute score for each query\n",
    "        score_sum = 0.\n",
    "        for qid in reference.keys():\n",
    "            ground_truth_ids = set([str(pid) for pid in reference[qid]])\n",
    "            ref_vec = [1.0] * len(ground_truth_ids)\n",
    "            pred_vec = [1.0 if pid in ground_truth_ids else 0.0 for pid in predictions[qid]]\n",
    "            score_sum += get_ndcg(pred_vec, ref_vec, k)\n",
    "        # the higher score, the better\n",
    "        score = score_sum / len(reference)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0U5XAi6Ar5D"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10148921,
     "status": "ok",
     "timestamp": 1636219971941,
     "user": {
      "displayName": "Yasser Otiefy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64",
      "userId": "11606645386995589698"
     },
     "user_tz": -60
    },
    "id": "-8khJgNZAr5F",
    "outputId": "a957f6b0-64b7-4ed2-98e0-788e46c9bf66",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "gc.collect()\n",
    "fold_id = -1\n",
    "print(\"\\n\\n[!] fold_id = {} starting\".format(fold_id))\n",
    "cfg[\"filename\"] = cfg[\"raw_filename\"].format(cfg[\"verbose\"], FOLD_NUM, fold_id)\n",
    "\n",
    "\n",
    "cfg[\"num_example\"] = len(train_data)\n",
    "print(len(train_data))\n",
    "\n",
    "tf.compat.v1.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "seed(SEED - fold_id)\n",
    "np.random.seed(SEED - fold_id)\n",
    "tf.compat.v1.random.set_random_seed(SEED - fold_id)\n",
    "train_D = data_generator(train_data)\n",
    "print(cfg)\n",
    "model = build_model(cfg, summary=True, \n",
    "                    word_embedding_matrix=word_embedding_matrix,\n",
    "                    )\n",
    "tf.keras.utils.plot_model(model, to_file=\"models/model_v1.png\", show_shapes=True)\n",
    "#     model.load_weights('[image-concat-query]-wwm_uncased_L24-1024_20oof0')\n",
    "\n",
    "#     checkpoint= ModelCheckpoint(cfg[\"filename\"], monitor='acc', verbose=1, save_best_only=False, mode='max') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OvOGGA_tP8F"
   },
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U73CNxpCtVUY"
   },
   "outputs": [],
   "source": [
    "# %%capture training\n",
    "import datetime\n",
    "\n",
    "# tf.compat.v1.keras.backend.clear_session()\n",
    "evaluator = Evaluate(filename=cfg[\"filename\"])\n",
    "log_dir = \"logs/fit/1M_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.compat.v1.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# def lr_schedule(epoch):\n",
    "#   \"\"\"\n",
    "#   Returns a custom learning rate that decreases as epochs progress.\n",
    "#   \"\"\"\n",
    "#   learning_rate = 0.2\n",
    "#   if epoch > 10:\n",
    "#     learning_rate = 0.02\n",
    "#   if epoch > 20:\n",
    "#     learning_rate = 0.01\n",
    "#   if epoch > 50:\n",
    "#     learning_rate = 0.005\n",
    "\n",
    "#   tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "#   return learning_rate\n",
    "\n",
    "# lr_callback = tf.compat.v1.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "model.fit(train_D.__iter__(),\n",
    "                          steps_per_epoch=len(train_D),\n",
    "                          epochs=MAX_EPOCH,\n",
    "                          callbacks=[evaluator, tensorboard_callback],\n",
    "                          shuffle=True\n",
    "                          )\n",
    "print(\"\\n\\n[!] fold_id = {} finish\".format(fold_id))\n",
    "del model, evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUo7uyS6Ar5G",
    "scrolled": true
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73205,
     "status": "ok",
     "timestamp": 1636220046397,
     "user": {
      "displayName": "Yasser Otiefy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64",
      "userId": "11606645386995589698"
     },
     "user_tz": -60
    },
    "id": "8yAEZS7dAr5G",
    "outputId": "ff7ac5dd-b2e5-4095-ef2e-f206020b4592"
   },
   "outputs": [],
   "source": [
    "with open('data/testA_data.pkl', 'rb') as outp:\n",
    "    test_data = pickle.load(outp)\n",
    "\n",
    "f = cfg[\"filename\"] + \".h5\"\n",
    "print(f)\n",
    "if \"bert\" in cfg[\"verbose\"]:\n",
    "    custom_objects = get_custom_objects()\n",
    "    model = load_model(f, custom_objects=custom_objects)  \n",
    "else:\n",
    "    model = load_model(f)\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ct2eCmYhAr5H"
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "result = defaultdict(list)\n",
    "for i in trange(len(test_data)):\n",
    "    d = test_data.iloc[i]\n",
    "    qid = d['query_id']\n",
    "    pid = d['product_id']\n",
    "    text = d['query']\n",
    "    label_words = d['label_words']\n",
    "    t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n",
    "\n",
    "    image = np.array(d['feature_convert'], dtype=\"float32\")\n",
    "    image = image[: cfg[\"max_box\"]]\n",
    "    img_mask = [1 for _ in image[: cfg[\"max_box\"]]]                   \n",
    "    pos = np.array(d['pos'], dtype=\"float32\")\n",
    "    pos = pos[: cfg[\"max_box\"]]\n",
    "\n",
    "    image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n",
    "    image_char = image_char[: cfg[\"max_box\"]]\n",
    "    image_char = pad_sequences(image_char, \n",
    "                               maxlen=cfg[\"max_char\"], \n",
    "                               dtype='int32',\n",
    "                               padding='post',\n",
    "                               truncating='post',\n",
    "                               value=cfg[\"x_pad\"]) \n",
    "    output = model.predict([np.asarray([t1]), np.asarray([t2]), np.asarray([image]), np.asarray([img_mask]), np.asarray([pos]), np.asarray([image_char])])\n",
    "    result[qid].append((pid, output[0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOWqYUaXAr5H"
   },
   "outputs": [],
   "source": [
    "query_id,product1,product2,product3,product4,product5 = [],[],[],[],[],[]\n",
    "for key in result.keys():\n",
    "    rlist = result[key]\n",
    "    rlist.sort(key=lambda x: x[1], reverse=True)\n",
    "    query_id.append(key)\n",
    "    product1.append(rlist[0][0])\n",
    "    product2.append(rlist[1][0])\n",
    "    product3.append(rlist[2][0])\n",
    "    product4.append(rlist[3][0])\n",
    "    product5.append(rlist[4][0])\n",
    "\n",
    "sub = pd.DataFrame({'query-id':query_id,\n",
    "                    'product1':product1,\n",
    "                    'product2':product2,\n",
    "                    'product3':product3,\n",
    "                    'product4':product4,\n",
    "                    'product5':product5,\n",
    "\n",
    "})\n",
    "\n",
    "sub.to_csv('result/submission_1M.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hjq_AYpAAr5I"
   },
   "outputs": [],
   "source": [
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecQVcr2zXytP"
   },
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1636222703249,
     "user": {
      "displayName": "Yasser Otiefy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64",
      "userId": "11606645386995589698"
     },
     "user_tz": -60
    },
    "id": "RR5AV6DQXyGN",
    "outputId": "938ec73d-ba80-493f-f6c5-2b6f41fb6faf"
   },
   "outputs": [],
   "source": [
    "!python eval.py data/testA_answer.json result/submission_1M.csv result/testA_result_1M.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfArcyPlAr5J"
   },
   "outputs": [],
   "source": [
    "# !pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    global cfg\n",
    "    \n",
    "    def _get_model(base_dir, cfg_=None):\n",
    "        config_file = os.path.join(base_dir, 'bert_config.json')\n",
    "        checkpoint_file = os.path.join(base_dir, 'bert_model.ckpt')\n",
    "        if not os.path.exists(config_file):\n",
    "            config_file = os.path.join(base_dir, 'bert_config_large.json')\n",
    "            checkpoint_file = os.path.join(base_dir, 'roberta_l24_large_model')\n",
    "        print(config_file, checkpoint_file)\n",
    "#         model = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True, seq_len=cfg_['maxlen'])\n",
    "        model = load_trained_model_from_checkpoint(config_file, \n",
    "                                           checkpoint_file, \n",
    "                                           training=False, \n",
    "                                           trainable=cfg_[\"bert_trainable\"], \n",
    "                                           output_layer_num=cfg[\"cls_num\"],\n",
    "                                           seq_len=None)\n",
    "        return model\n",
    "    \n",
    "    def get_opt(num_example, warmup_proportion=0.1, lr=2e-5, min_lr=None):\n",
    "        if cfg[\"opt\"].lower() == \"nadam\":\n",
    "            opt = Nadam(lr=lr)\n",
    "        else:\n",
    "            total_steps, warmup_steps = calc_train_steps(\n",
    "                num_example=num_example,\n",
    "                batch_size=B_SIZE,\n",
    "                epochs=MAX_EPOCH,\n",
    "                warmup_proportion=warmup_proportion,\n",
    "            )\n",
    "\n",
    "            opt = AdamWarmup(total_steps, warmup_steps, lr=lr, min_lr=min_lr)\n",
    "\n",
    "        return opt\n",
    "\n",
    "    # model1 = _get_model(cfg[\"base_dir\"], cfg)\n",
    "    # model1 = Model(inputs=model1.inputs[: 2], outputs=model1.layers[-7].output)\n",
    "\n",
    "    global word_index\n",
    "    word_embedding_matrix = load_word_embed(word_index=word_index)\n",
    "    embed_layer = Embedding(input_dim=word_embedding_matrix.shape[0], \n",
    "                            output_dim=word_embedding_matrix.shape[1],\n",
    "                            weights=[word_embedding_matrix],\n",
    "                            trainable=cfg[\"trainable\"],\n",
    "                            name=\"embed_layer\"\n",
    "                        )\n",
    "        \n",
    "    inp_token1 = Input(shape=(None, ), dtype=np.int32, name=\"query_token_input\")\n",
    "    inp_segm1 = Input(shape=(None, ), dtype=np.float32, name=\"query_segm_input\")\n",
    "    \n",
    "#     inp_token2 = Input(shape=(None, ), dtype=np.int32)\n",
    "#     inp_segm2 = Input(shape=(None, ), dtype=np.float32)    \n",
    "    \n",
    "    inp_image = Input(shape=(None, 2048), dtype=np.float32, name=\"image_input\")\n",
    "    inp_image_mask = Input(shape=(None, ), dtype=np.float32, name=\"image_mask_input\")\n",
    "    inp_pos = Input(shape=(None, 5), dtype=np.float32, name=\"image_pos_input\")        \n",
    "    inp_image_char = Input(shape=(None, cfg[\"max_char\"]), dtype=np.int32, name='image_char_input')\n",
    "    \n",
    "    \n",
    "    mask = Lambda(lambda x: K.cast(K.not_equal(x, cfg[\"x_pad\"]), 'float32'), name=\"token_mask\")(inp_token1)\n",
    "    word_embed = embed_layer(inp_token1)\n",
    "    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n",
    "    word_embed = Bidirectional(LSTM(cfg[\"unit1_1\"], return_sequences=True), merge_mode=\"sum\")(word_embed)\n",
    "    word_embed = BatchNormalization()(word_embed)\n",
    "    # word_embed = Dropout(0.3)(word_embed)\n",
    "    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n",
    "\n",
    "    # sequence_output = model1([inp_token1, inp_segm1])\n",
    "    # sequence_output = Concatenate(axis=-1)([sequence_output, word_embed])\n",
    "    text_pool = Lambda(lambda x: x[:, 0, :])(word_embed)\n",
    "\n",
    "    # Share weights of character-level embedding for premise and hypothesis\n",
    "    character_embedding_layer = TimeDistributed(Sequential([\n",
    "        embed_layer,\n",
    "        # Embedding(input_dim=100, output_dim=char_embedding_size, input_length=chars_per_word),\n",
    "        Conv1D(filters=128, kernel_size=3, name=\"char_embed_conv1d\"),\n",
    "        GlobalMaxPooling1D()\n",
    "    ]), name='CharEmbedding')\n",
    "    character_embedding_layer.build(input_shape=(None, None, cfg[\"max_char\"]))\n",
    "    image_char_embed  = character_embedding_layer(inp_image_char)    \n",
    "    image_embed = Concatenate(axis=-1)([image_char_embed, inp_image])    \n",
    "    image_embed = Dense(256, activation='relu', name='image_embed')(image_embed)\n",
    "    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n",
    "    pos_embed = Dense(256, activation='relu', name='pos_embed')(inp_pos)\n",
    "    pos_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([pos_embed, inp_image_mask])\n",
    "    embed = Add()([image_embed , pos_embed]) # batch, maxlen(10), 1024+128\n",
    "    \n",
    "    image_embed = Bidirectional(LSTM(512, return_sequences=True), merge_mode=\"sum\")(embed)\n",
    "    image_embed = BatchNormalization()(image_embed)\n",
    "    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n",
    "    \n",
    "    image_pool = Lambda(lambda x: x[:, 0, :])(image_embed)\n",
    "    \n",
    "    pool = Concatenate(axis=-1)([image_pool, text_pool])\n",
    "\n",
    "    hp_units = hp.Int('units', min_value=64, max_value=2048, step=32)\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh', 'sigmoid', 'leakyrelu'])\n",
    "    pool = Dense(hp_units, activation=hp_activation)(pool)\n",
    "    hp_dropout_prop = hp.Choice('dropout_prop', values=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "    pool = Dropout(hp_dropout_prop)(pool)\n",
    "    pool = Dense(hp_units, activation=hp_activation)(pool)\n",
    "    pool = Dense(hp_units, activation=hp_activation)(pool)\n",
    "    \n",
    "    output = Dense(2, activation='softmax', name='output')(pool)\n",
    "\n",
    "    model = Model(inputs=[inp_token1, inp_segm1, \n",
    "                          inp_image, inp_image_mask,\n",
    "                          inp_pos, inp_image_char], outputs=[output])#\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.compat.v1.keras.optimizers.Adam(learning_rate=hp_learning_rate), loss={\n",
    "                'output': 'sparse_categorical_crossentropy'\n",
    "            }, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project hyperparameter_tuning/multimodal_hyperparameter_tuning/oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 20:46:19.080563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8887 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:86:00.0, compute capability: 3.7\n",
      "2021-12-27 20:46:19.081579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10248 MB memory:  -> device: 1, name: Tesla K80, pci bus id: 0000:87:00.0, compute capability: 3.7\n"
     ]
    }
   ],
   "source": [
    "# tf.compat.v1.keras.backend.clear_session()\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='hyperparameter_tuning',\n",
    "                     project_name='multimodal_hyperparameter_tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=5)\n",
    "log_dir = \"logs/multimodal_hpram_tuning/\"\n",
    "tensorboard_callback = tf.compat.v1.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units             |992               |?                 \n",
      "activation        |tanh              |?                 \n",
      "dropout_prop      |0.1               |?                 \n",
      "learning_rate     |0.001             |?                 \n",
      "tuner/epochs      |3                 |?                 \n",
      "tuner/initial_e...|0                 |?                 \n",
      "tuner/bracket     |2                 |?                 \n",
      "tuner/round       |0                 |?                 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 20:46:48.381853: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8301\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/lib64/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2021-12-27 20:46:49.259152: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-12-27 20:46:49.259858: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-12-27 20:46:49.259934: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2021-12-27 20:46:49.261129: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-12-27 20:46:49.261359: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 134612/Unknown - 26780s 199ms/step - loss: 0.0773 - accuracy: 0.4867- 10885s 199ms/step - loss: 0.0916 -  - 10888s 199ms/step - loss: 0.0916 - accur - 10890s 199ms/step - los - 10896s 199ms/step - loss: 0.091 - 109 - 10931s 199ms/step - loss: 0.0915 - accuracy: 0. - 10932s 199ms/step - loss: 0.0915 - accuracy: 0.48 - 10932s 199ms/step - loss: 0.0915 - accuracy: 0.48 - 10933s 199ms/step - l - 10939s 199ms/step - l  - 10966s 199ms/step - loss: 0.0914 - accuracy: 0 - 11226s 199ms/step - loss: 0.09 - 1 - 11251s 199ms/step - lo - 112 - 11288s 199ms/step - loss: 0.0907 - accurac - 11290s 19 - 11298s 199ms/step - loss:  - 11303s 199ms/step - loss: 0.0906 - accuracy: - 11305s 199ms/step - loss: 0.0906 - accuracy: 0.4 - 11306s 199ms/step - loss: 0.0906 - accuracy - 11307s 199ms/step - loss: 0.0906 - accur - 11309s 199ms/step - loss: 0.0906 - accuracy: 0.4 - 11310s 199ms/step - loss: 0.0906 - accuracy - 11312s 199ms/step - loss: 0.0906 - acc - 1131 - 11356s 199ms/ste - 11363s 199ms/step - loss: 0. - 11368s 199ms/step - loss: 0. - 1137 - 11446s 199ms/step - 11464s 199ms/step - loss: 0.0903 - accuracy: 0.  - 11507s 199ms/step - loss: 0.0902 - - 11510s 199ms/step - - 1151 - 11526s 199ms/step - loss: 0.0902 - - 11647s 199ms/s - 11665s 199ms/step - loss: 0.0 - 11670s 199ms/ - 11678s 199ms/step - loss: 0.089 - 116 - 11691s 199 - 11699s 199ms/step - loss: 0.0 - 11704s 199ms/step - loss: 0.0898 - accuracy:  - 11705s 199m - 11713s 199ms - 11720s 199ms/step - loss:  - 11747s 199ms/step - loss: 0.08 - 1176 - 11772s 199ms/step - l - 11777s 199ms/step - loss: 0.0897 - accuracy - 11779s 199ms/step - loss: 0.0897 - accuracy: - 11781s 1 - 11799s 199ms/step - loss: 0.0896 -  - 11803s 199ms/step -  - 11819s 199ms/step - loss: 0.0896  - 12060s 199ms/step - loss: 0. - 12065s 199ms/step - loss - 12092s 199ms/step - loss: 0.0890 - accu - 12094s 199ms/step - loss: 0.0890 - accur - 12096s 199ms/ste - 12103s 199ms/step - loss: 0 - 12108s 199ms/step - loss: 0.0890 - accuracy:  - 12110s 199ms/step - loss: 0.0890 - accuracy - 12111s 199ms/step  - 12129s 199ms/step - - 12146s 199ms/step - loss: 0.0889 - accura - 12148s 199ms/step - loss: 0.0889 - accu - 12150s 199ms/step - loss:  - 12155s 199ms/step - loss: 0.0889 - accuracy: 0 - 12156s 199ms/step - loss:  - 12193s 199ms/step - loss: 0.0889 - accuracy: 0.484 - 12280s 199ms/step - loss:  - 12286s 199ms/step - loss: 0.0887 - accur - 12288s 199ms/ste - 12294  - 12392 - 12423s 199ms/step - loss: 0.0884 - accuracy: 0 - 12424s 19 - 12433s 199ms/step - loss: 0.0884 - accuracy: 0.484 - 12433s 199ms/step - loss: 0.0 - 12448s 199ms/step - loss: 0.0884 - accuracy: 0.48 - 12448s 199ms/step - loss: 0.0884 - accurac - 12450s 199ms/step - loss: 0.088 -  - 12464s 199 - 12472s 199ms/step - loss: 0.0884 - accuracy: 0.484 - 12472s 199ms/step - loss: 0.0884 - accu - 12573s 199ms/step - loss: 0.0882 - accu - 12575s 199ms/step - loss: 0.0882 - accu - 12578s 1 - 12586s 1 - 15913s 1 - 15932s 19 - - 15973s 199ms/step - loss: 0.0832 - accur - 15975s 199ms/step - loss: 0.0832 - ac - 15978s 199ms/step - loss: 0 - 15983s 199 - 15991s 199ms/step - loss: 0.0832 - accuracy: 0 -  - 16132s 199ms/step - loss: 0.0831 -  - 16135s 199ms/step - loss:  - 16140s 199ms/step - loss: 0.0831 - 16144s 199ms/step - loss: 0.0831 - accuracy: 0.485 - 16144s 199ms/step - loss: 0.0831 - accura - 16146s 199ms/step - lo - 16323s 199ms/step - loss: 0.08 - 16338s 199ms/step - loss: 0. - 16343s 199ms/step - loss: 0.0828 - accuracy: 0. - 16365s 199ms/step - loss: 0.0828 - accuracy: 0.485 - 16365s 199ms/step - loss: 0.0828 - accuracy: 0.48 - 16366s 199ms/step - - 16 - 16393s 199ms/ste - 16399s 199ms/step - loss: 0.0828 - accur - 16402s 199ms/step - loss: 0.0828 - accuracy: 0. - 16468s 199ms/step - loss:  - 16484s 199ms/step - loss: 0.0 - 16488s 199ms/step - loss: 0.0827 - acc - 16491s 199ms/st - 16498s 199ms/step - loss: 0.0827 - accuracy: 0.485 - 16498s 1 - 16506s 199ms/step - loss: 0.0827 - accuracy - 16508s 199ms/step - loss: 0.0827 - accuracy: 0.485 - 16508s 199ms/step - los - 16514s 199ms/step - loss: 0.0827  - 16517s 199ms/step - - 16524s 199m - 16564s 199ms/step - loss: 0.0826 - accuracy: 0.4 - 16564s 199ms/step - l - 16699s 199ms/step - loss: 0.0825 - accuracy: 0. - 16700s 199ms/ - 16750s 199ms/step - loss: - 16756s 199ms/ste - 17108s 199ms/step - loss: 0.0821 - accura - 17110s 199ms/step - loss: 0.0821 - accuracy: 0. - 17110s 199ms/step - loss: 0.0821 - accuracy:  - 17112s 199ms/step - loss: 0.0821 -  - 171 - 17125s 199ms/step - loss: 0.0821 - accura - 17127s 199ms/step - loss: 0.0821 - a - 17130s 199ms/step - loss: 0. - 17134s 199ms/s - 17249s 199m - 17279s 199ms/step - loss: 0.0819 - accuracy: 0 - 17280s 199ms/step - loss: 0.0819 - accurac - 17282s 199ms/step - loss: 0.0819 - accuracy: 0.48 - 17283s 199ms/step - loss: 0.0819 - accu - 17285s 199ms/step - loss - 17290s 199ms/step - loss: 0.0819 - ac - 17293s 19 - 17355s 199ms/step - loss: 0.08 - 17369s 199ms/step - - 17397s 199ms/step - loss: 0.0818 - accur -  - 17410s 199ms/step - loss: 0.0818 - accuracy:  - 1 - 17421s 199ms/step - loss: 0.081 - 17425s 199ms/step - loss: 0.0818 - accuracy: 0. - 17426s 199ms/step - loss: 0.081 - 17430s 199ms/step - loss: 0.0818 - 17466s 199ms/step - loss: 0.08 - 17470s 199ms/st - 17478s 199ms/step - loss: 0.0817 -  - 17481s 199ms/step - loss: 0.0817  - 174 - 17494s 199 - 17535s 199ms/step - loss: 0.0817 - accurac - 17537s 199ms/ - 17577s 199ms/step - loss: 0.0816 - accuracy:  - 18117s 199ms/step - loss: 0 - 18122s 199ms/step - lo - 18128s 199ms/step - loss: 0.0812 - 18153s 199ms/ste - 18160s  - 18180s 199 - 18188s 199ms/step - loss: 0.0811 - accuracy: 0.48 - 18189s 199ms/step - loss: 0.0811 - accuracy:  - 18190s 199ms/step - loss:  - 18195s  - 18203s 199ms/step - los - 19887s 199ms/step - lo - 19893s 199ms/s - 19954s 199ms/step - loss: 0.0799 - accura - 19956s 199ms/step - loss: 0.079 - - 20974s 199ms/step - - 21013s 19 - 21 - 21  - 2164 -  - 22082s 199ms/step - loss: 0.0788 - accuracy: 0 - 22083s 199ms/step - loss: 0.0788 - accura - 22085s 199ms/step - loss: 0.0788 - accuracy: 0.4 - 22086s 199ms/step - loss: 0.0788 - - 22089s 199ms/step - lo - 22170s 199ms/step - loss: 0.0787 - accurac - 22172s 199ms/step - loss: 0.0787 - ac - 22174s 199ms/step - loss: 0.0787 - accuracy: 0 - 22175s 199ms/step - lo - 22181s 199ms/s - 22671s 199ms/step - loss: 0.0786 - accuracy - 22 - 22714s 199ms/step - loss: 0.0785 - a - 22717s 199ms/ste - 23003s 199ms/step - loss: 0.0784 - accuracy: 0.4 - 23004s 199ms/step - loss: 0.0784  - 23007s 199ms/s - 23079 - 23088s 199ms/step - loss: 0.07 - 23092s 199ms/ - 23100s 199ms/step - 23117s 199ms/step - loss: 0.0784 - accura - 23 - 24431s 19 - 2 - 24449s 1 - 25268s 199ms/s - 25330s 199ms/step - loss: 0.0777 - accuracy: 0 - 25331s 199ms/step  - 25338s 1 - 25435s  - 25455s 199ms/step - loss: 0 - 25460s 199ms/s - 25467s 199ms/ - 26121s - 26368s 199ms/st - 26386s 199ms/step - loss: 0.0774 - acc - 26389s 199ms/step - loss: 0.0774 - accuracy - 26390s 199ms/step - loss: 0.0774 - accuracy: 0.48 - 26391s 199ms/st - 26517s 199ms/step - loss:  - 26554s 199ms/step - loss: 0.0774 - accur - 26556s 199ms/ste -  - 26605s 199ms/step - loss: 0.0773 - a - 26608s - 26617s 199ms/step - loss: 0. - 2664 - 2 - 26662s - 26671s 199ms/step - loss: 0.0773 - accuracy: 0.4 - 26671s 199ms/step - loss: 0.0773 - accuracy:  - 26672s 199ms/step - loss: 0.0773 - accuracy:  - 26674s 199ms/step - loss - 26679s 199ms/step - loss: 0.0773 - accuracy: 0.4 - 26680s 199ms/step - loss: 0.0773 - a - 26683s 199ms/step - loss: 0.0773 - accuracy: - 26684s 199ms/step - loss: 0.0773 - - 26688s 199ms/step - loss: 0.0773 - 26691s 199ms/step - loss: 0.0773 - acc - 26737s 199ms/step - - 26755s 199ms/step - loss: 0.0773 - accuracy: 0 - 26756s 199ms/step - loss: 0.0773 - accu - 26758s 199ms/step - loss: 0.0773 - accuracy: - 26760s 199ms/step - loss: 0.0773 - accuracy: 0. - 26760s 199ms/step - loss: 0.0773 - acc - 26763s 199ms/step - loss: 0 - 26768s 199ms/step - loss: 0.0773 - accuracy: 0.486 - 26768s 199ms/step - loss: 0.0773 - accuracy: 0 - 26769s 199ms/st - 26776s 199ms/step - loss: 0.0773 - accuracy:  - 26778s 199ms/step - loss: 0.0773 - accuracy: 0.4 - 26778s 199ms/step - loss: 0.0773 - accura - 26780s 199ms/step - loss: 0.0773 - accuracy: 0.4867"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 148641/Unknown - 29569s 199ms/step - loss: 0.0770 - accuracy: 0.4868- 26783s 199ms/step - l - 26 - 26799s 199ms/step -  - 26805s 199ms/step - loss: 0.0773  - 26885s 199ms/step - loss: 0.0773 - accu - 26887s 199ms/step - loss: 0.0773 - 26891s 199ms/step - loss: - 26906s 199ms/step - loss: 0. - 26911s 199ms/step - loss: 0.0773 - 26914s 199ms/ - 26922s 199ms/step - loss: 0.0773 - - 26957s 199ms/step - l - 26974s 199ms/step - loss: 0.0 - 26978s 199ms/step - loss - 26984s 199ms/step - loss: 0.0773 - accuracy: 0 - 26985s 199ms/step - loss - 26990s 199ms/step - loss: 0.0773 -  - 27003s 199ms/step - loss: 0.0773 - - 27006s 199ms/step - loss: 0.0773 - ac - 27009s 199ms - 27060s 199ms/step - loss:  - 27065s 199ms/step - loss: 0.0772 - ac - 27067s 199ms - 27 - 27085s 199ms/step - loss: 0.07 - 27089s 199ms/ - 27118s 199ms/step - loss: 0.0772 - accurac - 27120s - 27183s 199ms/step - loss: 0.0772 - accu - 27185s 199ms/step - loss: 0.0772 - accuracy: 0 - 27186s 199ms/step - loss: 0.0772 - accuracy - 27188s 199ms/step - loss: 0.0772 - 27192s 199ms/step - los - 27198s 199ms - 27206s 199ms/step - loss: 0.0772 - accuracy: 0 - 27207s 199ms/step - loss: 0.0772 - a - 27209s 199ms/step - loss: 0.0 - 27225s 1 - 27233s 199ms/ - 27263s  - 27272s 199ms/step  - 27279s 199ms/step - l - 27296s 199ms/step - loss: 0.0772 - accuracy: 0.4 - 27296s 199ms/step - lo - 27334s 199ms/step - loss: 0.0 - 27360s 199ms/step - - 27366s 199ms/step - loss:  - 273 - 27381s 199ms/step - loss:  - 27429s 199ms/step - loss: 0.0772 - accuracy: 0 - 27506s 199ms/step - 27523s 199ms/step - loss: 0.0772 - accuracy: 0.4 - 27523s 199ms/step - loss: 0 - 27528s 199ms/step - loss: 0.0772 - accuracy: 0.48 - 27529s 1 - 27537s 199ms/step - loss: 0.0772 -  - 27540s 199ms/step - loss: 0.0772 - accurac - 27553s 199ms/step - loss: 0.0772 - ac - 27556s 199ms/step -  - 27573s 199ms/step - loss: 0.077 - 27577s 199ms/  - 27704s 199 - 27723s 199ms/step - loss: 0.0771 - accuracy: - 27768s 199ms/step - loss - 27827s 199ms/step - loss: 0.0771 - 27991s 199ms/step  - 27997s  - 28007s 199ms/step - loss: 0.0771 - accura - 28019s 199ms/step - loss: 0.07 - 28024s 199ms/step - loss: 0 - 28093s 199ms/step - loss: 0 - 28098s 199ms/step - loss:  - 28103s 199ms/step - loss: 0.0771 - acc - 28106s 199ms/step - 281 - 28121s 199ms/step - loss: 0.0771 - accur - 28123s 199ms/step - los - 28129s 199ms - 28137s 199ms/step - loss: 0.0771 - accuracy: 0. - 28138s  - 28253s 199ms/step - loss: 0.0770  - 28256s 199ms/step - - 28262s 199ms/st - 28269s 199ms/step - loss - 28306s 199ms/step - loss: 0.0770 - - 28342s 199ms/step - loss - 28359s 1 - 28388s 199ms/step - loss: 0.0770 - accuracy: 0 - 28389s 199ms/step - loss: - 28394s 199ms/step - loss: 0.0770 - accuracy: 0.4 - 28395s 199ms/step - loss:  - 2 - 28518s 199ms/step - loss: 0.0770 - accuracy: 0. - 28519s 199m - 28527s 199ms/step - loss: 0 - 28532s 199ms/step - loss: 0.0770 - accuracy:  - 28533s 199ms/step - 28540s 199 - 28558s 199ms/step - loss: - 28564s 199ms/step - loss: 0.0770 - accur - 28566s 199ms/step - loss: 0.07 - 2 - 28591s 199ms/step - los - 28596s 199ms/ste - 28635s 199ms/step - loss: 0.07  - 28650s 199ms/step - loss: 0.0770 - 28654s 199ms/step - loss: 0.0770 -  - 28657s 199ms - 28676s 199ms/st - 28759s 199ms/step - loss: 0.0770 - accurac - 28761s 199ms - 28769s 199ms/step - loss:  - 28774s 19 - 28782s 199ms/step -  - 28788s 199ms/step - loss: 0.0770 - accuracy:  - 28789s 199ms/step - loss: 0.0770 - accuracy:  - 28790s 199ms/step - 28797s 199ms/step - loss: 0.0770 - accuracy: 0.4 - 28798s 19 - 28881s 199ms/s - 28920s 199ms/step - loss: 0.0770  - 28923s 199ms/step - loss: 0.0770 - accurac - 28925s 199ms/step - loss: - - 28961 - 28981s 199ms/s - 28999s 199ms/ - 29104s 199ms - 29 - 29175s 199ms/step - loss: 0.077 - 2917 - 29189s - 29208s 199ms/step - loss: 0.0770 - accura - 29221s 199ms/step - loss: 0.0770 - - 29224s 199ms/step - loss: 0.0770 - accurac - 29226s 199ms/step - loss: 0.0770 - accurac - 29228s 199ms/ste - 29267s 199ms/step - loss: 0.0770 - accuracy: 0.4 - 29267s 199ms/step - loss: 0.0770 - accuracy: 0.486 - 29267s 199ms/step - - 29274s 199ms/s - 29282s 199ms/step - loss:  - 29287s 199ms/step - loss: 0.0 - 29301s 199ms/step - l - 29307s 199ms/step - lo - 29313s -"
     ]
    }
   ],
   "source": [
    "tuner.search(train_D.__iter__(), epochs=50, validation_data=val_D.__iter__(), callbacks=[stop_early, tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train_D.__iter__(), epochs=50, validation_data=val_D.__iter__())\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(train_D.__iter__(), epochs=best_epoch, validation_data=val_D.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "[image-concat-query]-wwm_uncased_L12-768_v3_quart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
