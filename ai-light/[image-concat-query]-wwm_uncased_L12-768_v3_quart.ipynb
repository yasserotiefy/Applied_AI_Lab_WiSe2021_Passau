{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASY11viGC-CR"
   },
   "source": [
    "### Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 113094,
     "status": "ok",
     "timestamp": 1636221066554,
     "user": {
      "displayName": "Yasser Otiefy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64",
      "userId": "11606645386995589698"
     },
     "user_tz": -60
    },
    "id": "AQD3X56MDC41",
    "outputId": "98a56160-961f-40f1-c157-9853b2ad57b8"
   },
   "outputs": [],
   "source": [
    "# !pip install swifter pandas numpy\n",
    "# !pip install -q -U keras-tuner\n",
    "# !pip uninstall -y tensorflow-gpu keras keras-transformer keras_bert\n",
    "# !pip install tensorflow-gpu==1.14.0 keras==2.2.4 keras-transformer==0.33.0 keras_bert==0.78.0 \n",
    "# !pip install tensorflow-gpu keras keras-transformer keras_bert tensorflow-ranking\n",
    "# !pip install pydot pydotplus\n",
    "# !pip install h5py==2.10.0 --force-reinstall\n",
    "# !apt-get install graphviz -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8GPhl_YBO9X"
   },
   "source": [
    "### Download required embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpdWSjMNR18V"
   },
   "outputs": [],
   "source": [
    "# !wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip data/\n",
    "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip data/\n",
    "# !wget https://nlp.stanford.edu/data/glove.840B.300d.zip data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wI8SduklTKXO"
   },
   "outputs": [],
   "source": [
    "# !unzip data/uncased_L-12_H-768_A-12.zip \n",
    "# !unzip data/crawl-300d-2M.vec.zip\n",
    "# !unzip data/glove.840B.300d.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vp6skypuClUf"
   },
   "source": [
    "### Run Preprocessing File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnDeHDjqCqPX"
   },
   "outputs": [],
   "source": [
    "# !python preprocess.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh7BB7hTBKOs"
   },
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1636209799226,
     "user": {
      "displayName": "Yasser Otiefy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64",
      "userId": "11606645386995589698"
     },
     "user_tz": -60
    },
    "id": "qtsQ8SovAr4v",
    "outputId": "cec16143-f0a5-4dc7-b4e6-85204f1e9bfb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import choice, seed\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, CuDNNLSTM as LSTM, Dropout, BatchNormalization\n",
    "from keras.layers import Dense, Concatenate, Embedding, Bidirectional, Lambda, Conv1D\n",
    "from keras.layers import Add, TimeDistributed, GlobalMaxPooling1D\n",
    "from keras.optimizers import nadam_v2 as Nadam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import Callback\n",
    "import keras.backend as K\n",
    "import keras\n",
    "from keras_bert.loader import load_trained_model_from_checkpoint\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras_bert import get_custom_objects\n",
    "from keras_bert import Tokenizer\n",
    "from collections import defaultdict\n",
    "from eval import read_submission, get_ndcg\n",
    "from tqdm import trange\n",
    "import pickle\n",
    "import dask.dataframe as dd\n",
    "import joblib\n",
    "\n",
    "\n",
    "BERT_PRETRAINED_DIR = \"/root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/uncased_L-12_H-768_A-12\"\n",
    "VAL_ANS_PATH = '/root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/valid_answer.json'\n",
    "LABEL_PATH = '/root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/multimodal_labels.txt'\n",
    "\n",
    "MAX_EPOCH = 20\n",
    "MAX_LEN = 10\n",
    "B_SIZE = 256\n",
    "FOLD_IDS = [-1]\n",
    "FOLD_NUM = 20\n",
    "THRE = 0.5\n",
    "SHUFFLE = True\n",
    "MAX_BOX = 5\n",
    "MAX_CHAR = 5\n",
    "PREFIX = \"[image-bert-concat-query]-wwm_uncased_L12-768_v3_1M_example\"\n",
    "SEED = 2021\n",
    "ACCUM_STEP = int(128 // B_SIZE)\n",
    "SAVE_EPOCHS=[10, 20, 35, 50, 80, 100]\n",
    "IMAGE_LABEM_CONCAT_TOKEN = \"###\"\n",
    "CONCAT_TOKE = \"[unused0]\"\n",
    "\n",
    "cfg = {}\n",
    "cfg[\"verbose\"] = PREFIX\n",
    "cfg[\"base_dir\"] = BERT_PRETRAINED_DIR\n",
    "cfg['maxlen'] = MAX_LEN\n",
    "cfg[\"max_box\"] = MAX_BOX\n",
    "cfg[\"max_char\"] = MAX_CHAR\n",
    "cfg[\"lr\"] = 1e-4\n",
    "cfg['min_lr'] = 6e-8\n",
    "cfg[\"opt\"] = \"nadam\"\n",
    "cfg[\"loss_w\"] =  20.\n",
    "cfg[\"trainable\"] = True\n",
    "cfg[\"bert_trainable\"] = True\n",
    "cfg[\"mix_mode\"] = \"\"   # add concat average\n",
    "cfg[\"unit1_1\"] = 128\n",
    "cfg[\"accum_step\"] = ACCUM_STEP\n",
    "cfg[\"cls_num\"] = 2\n",
    "cfg[\"raw_filename\"] = \"{}_{}oof{}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rqxc8sS8Ar43"
   },
   "outputs": [],
   "source": [
    "def get_vocab():\n",
    "    \n",
    "    if \"albert\"in cfg[\"verbose\"].lower():\n",
    "        dict_path = os.path.join(BERT_PRETRAINED_DIR, 'vocab_chinese.txt')\n",
    "    else:\n",
    "        dict_path = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
    "    with open(dict_path, mode=\"r\", encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [l.strip() for l in lines]\n",
    "\n",
    "    word_index = {v: k  for k, v in enumerate(lines)}\n",
    "    return word_index\n",
    "\n",
    "\n",
    "word_index = get_vocab()\n",
    "cfg[\"x_pad\"] = word_index[\"[PAD]\"]\n",
    "tokenizer = Tokenizer(word_index)\n",
    "\n",
    "\n",
    "def get_label(path):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        label2id = {l.split('\\n')[0].split('\\t')[1]:int(l.split('\\n')[0].split('\\t')[0]) for l in lines[1:]}\n",
    "        id2label = {int(l.split('\\n')[0].split('\\t')[0]):l.split('\\n')[0].split('\\t')[1] for l in lines[1:]}\n",
    "    return label2id, id2label\n",
    "\n",
    "\n",
    "label2id, id2label = get_label(LABEL_PATH)\n",
    "label_set = set(label2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/train_data.pkl', 'rb') as outp:\n",
    "#     train_data= joblib.load(outp)\n",
    "# 100K sample\n",
    "with open('data/sample_train_data.pkl', 'rb') as outp:\n",
    "    train_data = joblib.load(outp)\n",
    "\n",
    "with open(\"data/sample_val.pkl\", \"rb\") as f:\n",
    "    val_data = joblib.load(f)\n",
    "\n",
    "# with open('data/val_data.pkl', 'rb') as outp:\n",
    "#     val_data = pickle.load(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pMZVTqarAr46"
   },
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype=np.float16)\n",
    "\n",
    "\n",
    "def load_embed(path, dim=300, word_index=None):\n",
    "    embedding_index = {}\n",
    "    with open(path, mode=\"r\", encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            l = l.strip().split()\n",
    "            word, arr = l[0], l[1:]\n",
    "            if len(arr) != dim:\n",
    "                print(\"[!] l = {}\".format(l))\n",
    "                continue\n",
    "            if word_index and word not in word_index:\n",
    "                continue\n",
    "            word, arr = get_coefs(word, arr)\n",
    "            embedding_index[word] = arr\n",
    "    return embedding_index\n",
    "\n",
    "\n",
    "def build_matrix(path, word_index=None, max_features=None, dim=300):\n",
    "    embedding_index = load_embed(path, dim=dim, word_index=word_index)\n",
    "    max_features = len(word_index) + 1 if max_features is None else max_features \n",
    "    embedding_matrix = np.zeros((max_features + 1, dim))\n",
    "    unknown_words = []\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i <= max_features:\n",
    "            try:\n",
    "                embedding_matrix[i] = embedding_index[word]\n",
    "            except KeyError:\n",
    "                unknown_words.append(word)\n",
    "    return embedding_matrix, unknown_words\n",
    "\n",
    "\n",
    "def load_word_embed(word_embed_glove=\"data/glove.840B.300d.txt\", \n",
    "                    word_embed_crawl=\"data/crawl-300d-2M.vec\",\n",
    "               save_filename=\"word_embedding_matrix\",\n",
    "               word_index=None):\n",
    "    \"\"\"\n",
    "    (30524, 300) 7590\n",
    "    (30524, 300) 7218\n",
    "    \"\"\"    \n",
    "    if os.path.exists(save_filename + \".npy\"):\n",
    "        word_embedding_matrix = np.load(save_filename + \".npy\").astype(\"float32\")\n",
    "    else:\n",
    "        word_embedding_matrix, _ = build_matrix(word_embed_glove, word_index=word_index, dim=300)\n",
    "        word_embedding_matrix_v2, _ = build_matrix(word_embed_crawl, word_index=word_index, dim=300)\n",
    "        word_embedding_matrix = np.concatenate([word_embedding_matrix, word_embedding_matrix_v2], axis=1)\n",
    "        \n",
    "        gc.collect()\n",
    "        np.save(save_filename, word_embedding_matrix)\n",
    "    return word_embedding_matrix\n",
    "\n",
    "\n",
    "word_embedding_matrix = load_word_embed(word_index=word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tHoD4ogMAr47"
   },
   "outputs": [],
   "source": [
    "def build_model(cfg, summary=False, word_embedding_matrix=None):\n",
    "    \n",
    "    def _get_model(base_dir, cfg_=None):\n",
    "        config_file = os.path.join(base_dir, 'bert_config.json')\n",
    "        checkpoint_file = os.path.join(base_dir, 'bert_model.ckpt')\n",
    "        if not os.path.exists(config_file):\n",
    "            config_file = os.path.join(base_dir, 'bert_config_large.json')\n",
    "            checkpoint_file = os.path.join(base_dir, 'roberta_l24_large_model')\n",
    "        # print(config_file, checkpoint_file)\n",
    "        model = load_trained_model_from_checkpoint(config_file, \n",
    "                                           checkpoint_file, \n",
    "                                           training=False, \n",
    "                                           trainable=cfg_[\"bert_trainable\"], \n",
    "                                           output_layer_num=cfg[\"cls_num\"],\n",
    "                                           seq_len=None)\n",
    "        return model\n",
    "    \n",
    "    def get_opt(num_example, warmup_proportion=0.1, lr=2e-5, min_lr=None):\n",
    "        if cfg[\"opt\"].lower() == \"nadam\":\n",
    "            opt = Nadam(lr=lr)\n",
    "        else:\n",
    "            total_steps, warmup_steps = calc_train_steps(\n",
    "                num_example=num_example,\n",
    "                batch_size=B_SIZE,\n",
    "                epochs=MAX_EPOCH,\n",
    "                warmup_proportion=warmup_proportion,\n",
    "            )\n",
    "\n",
    "            opt = AdamWarmup(total_steps, warmup_steps, lr=lr, min_lr=min_lr)\n",
    "\n",
    "        return opt\n",
    "\n",
    "    model1 = _get_model(cfg[\"base_dir\"], cfg)\n",
    "    model1 = Model(inputs=model1.inputs[: 2], outputs=model1.layers[-7].output)\n",
    "\n",
    "    if word_embedding_matrix is not None:\n",
    "        embed_layer = Embedding(input_dim=word_embedding_matrix.shape[0], \n",
    "                                output_dim=word_embedding_matrix.shape[1],\n",
    "                                weights=[word_embedding_matrix],\n",
    "                                trainable=cfg[\"trainable\"],\n",
    "                                name=\"embed_layer\"\n",
    "                         )\n",
    "        \n",
    "    inp_token1 = Input(shape=(None, ), dtype=np.int32, name=\"query_token_input\")\n",
    "    inp_segm1 = Input(shape=(None, ), dtype=np.float32, name=\"query_segm_input\")\n",
    "      \n",
    "    \n",
    "    inp_image = Input(shape=(None, 2048), dtype=np.float32, name=\"image_input\")\n",
    "    inp_image_mask = Input(shape=(None, ), dtype=np.float32, name=\"image_mask_input\")\n",
    "    inp_pos = Input(shape=(None, 5), dtype=np.float32, name=\"image_pos_input\")        \n",
    "    inp_image_char = Input(shape=(None, cfg[\"max_char\"]), dtype=np.int32, name='image_char_input')\n",
    "    \n",
    "    \n",
    "    mask = Lambda(lambda x: K.cast(K.not_equal(x, cfg[\"x_pad\"]), 'float32'), name=\"token_mask\")(inp_token1)\n",
    "    word_embed = embed_layer(inp_token1)\n",
    "    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n",
    "    word_embed = Bidirectional(LSTM(cfg[\"unit1_1\"], return_sequences=True), merge_mode=\"sum\")(word_embed)\n",
    "    word_embed = BatchNormalization()(word_embed)\n",
    "    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n",
    "\n",
    "    sequence_output = model1([inp_token1, inp_segm1])\n",
    "    sequence_output = Concatenate(axis=-1)([sequence_output, word_embed])\n",
    "    text_pool = Lambda(lambda x: x[:, 0, :])(sequence_output)\n",
    "\n",
    "    # Share weights of character-level embedding for premise and hypothesis\n",
    "    character_embedding_layer = TimeDistributed(Sequential([\n",
    "        embed_layer,\n",
    "        # Embedding(input_dim=100, output_dim=char_embedding_size, input_length=chars_per_word),\n",
    "        Conv1D(filters=128, kernel_size=3, name=\"char_embed_conv1d\"),\n",
    "        GlobalMaxPooling1D()\n",
    "    ]), name='CharEmbedding')\n",
    "    character_embedding_layer.build(input_shape=(None, None, cfg[\"max_char\"]))\n",
    "    image_char_embed  = character_embedding_layer(inp_image_char)    \n",
    "    image_embed = Concatenate(axis=-1)([image_char_embed, inp_image])    \n",
    "    image_embed = Dense(256, activation='relu', name='image_embed')(image_embed)\n",
    "    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n",
    "    pos_embed = Dense(256, activation='relu', name='pos_embed')(inp_pos)\n",
    "    pos_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([pos_embed, inp_image_mask])\n",
    "    embed = Add()([image_embed , pos_embed]) # batch, maxlen(10), 1024+128\n",
    "    \n",
    "    image_embed = Bidirectional(LSTM(512, return_sequences=True), merge_mode=\"sum\")(embed)\n",
    "    image_embed = BatchNormalization()(image_embed)\n",
    "    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n",
    "    \n",
    "    image_pool = Lambda(lambda x: x[:, 0, :])(image_embed)\n",
    "    \n",
    "    pool = Concatenate(axis=-1)([image_pool, text_pool])\n",
    "    pool = Dense(1024, activation=\"relu\")(pool)\n",
    "    pool = Dropout(0.3)(pool)\n",
    "    pool = Dense(512, activation=\"relu\")(pool)\n",
    "    pool = Dense(128, activation=\"relu\")(pool)\n",
    "    \n",
    "    output = Dense(2, activation='softmax', name='output')(pool)\n",
    "\n",
    "    opt = get_opt(num_example=cfg[\"num_example\"], lr=cfg['lr'], min_lr=cfg['min_lr'])\n",
    "    model = Model(inputs=[inp_token1, inp_segm1, \n",
    "                          inp_image, inp_image_mask,\n",
    "                          inp_pos, inp_image_char], outputs=[output])#\n",
    "    \n",
    "    model.compile(optimizer=opt, loss={\n",
    "                'output': 'sparse_categorical_crossentropy'\n",
    "            }, metrics=['accuracy'])\n",
    "    if summary:\n",
    "        model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dWGkWTgbAr48"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import base64\n",
    "\n",
    "\n",
    "def convertBoxes(num_boxes, boxes):\n",
    "    return np.frombuffer(base64.b64decode(boxes), dtype=np.float32).reshape(num_boxes, 4)\n",
    "def convertFeature(num_boxes, features,):\n",
    "    return np.frombuffer(base64.b64decode(features), dtype=np.float32).reshape(num_boxes, 2048)\n",
    "def convertLabel(num_boxes, label):\n",
    "    return np.frombuffer(base64.b64decode(label), dtype=np.int64).reshape(num_boxes)\n",
    "def convertLabelWord(num_boxes, label):\n",
    "    temp = np.frombuffer(base64.b64decode(label), dtype=np.int64).reshape(num_boxes)\n",
    "    return '###'.join([id2label[t] for t in temp])\n",
    "def convertPos(num_boxes, boxes, H, W):\n",
    "    pos_list = []\n",
    "    for i in range(num_boxes):\n",
    "        temp = boxes[i]\n",
    "        pos_list.append([temp[0]/W, \n",
    "                         temp[2]/W, \n",
    "                         temp[1]/H, \n",
    "                         temp[3]/H, \n",
    "                         ((temp[2] - temp[0]) * (temp[3] - temp[1]))/ (W*H),])\n",
    "    return pos_list\n",
    "\n",
    "\n",
    "def load_sample_data(path, frac=0.000001):\n",
    "    ### Data Sampling and decoding\n",
    "    train_data = dd.read_csv(path, sep='\\t', blocksize=25e6, quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "    \n",
    "    sample_train_data = train_data.sample(frac=frac).compute()\n",
    "    sample_train_data['words'] = sample_train_data['query']\n",
    "    sample_train_data['label_words'] = sample_train_data.apply(lambda x: convertLabelWord(x['num_boxes'], x['class_labels']), axis=1,meta= pd.Series([], dtype=str, name='label_words'))\n",
    "    sample_train_data['boxes_convert'] = sample_train_data.apply(lambda x: convertBoxes(x['num_boxes'], x['boxes']), axis=1, meta =pd.Series([], dtype=object, name='boxes_convert'))\n",
    "    sample_train_data['features'] = sample_train_data.apply(lambda x: convertFeature(x['num_boxes'], x['features']), axis=1, meta=pd.Series([], dtype=object, name='features'))\n",
    "    sample_train_data['pos'] = sample_train_data.apply(lambda x: convertPos(x['num_boxes'], x['boxes_convert'], x['image_h'], x['image_w']), axis=1, meta=pd.Series([], dtype=object, name='pos'))\n",
    "    return sample_train_data[['words', 'label_words', 'boxes_convert', 'features', 'pos']].compute()\n",
    "\n",
    "\n",
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            print(len(tokens_a))\n",
    "            tokens_b.pop()\n",
    "\n",
    "\n",
    "def token2id_X(X, x_dict, maxlen=None):\n",
    "    x = tokenizer.tokenize(X)\n",
    "    if maxlen:\n",
    "        x = x[: 1] + list(x)[1: maxlen - 1] + x[-1: ]     \n",
    "    seg = [0 for _ in x]\n",
    "    token = list(x)\n",
    "    x = [x_dict[e] if e in x_dict else x_dict[\"[UNK]\"] for e in token]\n",
    "    assert len(x) == len(seg)\n",
    "    return x, seg\n",
    "\n",
    "\n",
    "def seq_padding(X, maxlen=None, padding_value=None, debug=False):\n",
    "    L = [len(x) for x in X]\n",
    "    if maxlen is None:\n",
    "        maxlen = max(L)\n",
    "\n",
    "    pad_X = np.array([\n",
    "        np.concatenate([x, [padding_value] * (maxlen - len(x))]) if len(x) < maxlen else x[: maxlen] for x in X\n",
    "    ])\n",
    "    if debug:\n",
    "        print(\"[!] before pading {}\\n\".format(X))\n",
    "        print(\"[!] after pading {}\\n\".format(pad_X))\n",
    "    return pad_X\n",
    "    \n",
    "\n",
    "def MyChoice(Myset):\n",
    "    result = []\n",
    "    for i in Myset:\n",
    "        temp_set = set()\n",
    "        temp_set.add(i)\n",
    "        cho = choice(list(Myset - temp_set))\n",
    "        result.append(cho)\n",
    "    return result\n",
    "\n",
    "\n",
    "class data_generator:\n",
    "    \n",
    "    def __init__(self, data, batch_size=B_SIZE, shuffle=SHUFFLE):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = len(self.data) // self.batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        if len(self.data) % self.batch_size != 0:\n",
    "            self.steps += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "    \n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        inp_token1,\n",
    "        inp_segm1,\n",
    "        inp_image,\n",
    "        inp_image_mask,\n",
    "        inp_pos, \n",
    "        inp_image_char\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        while True:\n",
    "            idxs = list(range(len(self.data)))\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(idxs)\n",
    "            T1, T2, Image1, Pos1, label_word_list, image1_mask, image1_char = [], [], [], [], [], [], []\n",
    "            S1, S2, Image2, Pos2, image2_mask, image2_char = [], [], [], [], [], [] # 负样本\n",
    "            Id_set = set()\n",
    "\n",
    "            for i in idxs:\n",
    "                d = self.data.iloc[i]\n",
    "                text = d['words']\n",
    "                label_words = d['label_words']\n",
    "                \n",
    "                t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n",
    "                image = np.array(d['features'], dtype=\"float32\")\n",
    "                image = image[: cfg[\"max_box\"]]\n",
    "                img_mask = [1 for _ in image[: cfg[\"max_box\"]]]\n",
    "                \n",
    "                pos = np.array(d['pos'], dtype=\"float32\")\n",
    "                pos = pos[: cfg[\"max_box\"]]\n",
    "                \n",
    "                image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n",
    "                image_char = image_char[: cfg[\"max_box\"]]\n",
    "                # print(\"image_char\", len(image_char))\n",
    "                image_char = pad_sequences(image_char, \n",
    "                                           maxlen=cfg[\"max_char\"], \n",
    "                                           dtype='int32',\n",
    "                                           padding='post',\n",
    "                                           truncating='post',\n",
    "                                           value=cfg[\"x_pad\"])\n",
    "                \n",
    "                assert image.shape[0] == pos.shape[0]\n",
    "                assert image.shape[0] == cfg[\"max_box\"] or image.shape[0] == len(label_words.split(IMAGE_LABEM_CONCAT_TOKEN))\n",
    "                assert image_char.shape == (image.shape[0], cfg[\"max_char\"])\n",
    "\n",
    "                T1.append(t1)\n",
    "                T2.append(t2)\n",
    "                Image1.append(image)\n",
    "                image1_mask.append(img_mask)  \n",
    "                Pos1.append(pos)\n",
    "                image1_char.append(image_char)\n",
    "                Id_set.add(i)\n",
    "\n",
    "                if len(T1) == self.batch_size//2 or i == idxs[-1]:\n",
    "                    ## 加入负样本\n",
    "                    Id_new = MyChoice(Id_set)\n",
    "#                     print(Id_set, Id_new)\n",
    "                    for i, id_ in enumerate(Id_new):\n",
    "                        d_new = self.data.iloc[id_]\n",
    "                        text = d_new['words']\n",
    "                        t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n",
    "                        S1.append(t1)\n",
    "                        S2.append(t2)\n",
    "                        \n",
    "                        image = Image1[i]\n",
    "                        img_mask = image1_mask[i]\n",
    "                        pos = Pos1[i]\n",
    "                        image_char = image1_char[i]\n",
    "                        \n",
    "                        Image2.append(image)\n",
    "                        Pos2.append(pos)\n",
    "                        image2_mask.append(img_mask)\n",
    "                        image2_char.append(image_char)\n",
    "                    \n",
    "                    Y = [1] * len(T1) + [0] * len(S1)\n",
    "                   \n",
    "                    T1 = seq_padding(T1 + S1, padding_value=cfg[\"x_pad\"]) \n",
    "                    T2 = seq_padding(T2 + S2, padding_value=cfg[\"x_pad\"])\n",
    "                    \n",
    "                    Image1 = seq_padding(Image1 + Image2, \n",
    "                                         padding_value=np.zeros(shape=(2048, ))\n",
    "                                        )\n",
    "                                                         \n",
    "                    Pos1 = seq_padding(Pos1 + Pos2,\n",
    "                                       padding_value=np.zeros(shape=(5, ))\n",
    "                                      )\n",
    "                    image1_mask = seq_padding(image1_mask + image2_mask,\n",
    "                                             padding_value=0)\n",
    "                    \n",
    "                    image1_char = seq_padding(image1_char + image2_char,\n",
    "                                             padding_value=np.zeros(shape=(cfg[\"max_char\"])), debug=False)\n",
    "                    \n",
    "                    Y = np.array(Y).reshape((len(T1), -1))\n",
    "                    \n",
    "                    idx = np.arange(len(T1))\n",
    "                    np.random.shuffle(idx)\n",
    "        \n",
    "                    T1 = T1[idx]\n",
    "                    T2 = T2[idx]\n",
    "                    Image1 = Image1[idx]\n",
    "                    image1_mask = image1_mask[idx]\n",
    "                    Pos1 = Pos1[idx]\n",
    "                    image1_char = image1_char[idx]\n",
    "                    Y = Y[idx]\n",
    "                    \n",
    "                    yield [T1, T2, Image1, image1_mask, Pos1, image1_char], Y\n",
    "                    T1, T2, Image1, Pos1, label_word_list, image1_mask, image1_char = [], [], [], [], [], [], []\n",
    "                    S1, S2, Image2, Pos2, image2_mask, image2_char = [], [], [], [], [], [] # 负样本\n",
    "                    Id_set = set()\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "cSFjbRg6Ar5A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n",
      "x (256, 10) (256, 10) (256, 5, 2048) (256, 5) (256, 5, 5) (256, 5, 5) (256, 1)\n"
     ]
    }
   ],
   "source": [
    "train_D = data_generator(train_data)\n",
    "val_D = data_generator(val_data)\n",
    "_i  = 0\n",
    "for d in train_D:\n",
    "    _i += 1\n",
    "    if  _i > 10:\n",
    "        break\n",
    "    print('x',d[0][0].shape, d[0][1].shape,d[0][2].shape, d[0][3].shape, d[0][4].shape, d[0][5].shape, d[1].shape)\n",
    "\n",
    "_i  = 0\n",
    "for d in val_D:\n",
    "    _i += 1\n",
    "    if  _i > 10:\n",
    "        break\n",
    "    print('x',d[0][0].shape, d[0][1].shape,d[0][2].shape, d[0][3].shape, d[0][4].shape, d[0][5].shape, d[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wK6_y8irAr5C"
   },
   "outputs": [],
   "source": [
    "class Evaluate(Callback):\n",
    "    def __init__(self, filename=None):\n",
    "        self.score = []\n",
    "        self.best = 0.\n",
    "        self.filename = filename\n",
    "       \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch ==  0:\n",
    "            print(\"[!] test load&save model\")\n",
    "            f = self.filename + \".h5\"\n",
    "            custom_objects = get_custom_objects()\n",
    "            self.model.save(f, include_optimizer=False, overwrite=True)\n",
    "            if \"bert\" in cfg[\"verbose\"]:\n",
    "                model_ = load_model(f, custom_objects=custom_objects)  \n",
    "            else:\n",
    "                model_ = load_model(f) \n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "#         if epoch + 1 < 5:\n",
    "#             return\n",
    "        score = self.evaluate(self.model)\n",
    "        self.score.append((epoch, score))\n",
    "        \n",
    "        if epoch + 1 in SAVE_EPOCHS:\n",
    "            self.model.save(self.filename + \"_{}.h5\".format(epoch + 1), include_optimizer=False, overwrite=True)             \n",
    "        if score > self.best:\n",
    "            self.model.save(self.filename + \".h5\", include_optimizer=False)\n",
    "            \n",
    "        if score > self.best:\n",
    "            self.best = score\n",
    "            print(\"[!] epoch = {}, new NDCG best score = {}\".format(epoch + 1,  score))\n",
    "        print('[!] epoch = {}, score = {}, NDCG best score: {}\\n'.format(epoch + 1, score, self.best))\n",
    "\n",
    "    def eval_preprocess(self, row):\n",
    "\n",
    "            d = row\n",
    "            text = d['query']\n",
    "            label_words = d['label_words']\n",
    "            t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n",
    "            \n",
    "            image = np.array(d['feature_convert'], dtype=\"float32\")\n",
    "            image = image[: cfg[\"max_box\"]]\n",
    "            img_mask = [1 for _ in image[: cfg[\"max_box\"]]]                   \n",
    "            pos = np.array(d['pos'], dtype=\"float32\")\n",
    "            pos = pos[: cfg[\"max_box\"]]\n",
    "            \n",
    "            image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n",
    "            image_char = image_char[: cfg[\"max_box\"]]\n",
    "            image_char = pad_sequences(image_char, \n",
    "                                       maxlen=cfg[\"max_char\"], \n",
    "                                       dtype='int32',\n",
    "                                       padding='post',\n",
    "                                       truncating='post',\n",
    "                                       value=cfg[\"x_pad\"])\n",
    "            output = self.model.predict([np.asarray([t1]), np.asarray([t2]), np.asarray([image]), np.asarray([img_mask]), np.asarray([pos]), np.asarray([image_char])])\n",
    "            return output\n",
    "\n",
    "\n",
    "    def evaluate(self, model):\n",
    "        self.model = model\n",
    "        result = defaultdict(list)\n",
    "        val_results = val_data.apply(self.eval_preprocess, axis=1)\n",
    "        qid = val_data[\"query_id\"].values\n",
    "        pid = val_data[\"product_id\"].values\n",
    "\n",
    "\n",
    "        for i in trange(len(val_data)): \n",
    "            result[qid[i]].append((pid[i], val_results[i][0][1]))\n",
    "            \n",
    "        query_id,product1,product2,product3,product4,product5 = [],[],[],[],[],[]\n",
    "        for key in result.keys():\n",
    "            rlist = result[key]\n",
    "            rlist.sort(key=lambda x: x[1], reverse=True)\n",
    "            query_id.append(key)\n",
    "            product1.append(rlist[0][0])\n",
    "            product2.append(rlist[1][0])\n",
    "            product3.append(rlist[2][0])\n",
    "            product4.append(rlist[3][0])\n",
    "            product5.append(rlist[4][0])\n",
    "        sub = pd.DataFrame({'query-id':query_id,\n",
    "                            'product1':product1,\n",
    "                            'product2':product2,\n",
    "                            'product3':product3,\n",
    "                            'product4':product4,\n",
    "                            'product5':product5,\n",
    "\n",
    "        })\n",
    "        sub.to_csv('result/val_submission.csv',index=0)\n",
    "        \n",
    "        reference = json.load(open(VAL_ANS_PATH))\n",
    "        \n",
    "        # read predictions\n",
    "        k = 5\n",
    "        predictions = read_submission('result/val_submission.csv', reference, k)\n",
    "\n",
    "        # compute score for each query\n",
    "        score_sum = 0.\n",
    "        for qid in reference.keys():\n",
    "            ground_truth_ids = set([str(pid) for pid in reference[qid]])\n",
    "            ref_vec = [1.0] * len(ground_truth_ids)\n",
    "            pred_vec = [1.0 if pid in ground_truth_ids else 0.0 for pid in predictions[qid]]\n",
    "            score_sum += get_ndcg(pred_vec, ref_vec, k)\n",
    "        # the higher score, the better\n",
    "        score = score_sum / len(reference)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0U5XAi6Ar5D"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10148921,
     "status": "ok",
     "timestamp": 1636219971941,
     "user": {
      "displayName": "Yasser Otiefy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64",
      "userId": "11606645386995589698"
     },
     "user_tz": -60
    },
    "id": "-8khJgNZAr5F",
    "outputId": "a957f6b0-64b7-4ed2-98e0-788e46c9bf66",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "gc.collect()\n",
    "fold_id = -1\n",
    "print(\"\\n\\n[!] fold_id = {} starting\".format(fold_id))\n",
    "cfg[\"filename\"] = cfg[\"raw_filename\"].format(cfg[\"verbose\"], FOLD_NUM, fold_id)\n",
    "\n",
    "\n",
    "cfg[\"num_example\"] = len(train_data)\n",
    "print(len(train_data))\n",
    "\n",
    "tf.compat.v1.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "seed(SEED - fold_id)\n",
    "np.random.seed(SEED - fold_id)\n",
    "tf.compat.v1.random.set_random_seed(SEED - fold_id)\n",
    "train_D = data_generator(train_data)\n",
    "print(cfg)\n",
    "model = build_model(cfg, summary=True, \n",
    "                    word_embedding_matrix=word_embedding_matrix,\n",
    "                    )\n",
    "tf.keras.utils.plot_model(model, to_file=\"models/model_v1.png\", show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OvOGGA_tP8F"
   },
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U73CNxpCtVUY"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "evaluator = Evaluate(filename=cfg[\"filename\"])\n",
    "log_dir = \"logs/fit/1M_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.compat.v1.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(train_D.__iter__(),\n",
    "                          steps_per_epoch=len(train_D),\n",
    "                          epochs=MAX_EPOCH,\n",
    "                          callbacks=[evaluator, tensorboard_callback],\n",
    "                          shuffle=True\n",
    "                          )\n",
    "print(\"\\n\\n[!] fold_id = {} finish\".format(fold_id))\n",
    "del model, evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUo7uyS6Ar5G",
    "scrolled": true
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73205,
     "status": "ok",
     "timestamp": 1636220046397,
     "user": {
      "displayName": "Yasser Otiefy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64",
      "userId": "11606645386995589698"
     },
     "user_tz": -60
    },
    "id": "8yAEZS7dAr5G",
    "outputId": "ff7ac5dd-b2e5-4095-ef2e-f206020b4592"
   },
   "outputs": [],
   "source": [
    "with open('data/testA_data.pkl', 'rb') as outp:\n",
    "    test_data = pickle.load(outp)\n",
    "\n",
    "f = cfg[\"filename\"] + \".h5\"\n",
    "print(f)\n",
    "if \"bert\" in cfg[\"verbose\"]:\n",
    "    custom_objects = get_custom_objects()\n",
    "    model = load_model(f, custom_objects=custom_objects)  \n",
    "else:\n",
    "    model = load_model(f)\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ct2eCmYhAr5H"
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "result = defaultdict(list)\n",
    "for i in trange(len(test_data)):\n",
    "    d = test_data.iloc[i]\n",
    "    qid = d['query_id']\n",
    "    pid = d['product_id']\n",
    "    text = d['query']\n",
    "    label_words = d['label_words']\n",
    "    t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n",
    "\n",
    "    image = np.array(d['feature_convert'], dtype=\"float32\")\n",
    "    image = image[: cfg[\"max_box\"]]\n",
    "    img_mask = [1 for _ in image[: cfg[\"max_box\"]]]                   \n",
    "    pos = np.array(d['pos'], dtype=\"float32\")\n",
    "    pos = pos[: cfg[\"max_box\"]]\n",
    "\n",
    "    image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n",
    "    image_char = image_char[: cfg[\"max_box\"]]\n",
    "    image_char = pad_sequences(image_char, \n",
    "                               maxlen=cfg[\"max_char\"], \n",
    "                               dtype='int32',\n",
    "                               padding='post',\n",
    "                               truncating='post',\n",
    "                               value=cfg[\"x_pad\"]) \n",
    "    output = model.predict([np.asarray([t1]), np.asarray([t2]), np.asarray([image]), np.asarray([img_mask]), np.asarray([pos]), np.asarray([image_char])])\n",
    "    result[qid].append((pid, output[0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOWqYUaXAr5H"
   },
   "outputs": [],
   "source": [
    "query_id,product1,product2,product3,product4,product5 = [],[],[],[],[],[]\n",
    "for key in result.keys():\n",
    "    rlist = result[key]\n",
    "    rlist.sort(key=lambda x: x[1], reverse=True)\n",
    "    query_id.append(key)\n",
    "    product1.append(rlist[0][0])\n",
    "    product2.append(rlist[1][0])\n",
    "    product3.append(rlist[2][0])\n",
    "    product4.append(rlist[3][0])\n",
    "    product5.append(rlist[4][0])\n",
    "\n",
    "sub = pd.DataFrame({'query-id':query_id,\n",
    "                    'product1':product1,\n",
    "                    'product2':product2,\n",
    "                    'product3':product3,\n",
    "                    'product4':product4,\n",
    "                    'product5':product5,\n",
    "\n",
    "})\n",
    "\n",
    "sub.to_csv('result/submission_1M.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hjq_AYpAAr5I"
   },
   "outputs": [],
   "source": [
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecQVcr2zXytP"
   },
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1636222703249,
     "user": {
      "displayName": "Yasser Otiefy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64",
      "userId": "11606645386995589698"
     },
     "user_tz": -60
    },
    "id": "RR5AV6DQXyGN",
    "outputId": "938ec73d-ba80-493f-f6c5-2b6f41fb6faf"
   },
   "outputs": [],
   "source": [
    "!python eval.py data/testA_answer.json result/submission_1M.csv result/testA_result_1M.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    global cfg\n",
    "    \n",
    "    def _get_model(base_dir, cfg_=None):\n",
    "        config_file = os.path.join(base_dir, 'bert_config.json')\n",
    "        checkpoint_file = os.path.join(base_dir, 'bert_model.ckpt')\n",
    "        if not os.path.exists(config_file):\n",
    "            config_file = os.path.join(base_dir, 'bert_config_large.json')\n",
    "            checkpoint_file = os.path.join(base_dir, 'roberta_l24_large_model')\n",
    "        print(config_file, checkpoint_file)\n",
    "        model = load_trained_model_from_checkpoint(config_file, \n",
    "                                           checkpoint_file, \n",
    "                                           training=False, \n",
    "                                           trainable=cfg_[\"bert_trainable\"], \n",
    "                                           output_layer_num=cfg[\"cls_num\"],\n",
    "                                           seq_len=None)\n",
    "        return model\n",
    "    \n",
    "    def get_opt(num_example, warmup_proportion=0.1, lr=2e-5, min_lr=None):\n",
    "        if cfg[\"opt\"].lower() == \"nadam\":\n",
    "            opt = Nadam(lr=lr)\n",
    "        else:\n",
    "            total_steps, warmup_steps = calc_train_steps(\n",
    "                num_example=num_example,\n",
    "                batch_size=B_SIZE,\n",
    "                epochs=MAX_EPOCH,\n",
    "                warmup_proportion=warmup_proportion,\n",
    "            )\n",
    "\n",
    "            opt = AdamWarmup(total_steps, warmup_steps, lr=lr, min_lr=min_lr)\n",
    "\n",
    "        return opt\n",
    "\n",
    "    # model1 = _get_model(cfg[\"base_dir\"], cfg)\n",
    "    # model1 = Model(inputs=model1.inputs[: 2], outputs=model1.layers[-7].output)\n",
    "\n",
    "    global word_index\n",
    "    word_embedding_matrix = load_word_embed(word_index=word_index)\n",
    "    embed_layer = Embedding(input_dim=word_embedding_matrix.shape[0], \n",
    "                            output_dim=word_embedding_matrix.shape[1],\n",
    "                            weights=[word_embedding_matrix],\n",
    "                            trainable=cfg[\"trainable\"],\n",
    "                            name=\"embed_layer\"\n",
    "                        )\n",
    "        \n",
    "    inp_token1 = Input(shape=(None, ), dtype=np.int32, name=\"query_token_input\")\n",
    "    inp_segm1 = Input(shape=(None, ), dtype=np.float32, name=\"query_segm_input\")\n",
    "    \n",
    "#     inp_token2 = Input(shape=(None, ), dtype=np.int32)\n",
    "#     inp_segm2 = Input(shape=(None, ), dtype=np.float32)    \n",
    "    \n",
    "    inp_image = Input(shape=(None, 2048), dtype=np.float32, name=\"image_input\")\n",
    "    inp_image_mask = Input(shape=(None, ), dtype=np.float32, name=\"image_mask_input\")\n",
    "    inp_pos = Input(shape=(None, 5), dtype=np.float32, name=\"image_pos_input\")        \n",
    "    inp_image_char = Input(shape=(None, cfg[\"max_char\"]), dtype=np.int32, name='image_char_input')\n",
    "    \n",
    "    \n",
    "    mask = Lambda(lambda x: K.cast(K.not_equal(x, cfg[\"x_pad\"]), 'float32'), name=\"token_mask\")(inp_token1)\n",
    "    word_embed = embed_layer(inp_token1)\n",
    "    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n",
    "    word_embed = Bidirectional(LSTM(cfg[\"unit1_1\"], return_sequences=True), merge_mode=\"sum\")(word_embed)\n",
    "    word_embed = BatchNormalization()(word_embed)\n",
    "    # word_embed = Dropout(0.3)(word_embed)\n",
    "    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n",
    "\n",
    "    # sequence_output = model1([inp_token1, inp_segm1])\n",
    "    # sequence_output = Concatenate(axis=-1)([sequence_output, word_embed])\n",
    "    text_pool = Lambda(lambda x: x[:, 0, :])(word_embed)\n",
    "\n",
    "    # Share weights of character-level embedding for premise and hypothesis\n",
    "    character_embedding_layer = TimeDistributed(Sequential([\n",
    "        embed_layer,\n",
    "        # Embedding(input_dim=100, output_dim=char_embedding_size, input_length=chars_per_word),\n",
    "        Conv1D(filters=128, kernel_size=3, name=\"char_embed_conv1d\"),\n",
    "        GlobalMaxPooling1D()\n",
    "    ]), name='CharEmbedding')\n",
    "    character_embedding_layer.build(input_shape=(None, None, cfg[\"max_char\"]))\n",
    "    image_char_embed  = character_embedding_layer(inp_image_char)    \n",
    "    image_embed = Concatenate(axis=-1)([image_char_embed, inp_image])    \n",
    "    image_embed = Dense(256, activation='relu', name='image_embed')(image_embed)\n",
    "    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n",
    "    pos_embed = Dense(256, activation='relu', name='pos_embed')(inp_pos)\n",
    "    pos_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([pos_embed, inp_image_mask])\n",
    "    embed = Add()([image_embed , pos_embed]) # batch, maxlen(10), 1024+128\n",
    "    \n",
    "    image_embed = Bidirectional(LSTM(512, return_sequences=True), merge_mode=\"sum\")(embed)\n",
    "    image_embed = BatchNormalization()(image_embed)\n",
    "    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n",
    "    \n",
    "    image_pool = Lambda(lambda x: x[:, 0, :])(image_embed)\n",
    "    \n",
    "    pool = Concatenate(axis=-1)([image_pool, text_pool])\n",
    "\n",
    "    hp_units = hp.Int('units', min_value=64, max_value=2048, step=32)\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh', 'sigmoid', 'selu', 'elu'])\n",
    "    pool = Dense(hp_units, activation=hp_activation)(pool)\n",
    "    hp_dropout_prop = hp.Choice('dropout_prop', values=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "    pool = Dropout(hp_dropout_prop)(pool)\n",
    "    pool = Dense(hp_units, activation=hp_activation)(pool)\n",
    "    pool = Dense(hp_units, activation=hp_activation)(pool)\n",
    "    \n",
    "    output = Dense(2, activation='softmax', name='output')(pool)\n",
    "\n",
    "    model = Model(inputs=[inp_token1, inp_segm1, \n",
    "                          inp_image, inp_image_mask,\n",
    "                          inp_pos, inp_image_char], outputs=[output])#\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.compat.v1.keras.optimizers.Adam(learning_rate=hp_learning_rate), loss={\n",
    "                'output': 'sparse_categorical_crossentropy'\n",
    "            }, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "tf.compat.v1.random.set_random_seed(SEED)\n",
    "\n",
    "tuner = kt.RandomSearch(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_trials=50,\n",
    "                     directory='tmp/hyperparameter_tuning',\n",
    "                     project_name='multimodal_hyperparameter_tuning',\n",
    "                     overwrite=True,\n",
    "                     seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "log_dir = \"tmp/hparam_logs\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 03m 16s]\n",
      "val_accuracy: 1.0\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 03h 04m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_D.__iter__(), epochs=20, validation_data=val_D.__iter__(), callbacks=[stop_early, tensorboard_callback],\n",
    "            batch_size=1024, steps_per_epoch=len(train_D), validation_steps=len(val_D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir /tmp/hparam_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 320 and the optimal learning rate for the optimizer\n",
      "is 0.01.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 32s 727ms/step - loss: 1.1810 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 28s 717ms/step - loss: 0.6939 - accuracy: 0.5073 - val_loss: 0.6933 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 27s 691ms/step - loss: 0.6933 - accuracy: 0.6203 - val_loss: 0.6932 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 27s 698ms/step - loss: 0.6932 - accuracy: 0.5379 - val_loss: 0.6931 - val_accuracy: 0.9980\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 27s 682ms/step - loss: 0.6933 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 27s 689ms/step - loss: 0.6933 - accuracy: 0.4585 - val_loss: 0.6932 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 27s 687ms/step - loss: 0.6932 - accuracy: 0.4319 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 26s 669ms/step - loss: 0.6932 - accuracy: 0.5266 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 26s 677ms/step - loss: 0.6933 - accuracy: 0.4546 - val_loss: 0.6931 - val_accuracy: 0.6581\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 26s 675ms/step - loss: 0.6932 - accuracy: 0.3918 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 28s 703ms/step - loss: 0.6932 - accuracy: 0.4289 - val_loss: 0.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 27s 699ms/step - loss: 0.6932 - accuracy: 0.7723 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 26s 674ms/step - loss: 0.6931 - accuracy: 0.9331 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 27s 682ms/step - loss: 0.6931 - accuracy: 0.9165 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 26s 674ms/step - loss: 0.6932 - accuracy: 0.2904 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 26s 675ms/step - loss: 0.6932 - accuracy: 0.6007 - val_loss: 0.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 28s 703ms/step - loss: 0.6931 - accuracy: 0.1283 - val_loss: 0.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 27s 688ms/step - loss: 0.6932 - accuracy: 0.4128 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 27s 678ms/step - loss: 0.6931 - accuracy: 0.2844 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 27s 694ms/step - loss: 0.6931 - accuracy: 0.2642 - val_loss: 0.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 27s 701ms/step - loss: 0.6932 - accuracy: 0.6864 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 27s 684ms/step - loss: 0.6935 - accuracy: 0.4936 - val_loss: 0.6932 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 27s 695ms/step - loss: 0.6935 - accuracy: 0.3990 - val_loss: 0.6956 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 27s 678ms/step - loss: 0.6944 - accuracy: 0.5408 - val_loss: 0.6942 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 27s 691ms/step - loss: 0.6936 - accuracy: 0.3542 - val_loss: 0.6933 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 27s 684ms/step - loss: 0.6933 - accuracy: 0.4408 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 27s 702ms/step - loss: 0.6932 - accuracy: 0.6879 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 27s 683ms/step - loss: 0.6932 - accuracy: 0.4712 - val_loss: 0.6932 - val_accuracy: 0.5781\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 27s 690ms/step - loss: 0.6934 - accuracy: 0.6263 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 27s 693ms/step - loss: 0.6933 - accuracy: 0.4657 - val_loss: 0.6931 - val_accuracy: 4.9920e-05\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 27s 685ms/step - loss: 0.6932 - accuracy: 0.5360 - val_loss: 0.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 27s 694ms/step - loss: 0.6932 - accuracy: 0.7491 - val_loss: 0.6931 - val_accuracy: 0.9996\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 27s 698ms/step - loss: 0.6932 - accuracy: 0.8644 - val_loss: 0.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 26s 675ms/step - loss: 0.6932 - accuracy: 0.4615 - val_loss: 0.6931 - val_accuracy: 1.00000.6931 - accu - ETA: 0s - loss: 0.6931 - accuracy: 0.\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 28s 711ms/step - loss: 0.6931 - accuracy: 0.6809 - val_loss: 0.6932 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 27s 688ms/step - loss: 0.6932 - accuracy: 0.6207 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 26s 676ms/step - loss: 0.6931 - accuracy: 0.6127 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 27s 685ms/step - loss: 0.6932 - accuracy: 0.6762 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 26s 673ms/step - loss: 0.6931 - accuracy: 0.7236 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 27s 692ms/step - loss: 0.6932 - accuracy: 0.9323 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 27s 690ms/step - loss: 0.6931 - accuracy: 0.8734 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 27s 678ms/step - loss: 0.6931 - accuracy: 0.8807 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 27s 699ms/step - loss: 0.6932 - accuracy: 0.4463 - val_loss: 0.6932 - val_accuracy: 0.0000e+00uracy\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 27s 679ms/step - loss: 0.6932 - accuracy: 0.5755 - val_loss: 0.6932 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 27s 689ms/step - loss: 0.6932 - accuracy: 0.5066 - val_loss: 0.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 27s 686ms/step - loss: 0.6933 - accuracy: 0.2545 - val_loss: 0.6932 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 27s 701ms/step - loss: 0.6932 - accuracy: 0.5799 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 26s 674ms/step - loss: 0.6932 - accuracy: 0.6390 - val_loss: 0.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 26s 672ms/step - loss: 0.6932 - accuracy: 0.8013 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 27s 681ms/step - loss: 0.6931 - accuracy: 0.9646 - val_loss: 0.6931 - val_accuracy: 1.0000\n",
      "Best epoch: 1\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train_D.__iter__(), epochs=50, validation_data=val_D.__iter__(),\n",
    "batch_size=1024, steps_per_epoch=len(train_D), validation_steps=len(val_D))\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] test load&save model\n",
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.6763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 81354.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "[!] epoch = 1, new NDCG best score = 0.20283855755842342\n",
      "[!] epoch = 1, score = 0.20283855755842342, NDCG best score: 0.20283855755842342\n",
      "\n",
      "40/40 [==============================] - 1584s 41s/step - loss: 0.6931 - accuracy: 0.6763\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.9682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 87204.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "[!] epoch = 2, new NDCG best score = 0.20631023266244705\n",
      "[!] epoch = 2, score = 0.20631023266244705, NDCG best score: 0.20631023266244705\n",
      "\n",
      "40/40 [==============================] - 1592s 41s/step - loss: 0.6931 - accuracy: 0.9682\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.8662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 59646.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "[!] epoch = 3, new NDCG best score = 0.20938446715851433\n",
      "[!] epoch = 3, score = 0.20938446715851433, NDCG best score: 0.20938446715851433\n",
      "\n",
      "40/40 [==============================] - 1596s 41s/step - loss: 0.6932 - accuracy: 0.8662\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.8390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 69644.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 4, score = 0.2081444807715653, NDCG best score: 0.20938446715851433\n",
      "\n",
      "40/40 [==============================] - 1594s 41s/step - loss: 0.6932 - accuracy: 0.8390\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 88364.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 5, score = 0.20179497302263022, NDCG best score: 0.20938446715851433\n",
      "\n",
      "40/40 [==============================] - 1601s 41s/step - loss: 0.6931 - accuracy: 0.4006\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.6158 ETA: 1s - loss: 0.6931 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 69176.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 6, score = 0.20347145495109692, NDCG best score: 0.20938446715851433\n",
      "\n",
      "40/40 [==============================] - 1599s 41s/step - loss: 0.6931 - accuracy: 0.6158\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4594 ETA: 1s - loss: 0.6931 - accu"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 85149.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "[!] epoch = 7, new NDCG best score = 0.21409837602301246\n",
      "[!] epoch = 7, score = 0.21409837602301246, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1607s 41s/step - loss: 0.6931 - accuracy: 0.4594\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 84636.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 8, score = 0.21320434429617977, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1620s 42s/step - loss: 0.6931 - accuracy: 0.5034\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 87541.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 9, score = 0.2096240989026928, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1606s 41s/step - loss: 0.6931 - accuracy: 0.5936\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.6066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 117459.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 10, score = 0.21142028094015208, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1612s 41s/step - loss: 0.6931 - accuracy: 0.6066\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.7300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 81889.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 11, score = 0.2099959605457718, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1613s 41s/step - loss: 0.6931 - accuracy: 0.7300\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 85106.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 12, score = 0.20701001866667798, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1616s 41s/step - loss: 0.6931 - accuracy: 0.4598\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.2599 ETA: 1s - loss: 0.6931 - accu"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 109391.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 13, score = 0.20668838310726043, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1619s 42s/step - loss: 0.6931 - accuracy: 0.2599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.7027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 85216.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 14, score = 0.20661101410499338, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1622s 42s/step - loss: 0.6931 - accuracy: 0.7027\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.6862 ETA: 8s - loss: 0.6931 - accuracy - ETA: 7s - - ETA: 3s - los"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 62046.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 15, score = 0.21113990554226292, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1614s 41s/step - loss: 0.6931 - accuracy: 0.6862\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.9786"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 74526.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 16, score = 0.2106825746384644, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1628s 42s/step - loss: 0.6931 - accuracy: 0.9786\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.8807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 83404.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 17, score = 0.21362676096431177, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1621s 42s/step - loss: 0.6931 - accuracy: 0.8807\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.7754"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 87521.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 18, score = 0.20848211159877506, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1628s 42s/step - loss: 0.6931 - accuracy: 0.7754\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.9033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 117571.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] epoch = 19, score = 0.20764764214969902, NDCG best score: 0.21409837602301246\n",
      "\n",
      "40/40 [==============================] - 1623s 42s/step - loss: 0.6931 - accuracy: 0.9033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.9059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14720/14720 [00:00<00:00, 60030.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "[!] epoch = 20, new NDCG best score = 0.2142684258755416\n",
      "[!] epoch = 20, score = 0.2142684258755416, NDCG best score: 0.2142684258755416\n",
      "\n",
      "40/40 [==============================] - 1622s 42s/step - loss: 0.6931 - accuracy: 0.9059\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fold_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_730695/531193118.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                           )\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n[!] fold_id = {} finish\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fold_id' is not defined"
     ]
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "with open(\"data/val_data.pkl\", \"rb\") as f:\n",
    "    val_data = joblib.load(f)\n",
    "\n",
    "evaluator = Evaluate(filename=\"randomsearch_best_model\")\n",
    "log_dir = \"logs/fit/Randomsearch_best_hyparam\" \n",
    "tensorboard_callback = tf.compat.v1.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model.fit(train_D.__iter__(),\n",
    "                          steps_per_epoch=len(train_D),\n",
    "                          epochs=MAX_EPOCH,\n",
    "                          callbacks=[evaluator, tensorboard_callback],\n",
    "                          shuffle=True\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "[image-concat-query]-wwm_uncased_L12-768_v3_quart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
