{"cells":[{"cell_type":"markdown","metadata":{"id":"ASY11viGC-CR"},"source":["### Environment Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !apt-get update\n","# !apt install nvidia-cuda-toolkit -y"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":113094,"status":"ok","timestamp":1636221066554,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"AQD3X56MDC41","outputId":"98a56160-961f-40f1-c157-9853b2ad57b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow==1.13.1\n","  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n","     |████████████████████████████████| 92.6 MB 77 kB/s              \n","\u001b[?25hCollecting keras==2.2.4\n","  Using cached Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n","Collecting keras-transformer==0.33.0\n","  Using cached keras_transformer-0.33.0-py3-none-any.whl\n","Collecting keras_bert==0.78.0\n","  Using cached keras_bert-0.78.0-py3-none-any.whl\n","Requirement already satisfied: keras-applications>=1.0.6 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.0.8)\n","Requirement already satisfied: grpcio>=1.8.6 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.42.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.2)\n","Requirement already satisfied: numpy>=1.13.3 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.21.4)\n","Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.13.1)\n","Requirement already satisfied: astor>=0.6.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.8.1)\n","Requirement already satisfied: wheel>=0.26 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.37.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (3.19.1)\n","Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.13.0)\n","Requirement already satisfied: gast>=0.2.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.4.0)\n","Requirement already satisfied: six>=1.10.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.16.0)\n","Requirement already satisfied: pyyaml in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from keras==2.2.4) (6.0)\n","Requirement already satisfied: h5py in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from keras==2.2.4) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from keras==2.2.4) (1.7.3)\n","Requirement already satisfied: keras-multi-head>=0.22.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from keras-transformer==0.33.0) (0.28.0)\n","Requirement already satisfied: keras-pos-embd>=0.10.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from keras-transformer==0.33.0) (0.12.0)\n","Requirement already satisfied: keras-embed-sim>=0.7.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from keras-transformer==0.33.0) (0.9.0)\n","Requirement already satisfied: keras-position-wise-feed-forward>=0.5.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from keras-transformer==0.33.0) (0.7.0)\n","Requirement already satisfied: keras-layer-normalization>=0.12.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from keras-transformer==0.33.0) (0.15.0)\n","Requirement already satisfied: keras-self-attention>=0.50.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from keras-multi-head>=0.22.0->keras-transformer==0.33.0) (0.50.0)\n","Requirement already satisfied: markdown>=2.6.8 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (2.0.2)\n","Requirement already satisfied: mock>=2.0.0 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\n","Requirement already satisfied: importlib-metadata>=4.4 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.0.1)\n","Installing collected packages: keras, keras-transformer, tensorflow, keras-bert\n","Successfully installed keras-2.2.4 keras-bert-0.78.0 keras-transformer-0.33.0 tensorflow-1.13.1\n"]}],"source":["# !pip install swifter\n","# !pip uninstall -y tensorflow-gpu keras keras-transformer keras_bert\n","# !pip install tensorflow==1.13.1 keras==2.2.4 keras-transformer==0.33.0 keras_bert==0.78.0 \n","# !pip install tensorflow-gpu keras keras-transformer keras_bert\n","# !pip install pydot pydotplus\n","# !pip install h5py==2.10.0 --force-reinstall"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !apt-get install graphviz -y"]},{"cell_type":"markdown","metadata":{"id":"G8GPhl_YBO9X"},"source":["### Download required embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BpdWSjMNR18V"},"outputs":[],"source":["# !wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip data/\n","# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip data/\n","# !wget https://nlp.stanford.edu/data/glove.840B.300d.zip data/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wI8SduklTKXO"},"outputs":[],"source":["# !unzip data/uncased_L-12_H-768_A-12.zip \n","# !unzip data/crawl-300d-2M.vec.zip\n","# !unzip data/glove.840B.300d.zip "]},{"cell_type":"markdown","metadata":{"id":"Vp6skypuClUf"},"source":["### Run Preprocessing File"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dnDeHDjqCqPX"},"outputs":[],"source":["# !python preprocess.py"]},{"cell_type":"markdown","metadata":{"id":"Fh7BB7hTBKOs"},"source":["### Imports\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import tensorflow as tf\n","# tf.config.list_physical_devices(\"GPU\")"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":521,"status":"ok","timestamp":1636209799226,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"qtsQ8SovAr4v","outputId":"cec16143-f0a5-4dc7-b4e6-85204f1e9bfb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/root/.pyenv/versions/3.7.0/envs/team2_ai_light/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","Using TensorFlow backend.\n"]}],"source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","import gc\n","import json\n","import pandas as pd\n","import numpy as np\n","from random import choice, seed, shuffle, random, sample\n","import tensorflow as tf\n","import keras.backend.tensorflow_backend as KTF\n","from keras.models import Sequential, Model\n","from keras.layers import Input, CuDNNGRU as GRU, CuDNNLSTM, LSTM, Dropout, BatchNormalization\n","from keras.layers import Dense, Concatenate, Activation, Embedding, SpatialDropout1D, Bidirectional, Lambda, Conv1D\n","from keras.layers import Add, Average, TimeDistributed, GlobalMaxPooling1D\n","from keras.optimizers import Nadam, Adam, Adamax\n","from keras.activations import absolute_import\n","from keras.legacy import interfaces\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.callbacks import Callback\n","from keras.utils import to_categorical\n","import keras.backend as K\n","from keras.callbacks import ModelCheckpoint\n","import keras\n","from sklearn.model_selection import KFold\n","from keras.initializers import he_normal\n","# from keras_bert.bert import get_model\n","from keras_bert.loader import load_trained_model_from_checkpoint\n","from keras_bert import AdamWarmup, calc_train_steps\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.objectives import categorical_crossentropy\n","from keras.objectives import sparse_categorical_crossentropy\n","from keras import activations, initializers, regularizers, constraints\n","from keras.models import Model\n","from tqdm import tqdm\n","from model_utils import seq_gather, seq_and_vec, seq_maxpool\n","from keras.models import load_model\n","from keras_bert import get_custom_objects\n","from keras_bert import Tokenizer\n","from collections import defaultdict\n","from eval import read_submission, get_ndcg\n","from tqdm import tqdm, trange\n","import pickle\n","import joblib\n","\n","# gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n","# session = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n","\n","# my_devices = tf.config.experimental.list_physical_devices(device_type='CPU')\n","# tf.config.experimental.set_visible_devices(devices= my_devices, device_type='CPU')\n","# tf.config.set_visible_devices([], 'GPU')\n","\n","# sess = tf.compat.v1.Session()\n","\n","BERT_PRETRAINED_DIR = \"/root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/uncased_L-12_H-768_A-12\"\n","VAL_ANS_PATH = '/root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/valid_answer.json'\n","LABEL_PATH = '/root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/multimodal_labels.txt'\n","\n","MAX_EPOCH = 20\n","MAX_LEN = 20\n","B_SIZE = 128\n","FOLD_IDS = [-1]\n","FOLD_NUM = 20\n","THRE = 0.5\n","SHUFFLE = True\n","MAX_BOX = 10\n","MAX_CHAR = 8\n","PREFIX = \"[image-bert-concat-query]-wwm_uncased_L12-768_v3_quart\"\n","SEED = 2020\n","ACCUM_STEP = int(128 // B_SIZE)\n","SAVE_EPOCHS=[10, 20, 35, 50, 80, 100]\n","IMAGE_LABEM_CONCAT_TOKEN = \"###\"\n","CONCAT_TOKE = \"[unused0]\"\n","\n","cfg = {}\n","cfg[\"verbose\"] = PREFIX\n","cfg[\"base_dir\"] = BERT_PRETRAINED_DIR\n","cfg['maxlen'] = MAX_LEN\n","cfg[\"max_box\"] = MAX_BOX\n","cfg[\"max_char\"] = MAX_CHAR\n","cfg[\"lr\"] = 1e-4\n","cfg['min_lr'] = 6e-8\n","cfg[\"opt\"] = \"nadam\"\n","cfg[\"loss_w\"] =  20.\n","cfg[\"trainable\"] = True\n","cfg[\"bert_trainable\"] = True\n","cfg[\"mix_mode\"] = \"\"   # add concat average\n","cfg[\"unit1_1\"] = 128\n","cfg[\"accum_step\"] = ACCUM_STEP\n","cfg[\"cls_num\"] = 4\n","cfg[\"raw_filename\"] = \"{}_{}oof{}\"\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"rqxc8sS8Ar43"},"outputs":[],"source":["def get_vocab():\n","    if \"albert\"in cfg[\"verbose\"].lower():\n","        dict_path = os.path.join(BERT_PRETRAINED_DIR, 'vocab_chinese.txt')\n","    else:\n","        dict_path = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n","    with open(dict_path, mode=\"r\", encoding=\"utf8\") as f:\n","        lines = f.readlines()\n","        lines = [l.strip() for l in lines]\n","\n","    word_index = {v: k  for k, v in enumerate(lines)}\n","    return word_index\n","\n","\n","word_index = get_vocab()\n","cfg[\"x_pad\"] = word_index[\"[PAD]\"]\n","tokenizer = Tokenizer(word_index)\n","\n","\n","def get_label(path):\n","    with open(path) as f:\n","        lines = f.readlines()\n","        label2id = {l.split('\\n')[0].split('\\t')[1]:int(l.split('\\n')[0].split('\\t')[0]) for l in lines[1:]}\n","        id2label = {int(l.split('\\n')[0].split('\\t')[0]):l.split('\\n')[0].split('\\t')[1] for l in lines[1:]}\n","    return label2id, id2label\n","\n","\n","label2id, id2label = get_label(LABEL_PATH)\n","label_set = set(label2id.keys())"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"elapsed":16263,"status":"ok","timestamp":1636209821843,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"JxCVu3PpAr45","outputId":"a9ba4a30-eeac-4e60-9e18-887423c11f6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["10000 <class 'pandas.core.frame.DataFrame'>\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label_words</th>\n","      <th>features</th>\n","      <th>pos</th>\n","      <th>words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>624</th>\n","      <td>top clothes (coat, jacket, shirt, etc.)###huma...</td>\n","      <td>[[0.0, 0.0, 0.019117048, 0.0, 0.002718366, 0.3...</td>\n","      <td>[[0.1525, 0.99375, 0.19625, 0.8375, 0.53945156...</td>\n","      <td>sketch books</td>\n","    </tr>\n","    <tr>\n","      <th>8790</th>\n","      <td>shoes###shoes###shoes###shoes###bottom clothes...</td>\n","      <td>[[0.0, 0.0, 0.0, 0.00648563, 0.0, 0.0, 0.0, 0....</td>\n","      <td>[[0.59625, 0.955, 0.465, 0.76875, 0.1089703125...</td>\n","      <td>spring and summer thick with low shoes</td>\n","    </tr>\n","    <tr>\n","      <th>3637</th>\n","      <td>others###others###human face</td>\n","      <td>[[0.011686046, 0.0, 0.08248311, 0.0, 0.1034707...</td>\n","      <td>[[0.00125, 0.9925, 0.16875, 0.8175, 0.64307343...</td>\n","      <td>genuine books</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            label_words  \\\n","624   top clothes (coat, jacket, shirt, etc.)###huma...   \n","8790  shoes###shoes###shoes###shoes###bottom clothes...   \n","3637                       others###others###human face   \n","\n","                                               features  \\\n","624   [[0.0, 0.0, 0.019117048, 0.0, 0.002718366, 0.3...   \n","8790  [[0.0, 0.0, 0.0, 0.00648563, 0.0, 0.0, 0.0, 0....   \n","3637  [[0.011686046, 0.0, 0.08248311, 0.0, 0.1034707...   \n","\n","                                                    pos  \\\n","624   [[0.1525, 0.99375, 0.19625, 0.8375, 0.53945156...   \n","8790  [[0.59625, 0.955, 0.465, 0.76875, 0.1089703125...   \n","3637  [[0.00125, 0.9925, 0.16875, 0.8175, 0.64307343...   \n","\n","                                       words  \n","624                             sketch books  \n","8790  spring and summer thick with low shoes  \n","3637                           genuine books  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# 全量数据\n","# with open('../data/train_data.pkl', 'rb') as outp:\n","#     train_data= joblib.load(outp)\n","# 1w条\n","with open('data/sample_train_data.pkl', 'rb') as outp:\n","    train_data = joblib.load(outp)\n","\n","\n","with open('data/val_data.pkl', 'rb') as outp:\n","    val_data = pickle.load(outp)\n","    \n","print(len(train_data), type(train_data))\n","train_data.reset_index(drop=True, inplace=True)\n","train_data.sample(3)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"pMZVTqarAr46"},"outputs":[],"source":["def get_coefs(word, *arr):\n","    return word, np.asarray(arr, dtype=np.float16)\n","\n","\n","def load_embed(path, dim=300, word_index=None):\n","    embedding_index = {}\n","    with open(path, mode=\"r\", encoding=\"utf8\") as f:\n","        lines = f.readlines()\n","        for l in lines:\n","            l = l.strip().split()\n","            word, arr = l[0], l[1:]\n","            if len(arr) != dim:\n","                print(\"[!] l = {}\".format(l))\n","                continue\n","            if word_index and word not in word_index:\n","                continue\n","            word, arr = get_coefs(word, arr)\n","            embedding_index[word] = arr\n","    return embedding_index\n","\n","\n","def build_matrix(path, word_index=None, max_features=None, dim=300):\n","    embedding_index = load_embed(path, dim=dim, word_index=word_index)\n","    max_features = len(word_index) + 1 if max_features is None else max_features \n","    embedding_matrix = np.zeros((max_features + 1, dim))\n","    unknown_words = []\n","    \n","    for word, i in word_index.items():\n","        if i <= max_features:\n","            try:\n","                embedding_matrix[i] = embedding_index[word]\n","            except KeyError:\n","#                 print(word)\n","                unknown_words.append(word)\n","    return embedding_matrix, unknown_words\n","\n","\n","def load_word_embed(word_embed_glove=\"data/glove.840B.300d.txt\", \n","                    word_embed_crawl=\"data/crawl-300d-2M.vec\",\n","               save_filename=\"word_embedding_matrix\",\n","               word_index=None):\n","    \"\"\"\n","    (30524, 300) 7590\n","    (30524, 300) 7218\n","    \"\"\"    \n","    if os.path.exists(save_filename + \".npy\"):\n","        word_embedding_matrix = np.load(save_filename + \".npy\").astype(\"float32\")\n","    else:\n","        word_embedding_matrix, tx_unk = build_matrix(word_embed_glove, word_index=word_index, dim=300)\n","\n","        # print(word_embedding_matrix.shape, len(tx_unk))\n","        \n","        word_embedding_matrix_v2, tx_unk = build_matrix(word_embed_crawl, word_index=word_index, dim=300)\n","\n","        # print(word_embedding_matrix_v2.shape, len(tx_unk))\n","        \n","        word_embedding_matrix = np.concatenate([word_embedding_matrix, word_embedding_matrix_v2], axis=1)\n","        \n","        gc.collect()\n","        np.save(save_filename, word_embedding_matrix)\n","    return word_embedding_matrix\n","\n","\n","word_embedding_matrix = load_word_embed(word_index=word_index)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"tHoD4ogMAr47"},"outputs":[],"source":["def build_model(cfg, summary=False, word_embedding_matrix=None):\n","    \n","    def _get_model(base_dir, cfg_=None):\n","        config_file = os.path.join(base_dir, 'bert_config.json')\n","        checkpoint_file = os.path.join(base_dir, 'bert_model.ckpt')\n","        if not os.path.exists(config_file):\n","            config_file = os.path.join(base_dir, 'bert_config_large.json')\n","            checkpoint_file = os.path.join(base_dir, 'roberta_l24_large_model')\n","        print(config_file, checkpoint_file)\n","#         model = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True, seq_len=cfg_['maxlen'])\n","        model = load_trained_model_from_checkpoint(config_file, \n","                                           checkpoint_file, \n","                                           training=False, \n","                                           trainable=cfg_[\"bert_trainable\"], \n","                                           output_layer_num=cfg[\"cls_num\"],\n","                                           seq_len=cfg_['maxlen'])\n","        return model\n","    \n","    def get_opt(num_example, warmup_proportion=0.1, lr=2e-5, min_lr=None):\n","        if cfg[\"opt\"].lower() == \"nadam\":\n","            opt = Nadam(lr=lr)\n","        else:\n","            total_steps, warmup_steps = calc_train_steps(\n","                num_example=num_example,\n","                batch_size=B_SIZE,\n","                epochs=MAX_EPOCH,\n","                warmup_proportion=warmup_proportion,\n","            )\n","\n","            opt = AdamWarmup(total_steps, warmup_steps, lr=lr, min_lr=min_lr)\n","\n","        return opt\n","\n","    model1 = _get_model(cfg[\"base_dir\"], cfg)\n","    model1 = Model(inputs=model1.inputs[: 2], outputs=model1.layers[-7].output)\n","\n","    if word_embedding_matrix is not None:\n","        embed_layer = Embedding(input_dim=word_embedding_matrix.shape[0], \n","                                output_dim=word_embedding_matrix.shape[1],\n","                                weights=[word_embedding_matrix],\n","                                trainable=cfg[\"trainable\"],\n","                                name=\"embed_layer\"\n","                         )\n","        \n","    inp_token1 = Input(shape=(None, ), dtype=np.int32, name=\"query_token_input\")\n","    inp_segm1 = Input(shape=(None, ), dtype=np.float32, name=\"query_segm_input\")\n","    \n","#     inp_token2 = Input(shape=(None, ), dtype=np.int32)\n","#     inp_segm2 = Input(shape=(None, ), dtype=np.float32)    \n","    \n","    inp_image = Input(shape=(None, 2048), dtype=np.float32, name=\"image_input\")\n","    inp_image_mask = Input(shape=(None, ), dtype=np.float32, name=\"image_mask_input\")\n","    inp_pos = Input(shape=(None, 5), dtype=np.float32, name=\"image_pos_input\")        \n","    inp_image_char = Input(shape=(None, cfg[\"max_char\"]), dtype=np.int32, name='image_char_input')\n","    \n","    \n","    mask = Lambda(lambda x: K.cast(K.not_equal(x, cfg[\"x_pad\"]), 'float32'), name=\"token_mask\")(inp_token1)\n","    word_embed = embed_layer(inp_token1)\n","    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n","    word_embed = Bidirectional(LSTM(cfg[\"unit1_1\"], return_sequences=True), merge_mode=\"sum\")(word_embed)\n","    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n","\n","    sequence_output = model1([inp_token1, inp_segm1])\n","    sequence_output = Concatenate(axis=-1)([sequence_output, word_embed])\n","    text_pool = Lambda(lambda x: x[:, 0, :])(sequence_output)\n","\n","    # Share weights of character-level embedding for premise and hypothesis\n","    character_embedding_layer = TimeDistributed(Sequential([\n","        embed_layer,\n","        # Embedding(input_dim=100, output_dim=char_embedding_size, input_length=chars_per_word),\n","        Conv1D(filters=128, kernel_size=3, name=\"char_embed_conv1d\"),\n","        GlobalMaxPooling1D()\n","    ]), name='CharEmbedding')\n","    character_embedding_layer.build(input_shape=(None, None, cfg[\"max_char\"]))\n","    image_char_embed  = character_embedding_layer(inp_image_char)    \n","    image_embed = Concatenate(axis=-1)([image_char_embed, inp_image])    \n","    image_embed = Dense(512, activation='relu', name='image_embed')(image_embed)\n","    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n","    pos_embed = Dense(512, activation='relu', name='pos_embed')(inp_pos)\n","    pos_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([pos_embed, inp_image_mask])\n","    embed = Add()([image_embed , pos_embed]) # batch, maxlen(10), 1024+128\n","    \n","    image_embed = Bidirectional(LSTM(1152, return_sequences=True), merge_mode=\"sum\")(embed)\n","    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n","    \n","    image_pool = Lambda(lambda x: x[:, 0, :])(image_embed)\n","    \n","    pool = Concatenate(axis=-1)([image_pool, text_pool])\n","    pool = Dense(2048, activation=\"relu\")(pool)\n","    pool = Dense(512, activation=\"relu\")(pool)\n","    pool = Dense(128, activation=\"relu\")(pool)\n","    \n","    output = Dense(2, activation='softmax', name='output')(pool)\n","\n","    opt = get_opt(num_example=cfg[\"num_example\"], lr=cfg[\"lr\"], min_lr=cfg['min_lr'])\n","    model = Model(inputs=[inp_token1, inp_segm1, \n","                          inp_image, inp_image_mask,\n","                          inp_pos, inp_image_char], outputs=[output])#\n","    \n","    model.compile(optimizer=opt, loss={\n","                'output': 'sparse_categorical_crossentropy'\n","            }, metrics=['accuracy'])\n","    if summary:\n","        model.summary()\n","    \n","    return model\n","\n","# cfg[\"num_example\"] = 32\n","# model = build_model(cfg, summary=True, word_embedding_matrix=word_embedding_matrix)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"dWGkWTgbAr48"},"outputs":[],"source":["def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n","\n","    # This is a simple heuristic which will always truncate the longer sequence\n","    # one token at a time. This makes more sense than truncating an equal percent\n","    # of tokens from each, since if one sequence is very short then each token\n","    # that's truncated likely contains more information than a longer sequence.\n","\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b)\n","        if total_length <= max_length:\n","            break\n","        if len(tokens_a) > len(tokens_b):\n","            tokens_a.pop()\n","        else:\n","            print(len(tokens_a))\n","            tokens_b.pop()\n","\n","\n","def token2id_X(X, x_dict, maxlen=None):\n","    x = tokenizer.tokenize(X)\n","    if maxlen:\n","        x = x[: 1] + list(x)[1: maxlen - 1] + x[-1: ]     \n","    seg = [0 for _ in x]\n","    token = list(x)\n","    x = [x_dict[e] if e in x_dict else x_dict[\"[UNK]\"] for e in token]\n","    assert len(x) == len(seg)\n","    return x, seg\n","\n","\n","def seq_padding(X, maxlen=None, padding_value=None, debug=False):\n","    L = [len(x) for x in X]\n","    if maxlen is None:\n","        maxlen = max(L)\n","\n","    pad_X = np.array([\n","        np.concatenate([x, [padding_value] * (maxlen - len(x))]) if len(x) < maxlen else x[: maxlen] for x in X\n","    ])\n","    if debug:\n","        print(\"[!] before pading {}\\n\".format(X))\n","        print(\"[!] after pading {}\\n\".format(pad_X))\n","    return pad_X\n","    \n","\n","def MyChoice(Myset):\n","    result = []\n","    for i in Myset:\n","        temp_set = set()\n","        temp_set.add(i)\n","        cho = choice(list(Myset - temp_set))\n","        result.append(cho)\n","    return result\n","\n","\n","class data_generator:\n","    \n","    def __init__(self, data, batch_size=B_SIZE, shuffle=SHUFFLE):\n","        self.data = data\n","        self.batch_size = batch_size\n","        self.steps = len(self.data) // self.batch_size\n","        self.shuffle = shuffle\n","        if len(self.data) % self.batch_size != 0:\n","            self.steps += 1\n","\n","    def __len__(self):\n","        return self.steps\n","    \n","    def __iter__(self):\n","        \"\"\"\n","        inp_token1,\n","        inp_segm1,\n","        inp_image,\n","        inp_image_mask,\n","        inp_pos, \n","        inp_image_char\n","        \"\"\"\n","        while True:\n","            idxs = list(range(len(self.data)))\n","            if self.shuffle:\n","                np.random.shuffle(idxs)\n","            T1, T2, Image1, Pos1, label_word_list, image1_mask, image1_char = [], [], [], [], [], [], []\n","            S1, S2, Image2, Pos2, image2_mask, image2_char = [], [], [], [], [], [] # 负样本\n","            Id_set = set()\n","\n","            for i in idxs:\n","                d = self.data.iloc[i]\n","                text = d['words']\n","                label_words = d['label_words']\n","                \n","                t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n","                image = np.array(d['features'], dtype=\"float32\")\n","                image = image[: cfg[\"max_box\"]]\n","                img_mask = [1 for _ in image[: cfg[\"max_box\"]]]\n","                \n","                pos = np.array(d['pos'], dtype=\"float32\")\n","                pos = pos[: cfg[\"max_box\"]]\n","                \n","                image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n","                image_char = image_char[: cfg[\"max_box\"]]\n","                # print(\"image_char\", len(image_char))\n","                image_char = pad_sequences(image_char, \n","                                           maxlen=cfg[\"max_char\"], \n","                                           dtype='int32',\n","                                           padding='post',\n","                                           truncating='post',\n","                                           value=cfg[\"x_pad\"])\n","                \n","                assert image.shape[0] == pos.shape[0]\n","                assert image.shape[0] == cfg[\"max_box\"] or image.shape[0] == len(label_words.split(IMAGE_LABEM_CONCAT_TOKEN))\n","                assert image_char.shape == (image.shape[0], cfg[\"max_char\"])\n","\n","                T1.append(t1)\n","                T2.append(t2)\n","                Image1.append(image)\n","                image1_mask.append(img_mask)  \n","                Pos1.append(pos)\n","                image1_char.append(image_char)\n","                Id_set.add(i)\n","\n","                if len(T1) == self.batch_size//2 or i == idxs[-1]:\n","                    ## 加入负样本\n","                    Id_new = MyChoice(Id_set)\n","#                     print(Id_set, Id_new)\n","                    for i, id_ in enumerate(Id_new):\n","                        d_new = self.data.iloc[id_]\n","                        text = d_new['words']\n","                        t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n","                        S1.append(t1)\n","                        S2.append(t2)\n","                        \n","                        image = Image1[i]\n","                        img_mask = image1_mask[i]\n","                        pos = Pos1[i]\n","                        image_char = image1_char[i]\n","                        \n","                        Image2.append(image)\n","                        Pos2.append(pos)\n","                        image2_mask.append(img_mask)\n","                        image2_char.append(image_char)\n","                    \n","                    Y = [1] * len(T1) + [0] * len(S1)\n","                   \n","                    T1 = seq_padding(T1 + S1, padding_value=cfg[\"x_pad\"]) \n","                    T2 = seq_padding(T2 + S2, padding_value=cfg[\"x_pad\"])\n","                    \n","                    Image1 = seq_padding(Image1 + Image2, \n","                                         padding_value=np.zeros(shape=(2048, ))\n","                                        )\n","                                                         \n","                    Pos1 = seq_padding(Pos1 + Pos2,\n","                                       padding_value=np.zeros(shape=(5, ))\n","                                      )\n","                    image1_mask = seq_padding(image1_mask + image2_mask,\n","                                             padding_value=0)\n","                    \n","                    image1_char = seq_padding(image1_char + image2_char,\n","                                             padding_value=np.zeros(shape=(cfg[\"max_char\"])), debug=False)\n","                    \n","                    Y = np.array(Y).reshape((len(T1), -1))\n","                    \n","                    idx = np.arange(len(T1))\n","                    np.random.shuffle(idx)\n","        \n","                    T1 = T1[idx]\n","                    T2 = T2[idx]\n","                    Image1 = Image1[idx]\n","                    image1_mask = image1_mask[idx]\n","                    Pos1 = Pos1[idx]\n","                    image1_char = image1_char[idx]\n","                    Y = Y[idx]\n","                    \n","                    yield [T1, T2, Image1, image1_mask, Pos1, image1_char], Y\n","                    T1, T2, Image1, Pos1, label_word_list, image1_mask, image1_char = [], [], [], [], [], [], []\n","                    S1, S2, Image2, Pos2, image2_mask, image2_char = [], [], [], [], [], [] # 负样本\n","                    Id_set = set()\n","\n","                        "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"cSFjbRg6Ar5A"},"outputs":[{"name":"stdout","output_type":"stream","text":["x (128, 10) (128, 10) (128, 10, 2048) (128, 10) (128, 10, 5) (128, 10, 8) (128, 1)\n","[[ 2703.     0.     0. ...     0.     0.     0.]\n"," [ 6210.  6210. 54190. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," ...\n"," [ 2703.  2703.  2703. ...     0.     0.     0.]\n"," [ 2703.  2703. 63124. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]]\n","x (128, 13) (128, 13) (128, 10, 2048) (128, 10) (128, 10, 5) (128, 10, 8) (128, 1)\n","[[ 2703.  2703.     0. ...     0.     0.     0.]\n"," [21740.     0.     0. ...     0.     0.     0.]\n"," [ 6210.  6210.  2703. ...     0.     0.     0.]\n"," ...\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," [ 6210.  2703.  2703. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]]\n","x (128, 10) (128, 10) (128, 10, 2048) (128, 10) (128, 10, 5) (128, 10, 8) (128, 1)\n","[[21740.     0.     0. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," [ 7593.  2703.  2703. ...     0.     0.     0.]\n"," ...\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," [ 2703.  2703.     0. ...     0.     0.     0.]]\n","x (128, 11) (128, 11) (128, 10, 2048) (128, 10) (128, 10, 5) (128, 10, 8) (128, 1)\n","[[11102. 11102.     0. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," ...\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," [ 2703.  2703. 37880. ...     0.     0.     0.]\n"," [ 2703.  2703.  2703. ...     0.     0.     0.]]\n","x (128, 13) (128, 13) (128, 10, 2048) (128, 10) (128, 10, 5) (128, 10, 8) (128, 1)\n","[[ 2703. 29895.  2703. ...     0.     0.     0.]\n"," [ 2703.  2703.  2703. ...     0.     0.     0.]\n"," [ 2703.  2703.     0. ...     0.     0.     0.]\n"," ...\n"," [21740.     0.     0. ...     0.     0.     0.]\n"," [37880.  2703.  2703. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]]\n","x (128, 12) (128, 12) (128, 10, 2048) (128, 10) (128, 10, 5) (128, 10, 8) (128, 1)\n","[[21740.     0.     0. ...     0.     0.     0.]\n"," [ 2703.  2703.     0. ...     0.     0.     0.]\n"," [54190. 54190.     0. ...     0.     0.     0.]\n"," ...\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," [ 9887.  2703.     0. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]]\n","x (128, 13) (128, 13) (128, 9, 2048) (128, 9) (128, 9, 5) (128, 9, 8) (128, 1)\n","[[ 2703.  2703.  7593. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," [ 2703. 63124.  2703. ...     0.     0.     0.]\n"," ...\n"," [ 2703.  2703.     0. ...     0.     0.     0.]\n"," [ 2703.  2703.     0. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]]\n","x (128, 12) (128, 12) (128, 10, 2048) (128, 10) (128, 10, 5) (128, 10, 8) (128, 1)\n","[[11102. 11102.     0. ...     0.     0.     0.]\n"," [ 2703.  2703.     0. ...     0.     0.     0.]\n"," [ 7593.  2703.  2703. ...  2703.  2703.     0.]\n"," ...\n"," [ 9887.  2703.     0. ...     0.     0.     0.]\n"," [ 2703.  4959.     0. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]]\n","x (128, 12) (128, 12) (128, 10, 2048) (128, 10) (128, 10, 5) (128, 10, 8) (128, 1)\n","[[ 2703.     0.     0. ...     0.     0.     0.]\n"," [37880.     0.     0. ...     0.     0.     0.]\n"," [ 4959. 54190.     0. ...     0.     0.     0.]\n"," ...\n"," [ 2703. 11102.  4959. ... 11102.     0.     0.]\n"," [ 2703. 11102.     0. ...     0.     0.     0.]\n"," [ 2703. 10430.  2703. ... 10430.  2703.  2703.]]\n","x (128, 12) (128, 12) (128, 10, 2048) (128, 10) (128, 10, 5) (128, 10, 8) (128, 1)\n","[[ 2703.  2703. 37880. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," [11102.     0.     0. ...     0.     0.     0.]\n"," ...\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," [ 2703.     0.     0. ...     0.     0.     0.]\n"," [21740.     0.     0. ...     0.     0.     0.]]\n"]}],"source":["train_D = data_generator(train_data)\n","_i  = 0\n","for d in train_D:\n","    _i += 1\n","    if  _i > 10:\n","        break\n","    print('x',d[0][0].shape, d[0][1].shape,d[0][2].shape, d[0][3].shape, d[0][4].shape, d[0][5].shape, d[1].shape)\n","    print(d[0][5].sum(axis=-1))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"wK6_y8irAr5C"},"outputs":[],"source":["class Evaluate(Callback):\n","    def __init__(self, filename=None):\n","        self.score = []\n","        self.best = 0.\n","        self.filename = filename\n","       \n","    def on_epoch_begin(self, epoch, logs=None):\n","        if epoch ==  0:\n","            print(\"[!] test load&save model\")\n","            f = self.filename + \".h5\"\n","            custom_objects = get_custom_objects()\n","            self.model.save(f, include_optimizer=False, overwrite=True)\n","            if \"bert\" in cfg[\"verbose\"]:\n","                model_ = load_model(f, custom_objects=custom_objects)  \n","            else:\n","                model_ = load_model(f) \n","    \n","    def on_epoch_end(self, epoch, logs=None):\n","#         if epoch + 1 < 5:\n","#             return\n","        score = self.evaluate(self.model)\n","        self.score.append((epoch, score))\n","        \n","        if epoch + 1 in SAVE_EPOCHS:\n","            self.model.save(self.filename + \"_{}.h5\".format(epoch + 1), include_optimizer=False, overwrite=True)             \n","        if score > self.best:\n","            self.model.save(self.filename + \".h5\", include_optimizer=False)\n","            \n","        if score > self.best:\n","            self.best = score\n","            print(\"[!] epoch = {}, new best score = {}\".format(epoch + 1,  score))\n","        print('[!] epoch = {}, score = {}, best score: {}\\n'.format(epoch + 1, score, self.best))\n","\n","    def evaluate(self, model):\n","        result = defaultdict(list)\n","        for i in trange(len(val_data)):\n","            d = val_data.iloc[i]\n","            qid = d['query_id']\n","            pid = d['product_id']\n","            text = d['query']\n","            label_words = d['label_words']\n","            t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n","            \n","            image = np.array(d['feature_convert'], dtype=\"float32\")\n","            image = image[: cfg[\"max_box\"]]\n","            img_mask = [1 for _ in image[: cfg[\"max_box\"]]]                   \n","            pos = np.array(d['pos'], dtype=\"float32\")\n","            pos = pos[: cfg[\"max_box\"]]\n","            \n","            image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n","            image_char = image_char[: cfg[\"max_box\"]]\n","            image_char = pad_sequences(image_char, \n","                                       maxlen=cfg[\"max_char\"], \n","                                       dtype='int32',\n","                                       padding='post',\n","                                       truncating='post',\n","                                       value=cfg[\"x_pad\"]) \n","            output = model.predict([[t1], [t2], [image], [img_mask], [pos], [image_char]])\n","            result[qid].append((pid, output[0][1]))\n","            \n","        query_id,product1,product2,product3,product4,product5 = [],[],[],[],[],[]\n","        for key in result.keys():\n","            rlist = result[key]\n","            rlist.sort(key=lambda x: x[1], reverse=True)\n","            query_id.append(key)\n","            product1.append(rlist[0][0])\n","            product2.append(rlist[1][0])\n","            product3.append(rlist[2][0])\n","            product4.append(rlist[3][0])\n","            product5.append(rlist[4][0])\n","        sub = pd.DataFrame({'query-id':query_id,\n","                            'product1':product1,\n","                            'product2':product2,\n","                            'product3':product3,\n","                            'product4':product4,\n","                            'product5':product5,\n","\n","        })\n","        sub.to_csv('result/val_submission.csv',index=0)\n","        \n","        reference = json.load(open(VAL_ANS_PATH))\n","        \n","        # read predictions\n","        k = 5\n","        predictions = read_submission('result/val_submission.csv', reference, k)\n","\n","        # compute score for each query\n","        score_sum = 0.\n","        for qid in reference.keys():\n","            ground_truth_ids = set([str(pid) for pid in reference[qid]])\n","            ref_vec = [1.0] * len(ground_truth_ids)\n","            pred_vec = [1.0 if pid in ground_truth_ids else 0.0 for pid in predictions[qid]]\n","            score_sum += get_ndcg(pred_vec, ref_vec, k)\n","        # the higher score, the better\n","        score = score_sum / len(reference)\n","        \n","        return score"]},{"cell_type":"markdown","metadata":{"id":"G0U5XAi6Ar5D"},"source":["# Train"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10148921,"status":"ok","timestamp":1636219971941,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"-8khJgNZAr5F","outputId":"a957f6b0-64b7-4ed2-98e0-788e46c9bf66","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","[!] fold_id = -1 starting\n","{'verbose': '[image-bert-concat-query]-wwm_uncased_L12-768_v3_quart', 'base_dir': '/root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/uncased_L-12_H-768_A-12', 'maxlen': 20, 'max_box': 10, 'max_char': 8, 'lr': 0.0001, 'min_lr': 6e-08, 'opt': 'nadam', 'loss_w': 20.0, 'trainable': True, 'bert_trainable': True, 'mix_mode': '', 'unit1_1': 128, 'accum_step': 1, 'cls_num': 4, 'raw_filename': '{}_{}oof{}', 'x_pad': 0, 'filename': '[image-bert-concat-query]-wwm_uncased_L12-768_v3_quart_20oof-1', 'num_example': 10000}\n","/root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/uncased_L-12_H-768_A-12/bert_config.json /root/Applied_AI_Lab_WiSe2021_Passau/ai-light/data/uncased_L-12_H-768_A-12/bert_model.ckpt\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","image_char_input (InputLayer)   (None, None, 8)      0                                            \n","__________________________________________________________________________________________________\n","CharEmbedding (TimeDistributed) (None, None, 128)    18544928    image_char_input[0][0]           \n","__________________________________________________________________________________________________\n","image_input (InputLayer)        (None, None, 2048)   0                                            \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, None, 2176)   0           CharEmbedding[0][0]              \n","                                                                 image_input[0][0]                \n","__________________________________________________________________________________________________\n","image_pos_input (InputLayer)    (None, None, 5)      0                                            \n","__________________________________________________________________________________________________\n","query_token_input (InputLayer)  (None, None)         0                                            \n","__________________________________________________________________________________________________\n","image_embed (Dense)             (None, None, 512)    1114624     concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","image_mask_input (InputLayer)   (None, None)         0                                            \n","__________________________________________________________________________________________________\n","pos_embed (Dense)               (None, None, 512)    3072        image_pos_input[0][0]            \n","__________________________________________________________________________________________________\n","embed_layer (Embedding)         (None, None, 600)    18314400    query_token_input[0][0]          \n","__________________________________________________________________________________________________\n","token_mask (Lambda)             (None, None)         0           query_token_input[0][0]          \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, None, 512)    0           image_embed[0][0]                \n","                                                                 image_mask_input[0][0]           \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, None, 512)    0           pos_embed[0][0]                  \n","                                                                 image_mask_input[0][0]           \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, None, 600)    0           embed_layer[0][0]                \n","                                                                 token_mask[0][0]                 \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, None, 512)    0           lambda_4[0][0]                   \n","                                                                 lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","query_segm_input (InputLayer)   (None, None)         0                                            \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, None, 128)    746496      lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","bidirectional_2 (Bidirectional) (None, None, 1152)   15344640    add_1[0][0]                      \n","__________________________________________________________________________________________________\n","model_3 (Model)                 multiple             103788288   query_token_input[0][0]          \n","                                                                 query_segm_input[0][0]           \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, None, 128)    0           bidirectional_1[0][0]            \n","                                                                 token_mask[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, None, 1152)   0           bidirectional_2[0][0]            \n","                                                                 image_mask_input[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, None, 896)    0           model_3[1][0]                    \n","                                                                 lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 1152)         0           lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 896)          0           concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 2048)         0           lambda_7[0][0]                   \n","                                                                 lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 2048)         4196352     concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 512)          1049088     dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 128)          65664       dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","output (Dense)                  (None, 2)            258         dense_3[0][0]                    \n","==================================================================================================\n","Total params: 144,853,410\n","Trainable params: 144,853,410\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["\n","gc.collect()\n","fold_id = -1\n","print(\"\\n\\n[!] fold_id = {} starting\".format(fold_id))\n","cfg[\"filename\"] = cfg[\"raw_filename\"].format(cfg[\"verbose\"], FOLD_NUM, fold_id)\n","cfg[\"num_example\"] = len(train_data)\n","\n","K.clear_session()\n","gc.collect()\n","seed(SEED - fold_id)\n","np.random.seed(SEED - fold_id)\n","tf.random.set_random_seed(SEED - fold_id)\n","train_D = data_generator(train_data)\n","print(cfg)\n","model = build_model(cfg, summary=True, \n","                    word_embedding_matrix=word_embedding_matrix,\n","                    )\n","tf.keras.utils.plot_model(model, to_file=\"models/model_v1.png\", show_shapes=True)\n","#     model.load_weights('[image-concat-query]-wwm_uncased_L24-1024_20oof0')\n","evaluator = Evaluate(filename=cfg[\"filename\"])\n","#     checkpoint= ModelCheckpoint(cfg[\"filename\"], monitor='acc', verbose=1, save_best_only=False, mode='max') \n"]},{"cell_type":"markdown","metadata":{"id":"0OvOGGA_tP8F"},"source":["### Model Fitting"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"U73CNxpCtVUY"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","[!] test load&save model\n"]}],"source":["model.fit_generator(train_D.__iter__(),\n","                          steps_per_epoch=len(train_D),\n","                          epochs=MAX_EPOCH,\n","                          callbacks=[evaluator],\n","                          shuffle=True\n","                          )\n","print(\"\\n\\n[!] fold_id = {} finish\".format(fold_id))\n","del model, evaluator"]},{"cell_type":"markdown","metadata":{"id":"fUo7uyS6Ar5G","scrolled":true},"source":["# Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73205,"status":"ok","timestamp":1636220046397,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"8yAEZS7dAr5G","outputId":"ff7ac5dd-b2e5-4095-ef2e-f206020b4592"},"outputs":[],"source":["with open('data/test_data.pkl', 'rb') as outp:\n","    test_data = pickle.load(outp)\n","\n","f = cfg[\"filename\"] + \".h5\"\n","if \"bert\" in cfg[\"verbose\"]:\n","    custom_objects = get_custom_objects()\n","    model = load_model(f, custom_objects=custom_objects)  \n","else:\n","    model = load_model(f)\n","print(\"finish\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ct2eCmYhAr5H"},"outputs":[],"source":["gc.collect()\n","result = defaultdict(list)\n","for i in trange(len(test_data)):\n","    d = test_data.iloc[i]\n","    qid = d['query_id']\n","    pid = d['product_id']\n","    text = d['query']\n","    label_words = d['label_words']\n","    t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n","\n","    image = np.array(d['feature_convert'], dtype=\"float32\")\n","    image = image[: cfg[\"max_box\"]]\n","    img_mask = [1 for _ in image[: cfg[\"max_box\"]]]                   \n","    pos = np.array(d['pos'], dtype=\"float32\")\n","    pos = pos[: cfg[\"max_box\"]]\n","\n","    image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n","    image_char = image_char[: cfg[\"max_box\"]]\n","    image_char = pad_sequences(image_char, \n","                               maxlen=cfg[\"max_char\"], \n","                               dtype='int32',\n","                               padding='post',\n","                               truncating='post',\n","                               value=cfg[\"x_pad\"]) \n","    output = model.predict([[t1], [t2], [image], [img_mask], [pos], [image_char]])\n","    result[qid].append((pid, output[0][1]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOWqYUaXAr5H"},"outputs":[],"source":["query_id,product1,product2,product3,product4,product5 = [],[],[],[],[],[]\n","for key in result.keys():\n","    rlist = result[key]\n","    rlist.sort(key=lambda x: x[1], reverse=True)\n","    query_id.append(key)\n","    product1.append(rlist[0][0])\n","    product2.append(rlist[1][0])\n","    product3.append(rlist[2][0])\n","    product4.append(rlist[3][0])\n","    product5.append(rlist[4][0])\n","\n","sub = pd.DataFrame({'query-id':query_id,\n","                    'product1':product1,\n","                    'product2':product2,\n","                    'product3':product3,\n","                    'product4':product4,\n","                    'product5':product5,\n","\n","})\n","\n","sub.to_csv('../result/submission.csv',index=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hjq_AYpAAr5I"},"outputs":[],"source":["sub.head(5)"]},{"cell_type":"markdown","metadata":{"id":"ecQVcr2zXytP"},"source":["## Eval"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":630,"status":"ok","timestamp":1636222703249,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"RR5AV6DQXyGN","outputId":"938ec73d-ba80-493f-f6c5-2b6f41fb6faf"},"outputs":[],"source":["!python eval.py ../data/testA_answer.json ../result/submission.csv ../result/test_result.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nfArcyPlAr5J"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"[image-concat-query]-wwm_uncased_L12-768_v3_quart.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}
