{"cells":[{"cell_type":"markdown","metadata":{"id":"ASY11viGC-CR"},"source":["### Environment Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":113094,"status":"ok","timestamp":1636221066554,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"AQD3X56MDC41","outputId":"98a56160-961f-40f1-c157-9853b2ad57b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting swifter\n","  Downloading swifter-1.0.9-py3-none-any.whl (14 kB)\n","Requirement already satisfied: bleach>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from swifter) (4.1.0)\n","Requirement already satisfied: dask[dataframe]>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (2.12.0)\n","Requirement already satisfied: parso>0.4.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (0.8.2)\n","Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (4.62.3)\n","Requirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from swifter) (1.3.0)\n","Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (1.1.5)\n","Collecting psutil>=5.6.6\n","  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n","\u001b[K     |████████████████████████████████| 296 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (7.6.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach>=3.1.1->swifter) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach>=3.1.1->swifter) (21.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bleach>=3.1.1->swifter) (1.15.0)\n","Collecting fsspec>=0.6.0\n","  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 65.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.19.5)\n","Collecting partd>=0.3.10\n","  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]>=2.10.0->swifter) (0.11.1)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (4.10.1)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (5.1.3)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (3.5.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (1.0.2)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (5.5.0)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (0.2.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (5.1.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (5.3.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (5.1.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (1.0.18)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (57.4.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (2.6.1)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.7.5)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (2.6.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (4.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->swifter) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->swifter) (2.8.2)\n","Collecting locket\n","  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (5.3.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.12.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (2.11.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.8.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (5.6.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (22.3.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (2.0.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.5.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.7.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.8.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach>=3.1.1->swifter) (2.4.7)\n","Installing collected packages: locket, partd, fsspec, psutil, swifter\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","Successfully installed fsspec-2021.11.0 locket-0.2.1 partd-1.2.0 psutil-5.8.0 swifter-1.0.9\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Found existing installation: tensorflow 2.6.0\n","Uninstalling tensorflow-2.6.0:\n","  Successfully uninstalled tensorflow-2.6.0\n","Found existing installation: keras 2.6.0\n","Uninstalling keras-2.6.0:\n","  Successfully uninstalled keras-2.6.0\n","\u001b[33mWARNING: Skipping keras-transformer as it is not installed.\u001b[0m\n","Collecting tensorflow-gpu==1.13.1\n","  Downloading tensorflow_gpu-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (345.0 MB)\n","\u001b[K     |████████████████████████████████| 345.0 MB 3.5 kB/s \n","\u001b[?25hCollecting keras==2.2.4\n","  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n","\u001b[K     |████████████████████████████████| 312 kB 68.5 MB/s \n","\u001b[?25hCollecting keras-transformer==0.33.0\n","  Downloading keras-transformer-0.33.0.tar.gz (11 kB)\n","Collecting keras_bert==0.78.0\n","  Downloading keras-bert-0.78.0.tar.gz (28 kB)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.19.5)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.41.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (3.17.3)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.4.0)\n","Collecting tensorboard<1.14.0,>=1.13.0\n","  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n","\u001b[K     |████████████████████████████████| 3.2 MB 32.1 MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.37.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n","\u001b[K     |████████████████████████████████| 367 kB 61.1 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.12.0)\n","Collecting keras-applications>=1.0.6\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.1.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n","Collecting keras-pos-embd>=0.10.0\n","  Downloading keras-pos-embd-0.12.0.tar.gz (6.0 kB)\n","Collecting keras-multi-head>=0.22.0\n","  Downloading keras-multi-head-0.28.0.tar.gz (14 kB)\n","Collecting keras-layer-normalization>=0.12.0\n","  Downloading keras-layer-normalization-0.15.0.tar.gz (4.2 kB)\n","Collecting keras-position-wise-feed-forward>=0.5.0\n","  Downloading keras-position-wise-feed-forward-0.7.0.tar.gz (4.5 kB)\n","Collecting keras-embed-sim>=0.7.0\n","  Downloading keras-embed-sim-0.9.0.tar.gz (4.1 kB)\n","Collecting keras-self-attention>=0.50.0\n","  Downloading keras-self-attention-0.50.0.tar.gz (12 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (4.8.1)\n","Collecting mock>=2.0.0\n","  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.2.4) (1.5.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.7.4.3)\n","Building wheels for collected packages: keras-transformer, keras-bert, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-transformer: filename=keras_transformer-0.33.0-py3-none-any.whl size=13260 sha256=88c64b606592d3bbe7063c72d62737b663311fa602c6528c23ddbbb13a8f976f\n","  Stored in directory: /root/.cache/pip/wheels/6a/d8/48/ad5dd5d184d38695ceb230091a11c954cb41f8be79169f5f25\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-bert: filename=keras_bert-0.78.0-py3-none-any.whl size=37882 sha256=f2628c60b9cc7dbe68693ceb595e8714942c2a3c78b284873292f7a5bffa8564\n","  Stored in directory: /root/.cache/pip/wheels/f5/95/5b/10b6e14cdbe8313cf9996fcf7e500b5e5d86290050ee3768f3\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.9.0-py3-none-any.whl size=4504 sha256=3cc9376438d8a0b68e199c8bce21ee1fc6a42c37ab6493bf999d2699fdf32f4d\n","  Stored in directory: /root/.cache/pip/wheels/a8/1e/d2/9bc15513dd2f8b9de3e628b3aa9d2de49e721deef6bbd1497e\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.15.0-py3-none-any.whl size=5224 sha256=2e5cdc135dd1f0bdf5fb9f23c26cbf5ed1b6a96aac05458e6526a3d05cc7615c\n","  Stored in directory: /root/.cache/pip/wheels/4d/be/fe/55422f77ac11fe6ddcb471198038de8a26b5a4dd1557883c1e\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-multi-head: filename=keras_multi_head-0.28.0-py3-none-any.whl size=15559 sha256=4aabbc1abcbf7a19ab61f4ff565ebe3bfb4c514a774e034d7c4363f9beb7b67d\n","  Stored in directory: /root/.cache/pip/wheels/79/4a/ea/9503ab5a02201dfb8635ba2cc8f30844661623c684a5b44472\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.12.0-py3-none-any.whl size=7469 sha256=de24f9f76539b79fbd01932de275887f5964209bee19de82159e4ac73c274114\n","  Stored in directory: /root/.cache/pip/wheels/77/99/fd/dd98f4876c3ebbef7aab0dbfbd37bca41d7db37d3a28b2cb09\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.7.0-py3-none-any.whl size=5541 sha256=99f136a526f155b4268aa4e7e23150776e5ea68226e94e2ab3bdf807af421e6e\n","  Stored in directory: /root/.cache/pip/wheels/2d/12/02/1ad455c4f181cda1a4e60c5445855853d5c2ea91f942586a04\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.50.0-py3-none-any.whl size=19414 sha256=9ec92ed5ad246d13b9e1fcff174a130cbdc26203fcf9459cf4d50b6bc05bc5dd\n","  Stored in directory: /root/.cache/pip/wheels/92/7a/a3/231bef5803298e7ec1815215bc0613239cb1e9c03c57b13c14\n","Successfully built keras-transformer keras-bert keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention\n","Installing collected packages: keras-applications, keras, keras-self-attention, mock, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, tensorflow-estimator, tensorboard, keras-transformer, tensorflow-gpu, keras-bert\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.6.0\n","    Uninstalling tensorflow-estimator-2.6.0:\n","      Successfully uninstalled tensorflow-estimator-2.6.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.6.0\n","    Uninstalling tensorboard-2.6.0:\n","      Successfully uninstalled tensorboard-2.6.0\n","Successfully installed keras-2.2.4 keras-applications-1.0.8 keras-bert-0.78.0 keras-embed-sim-0.9.0 keras-layer-normalization-0.15.0 keras-multi-head-0.28.0 keras-pos-embd-0.12.0 keras-position-wise-feed-forward-0.7.0 keras-self-attention-0.50.0 keras-transformer-0.33.0 mock-4.0.3 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n","Collecting h5py==2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n","\u001b[?25hCollecting numpy>=1.7\n","  Downloading numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 61 kB/s \n","\u001b[?25hCollecting six\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Installing collected packages: six, numpy, h5py\n","  Attempting uninstall: six\n","    Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kapre 0.3.5 requires tensorflow>=2.0.0, which is not installed.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed h5py-2.10.0 numpy-1.21.4 six-1.16.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","six"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install swifter\n","!pip uninstall -y tensorflow keras keras-transformer\n","!pip install tensorflow-gpu==1.13.1 keras==2.2.4 keras-transformer==0.33.0 keras_bert==0.78.0\n","!pip install h5py==2.10.0 --force-reinstall"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247,"status":"ok","timestamp":1636222518038,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"DTa9iYTGdjPM","outputId":"d9467db5-09ba-47e5-dc85-b5d1519b9017"},"outputs":[{"name":"stdout","output_type":"stream","text":[" eval.py\n","'[image-bert-concat-query]-wwm_uncased_L12-768_v3_quart_20oof-1_10.h5'\n","'[image-bert-concat-query]-wwm_uncased_L12-768_v3_quart_20oof-1_20.h5'\n","'[image-bert-concat-query]-wwm_uncased_L12-768_v3_quart_20oof-1.h5'\n","'[image-concat-query]-wwm_uncased_L12-768_v3_quart.ipynb'\n"," model_utils.py\n"," preprocess.py\n"," __pycache__\n"," word_embedding_matrix.npy\n"]}],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"G8GPhl_YBO9X"},"source":["### Mount"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20498,"status":"ok","timestamp":1636220946655,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"351qJiAGBgXA","outputId":"4b55f6ad-cb4e-411c-8c91-d57c36d3ae9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1636221117610,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"iLuItL-GBRQY","outputId":"b3fe81c7-f20e-4f19-b9b2-d5a4b5abc9e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Study/Passau/Applied AI/Experiment/yasser_path2/code\n"]}],"source":["%cd drive/MyDrive/Study/Passau/Applied\\ AI/Experiment/yasser_path2/code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BpdWSjMNR18V"},"outputs":[],"source":["# !wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip data\n","# ! wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip ../data/\n","# !wget https://nlp.stanford.edu/data/glove.840B.300d.zip ../data/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wI8SduklTKXO"},"outputs":[],"source":["# !unzip ../data/uncased_L-12_H-768_A-12.zip ../data/\n","# !unzip crawl-300d-2M.vec.zip\n","# !7z e glove.840B.300d.zip \n"]},{"cell_type":"markdown","metadata":{"id":"Vp6skypuClUf"},"source":["### Run Preprocessing File"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dnDeHDjqCqPX"},"outputs":[],"source":["# !python preprocess.py"]},{"cell_type":"markdown","metadata":{"id":"Fh7BB7hTBKOs"},"source":["### Imports\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":521,"status":"ok","timestamp":1636209799226,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"qtsQ8SovAr4v","outputId":"cec16143-f0a5-4dc7-b4e6-85204f1e9bfb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","import gc\n","import json\n","import pandas as pd\n","import numpy as np\n","from random import choice, seed, shuffle, random, sample\n","import tensorflow as tf\n","import keras.backend.tensorflow_backend as KTF\n","from keras.models import Sequential, Model\n","from keras.layers import Input, CuDNNGRU as GRU, CuDNNLSTM as LSTM, Dropout, BatchNormalization\n","from keras.layers import Dense, Concatenate, Activation, Embedding, SpatialDropout1D, Bidirectional, Lambda, Conv1D\n","from keras.layers import Add, Average, TimeDistributed, GlobalMaxPooling1D\n","from keras.optimizers import Nadam, Adam, Adamax\n","from keras.activations import absolute_import\n","from keras.legacy import interfaces\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.callbacks import Callback\n","from keras.utils import to_categorical\n","import keras.backend as K\n","from keras.callbacks import ModelCheckpoint\n","import keras\n","from sklearn.model_selection import KFold\n","from keras.initializers import he_normal\n","# from keras_bert.bert import get_model\n","from keras_bert.loader import load_trained_model_from_checkpoint\n","from keras_bert import AdamWarmup, calc_train_steps\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.objectives import categorical_crossentropy\n","from keras.objectives import sparse_categorical_crossentropy\n","from keras import activations, initializers, regularizers, constraints\n","from keras.models import Model\n","from tqdm import tqdm\n","from model_utils import seq_gather, seq_and_vec, seq_maxpool\n","from keras.models import load_model\n","from keras_bert import get_custom_objects\n","from keras_bert import Tokenizer\n","from collections import defaultdict\n","from eval import read_submission, get_ndcg\n","from tqdm import tqdm, trange\n","import pickle\n","from sklearn.externals import joblib\n","\n","\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth=True #不全部占满显存, 按需分配\n","sess = tf.Session(config=config)\n","KTF.set_session(sess)\n","\n","BERT_PRETRAINED_DIR = \"/content/drive/MyDrive/Study/Passau/Applied AI/Experiment/yasser_path2/data/uncased_L-12_H-768_A-12/\"\n","VAL_ANS_PATH = '/content/drive/MyDrive/Study/Passau/Applied AI/Experiment/yasser_path2/data/valid_answer.json'\n","LABEL_PATH = '/content/drive/MyDrive/Study/Passau/Applied AI/Experiment/yasser_path2/data/multimodal_labels.txt'\n","\n","MAX_EPOCH = 20\n","MAX_LEN = 20\n","B_SIZE = 128\n","FOLD_IDS = [-1]\n","FOLD_NUM = 20\n","THRE = 0.5\n","SHUFFLE = True\n","MAX_BOX = 10\n","MAX_CHAR = 8\n","PREFIX = \"[image-bert-concat-query]-wwm_uncased_L12-768_v3_quart\"\n","SEED = 2020\n","ACCUM_STEP = int(128 // B_SIZE)\n","SAVE_EPOCHS=[10, 20, 35, 50, 80, 100]\n","IMAGE_LABEM_CONCAT_TOKEN = \"###\"\n","CONCAT_TOKE = \"[unused0]\"\n","\n","cfg = {}\n","cfg[\"verbose\"] = PREFIX\n","cfg[\"base_dir\"] = BERT_PRETRAINED_DIR\n","cfg['maxlen'] = MAX_LEN\n","cfg[\"max_box\"] = MAX_BOX\n","cfg[\"max_char\"] = MAX_CHAR\n","cfg[\"lr\"] = 1e-4\n","cfg['min_lr'] = 6e-8\n","cfg[\"opt\"] = \"nadam\"\n","cfg[\"loss_w\"] =  20.\n","cfg[\"trainable\"] = True\n","cfg[\"bert_trainable\"] = True\n","cfg[\"mix_mode\"] = \"\"   # add concat average\n","cfg[\"unit1_1\"] = 128\n","cfg[\"accum_step\"] = ACCUM_STEP\n","cfg[\"cls_num\"] = 4\n","cfg[\"raw_filename\"] = \"{}_{}oof{}\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rqxc8sS8Ar43"},"outputs":[],"source":["def get_vocab():\n","    if \"albert\"in cfg[\"verbose\"].lower():\n","        dict_path = os.path.join(BERT_PRETRAINED_DIR, 'vocab_chinese.txt')\n","    else:\n","        dict_path = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n","    with open(dict_path, mode=\"r\", encoding=\"utf8\") as f:\n","        lines = f.readlines()\n","        lines = [l.strip() for l in lines]\n","\n","    word_index = {v: k  for k, v in enumerate(lines)}\n","    return word_index\n","\n","\n","word_index = get_vocab()\n","cfg[\"x_pad\"] = word_index[\"[PAD]\"]\n","tokenizer = Tokenizer(word_index)\n","\n","\n","def get_label(path):\n","    with open(path) as f:\n","        lines = f.readlines()\n","        label2id = {l.split('\\n')[0].split('\\t')[1]:int(l.split('\\n')[0].split('\\t')[0]) for l in lines[1:]}\n","        id2label = {int(l.split('\\n')[0].split('\\t')[0]):l.split('\\n')[0].split('\\t')[1] for l in lines[1:]}\n","    return label2id, id2label\n","\n","\n","label2id, id2label = get_label(LABEL_PATH)\n","label_set = set(label2id.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"elapsed":16263,"status":"ok","timestamp":1636209821843,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"JxCVu3PpAr45","outputId":"a9ba4a30-eeac-4e60-9e18-887423c11f6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["10000 <class 'pandas.core.frame.DataFrame'>\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>label_words</th>\n","      <th>features</th>\n","      <th>pos</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3867</th>\n","      <td>a pedal boys shoes</td>\n","      <td>others###shoes</td>\n","      <td>[[0.0, 0.0, 1.157958, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n","      <td>[[0.264, 0.363, 0.867, 0.994, 0.012573], [0.12...</td>\n","    </tr>\n","    <tr>\n","      <th>3118</th>\n","      <td>ms. gather swimsuit</td>\n","      <td>human face###skirt &amp; dress###others###shoes###...</td>\n","      <td>[[0.0, 0.0, 0.049101286, 0.0, 0.0, 0.21375555,...</td>\n","      <td>[[0.09875, 0.3075, 0.3325, 0.5075, 0.03653125]...</td>\n","    </tr>\n","    <tr>\n","      <th>2258</th>\n","      <td>oil control men's cleansing</td>\n","      <td>makeup, perfume, beauty tools and essential oi...</td>\n","      <td>[[0.0, 0.0, 0.10190404, 0.0, 0.268829, 0.0, 0....</td>\n","      <td>[[0.187, 0.889, 0.259, 0.738, 0.336258], [0.44...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            words  ...                                                pos\n","3867           a pedal boys shoes  ...  [[0.264, 0.363, 0.867, 0.994, 0.012573], [0.12...\n","3118          ms. gather swimsuit  ...  [[0.09875, 0.3075, 0.3325, 0.5075, 0.03653125]...\n","2258  oil control men's cleansing  ...  [[0.187, 0.889, 0.259, 0.738, 0.336258], [0.44...\n","\n","[3 rows x 4 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# 全量数据\n","# with open('../data/train_data.pkl', 'rb') as outp:\n","#     train_data= joblib.load(outp)\n","# 1w条\n","with open('../data/temp_data.pkl', 'rb') as outp:\n","    train_data = joblib.load(outp)\n","\n","\n","with open('../data/val_data.pkl', 'rb') as outp:\n","    val_data = pickle.load(outp)\n","    \n","print(len(train_data), type(train_data))\n","train_data.reset_index(drop=True, inplace=True)\n","train_data.sample(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pMZVTqarAr46"},"outputs":[],"source":["def get_coefs(word, *arr):\n","    return word, np.asarray(arr, dtype=np.float16)\n","\n","\n","def load_embed(path, dim=300, word_index=None):\n","    embedding_index = {}\n","    with open(path, mode=\"r\", encoding=\"utf8\") as f:\n","        lines = f.readlines()\n","        for l in lines:\n","            l = l.strip().split()\n","            word, arr = l[0], l[1:]\n","            if len(arr) != dim:\n","                print(\"[!] l = {}\".format(l))\n","                continue\n","            if word_index and word not in word_index:\n","                continue\n","            word, arr = get_coefs(word, arr)\n","            embedding_index[word] = arr\n","    return embedding_index\n","\n","\n","def build_matrix(path, word_index=None, max_features=None, dim=300):\n","    embedding_index = load_embed(path, dim=dim, word_index=word_index)\n","    max_features = len(word_index) + 1 if max_features is None else max_features \n","    embedding_matrix = np.zeros((max_features + 1, dim))\n","    unknown_words = []\n","    \n","    for word, i in word_index.items():\n","        if i <= max_features:\n","            try:\n","                embedding_matrix[i] = embedding_index[word]\n","            except KeyError:\n","#                 print(word)\n","                unknown_words.append(word)\n","    return embedding_matrix, unknown_words\n","\n","\n","def load_word_embed(word_embed_glove=\"../data/glove.840B.300d.txt\", \n","                    word_embed_crawl=\"../data/crawl-300d-2M.vec\",\n","               save_filename=\"./word_embedding_matrix\",\n","               word_index=None):\n","    \"\"\"\n","    (30524, 300) 7590\n","    (30524, 300) 7218\n","    \"\"\"    \n","    if os.path.exists(save_filename + \".npy\"):\n","        word_embedding_matrix = np.load(save_filename + \".npy\").astype(\"float32\")\n","    else:\n","        word_embedding_matrix, tx_unk = build_matrix(word_embed_glove, word_index=word_index, dim=300)\n","\n","        print(word_embedding_matrix.shape, len(tx_unk))\n","        \n","        word_embedding_matrix_v2, tx_unk = build_matrix(word_embed_crawl, word_index=word_index, dim=300)\n","\n","        print(word_embedding_matrix_v2.shape, len(tx_unk))\n","        \n","        word_embedding_matrix = np.concatenate([word_embedding_matrix, word_embedding_matrix_v2], axis=1)\n","        \n","        gc.collect()\n","        np.save(save_filename, word_embedding_matrix)\n","    return word_embedding_matrix\n","\n","\n","word_embedding_matrix = load_word_embed(word_index=word_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHoD4ogMAr47"},"outputs":[],"source":["def build_model(cfg, summary=False, word_embedding_matrix=None):\n","    \n","    def _get_model(base_dir, cfg_=None):\n","        config_file = os.path.join(base_dir, 'bert_config.json')\n","        checkpoint_file = os.path.join(base_dir, 'bert_model.ckpt')\n","        if not os.path.exists(config_file):\n","            config_file = os.path.join(base_dir, 'bert_config_large.json')\n","            checkpoint_file = os.path.join(base_dir, 'roberta_l24_large_model')\n","        print(config_file, checkpoint_file)\n","#         model = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True, seq_len=cfg_['maxlen'])\n","        model = load_trained_model_from_checkpoint(config_file, \n","                                           checkpoint_file, \n","                                           training=False, \n","                                           trainable=cfg_[\"bert_trainable\"], \n","                                           output_layer_num=cfg[\"cls_num\"],\n","                                           seq_len=cfg_['maxlen'])\n","        return model\n","    \n","    def get_opt(num_example, warmup_proportion=0.1, lr=2e-5, min_lr=None):\n","        if cfg[\"opt\"].lower() == \"nadam\":\n","            opt = Nadam(lr=lr)\n","        else:\n","            total_steps, warmup_steps = calc_train_steps(\n","                num_example=num_example,\n","                batch_size=B_SIZE,\n","                epochs=MAX_EPOCH,\n","                warmup_proportion=warmup_proportion,\n","            )\n","\n","            opt = AdamWarmup(total_steps, warmup_steps, lr=lr, min_lr=min_lr)\n","\n","        return opt\n","\n","    model1 = _get_model(cfg[\"base_dir\"], cfg)\n","    model1 = Model(inputs=model1.inputs[: 2], outputs=model1.layers[-7].output)\n","\n","    if word_embedding_matrix is not None:\n","        embed_layer = Embedding(input_dim=word_embedding_matrix.shape[0], \n","                                output_dim=word_embedding_matrix.shape[1],\n","                                weights=[word_embedding_matrix],\n","                                trainable=cfg[\"trainable\"],\n","                                name=\"embed_layer\"\n","                         )\n","        \n","    inp_token1 = Input(shape=(None, ), dtype=np.int32, name=\"query_token_input\")\n","    inp_segm1 = Input(shape=(None, ), dtype=np.float32, name=\"query_segm_input\")\n","    \n","#     inp_token2 = Input(shape=(None, ), dtype=np.int32)\n","#     inp_segm2 = Input(shape=(None, ), dtype=np.float32)    \n","    \n","    inp_image = Input(shape=(None, 2048), dtype=np.float32, name=\"image_input\")\n","    inp_image_mask = Input(shape=(None, ), dtype=np.float32, name=\"image_mask_input\")\n","    inp_pos = Input(shape=(None, 5), dtype=np.float32, name=\"image_pos_input\")        \n","    inp_image_char = Input(shape=(None, cfg[\"max_char\"]), dtype=np.int32, name='image_char_input')\n","    \n","    \n","    mask = Lambda(lambda x: K.cast(K.not_equal(x, cfg[\"x_pad\"]), 'float32'), name=\"token_mask\")(inp_token1)\n","    word_embed = embed_layer(inp_token1)\n","    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n","    word_embed = Bidirectional(LSTM(cfg[\"unit1_1\"], return_sequences=True), merge_mode=\"sum\")(word_embed)\n","    word_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([word_embed, mask])\n","\n","    sequence_output = model1([inp_token1, inp_segm1])\n","    sequence_output = Concatenate(axis=-1)([sequence_output, word_embed])\n","    text_pool = Lambda(lambda x: x[:, 0, :])(sequence_output)\n","\n","    # Share weights of character-level embedding for premise and hypothesis\n","    character_embedding_layer = TimeDistributed(Sequential([\n","        embed_layer,\n","        # Embedding(input_dim=100, output_dim=char_embedding_size, input_length=chars_per_word),\n","        Conv1D(filters=128, kernel_size=3, name=\"char_embed_conv1d\"),\n","        GlobalMaxPooling1D()\n","    ]), name='CharEmbedding')\n","    character_embedding_layer.build(input_shape=(None, None, cfg[\"max_char\"]))\n","    image_char_embed  = character_embedding_layer(inp_image_char)    \n","    image_embed = Concatenate(axis=-1)([image_char_embed, inp_image])    \n","    image_embed = Dense(512, activation='relu', name='image_embed')(image_embed)\n","    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n","    pos_embed = Dense(512, activation='relu', name='pos_embed')(inp_pos)\n","    pos_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([pos_embed, inp_image_mask])\n","    embed = Add()([image_embed , pos_embed]) # batch, maxlen(10), 1024+128\n","    \n","    image_embed = Bidirectional(LSTM(1152, return_sequences=True), merge_mode=\"sum\")(embed)\n","    image_embed = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([image_embed, inp_image_mask])\n","    \n","    image_pool = Lambda(lambda x: x[:, 0, :])(image_embed)\n","    \n","    pool = Concatenate(axis=-1)([image_pool, text_pool])\n","    pool = Dense(2048, activation=\"relu\")(pool)\n","    pool = Dense(512, activation=\"relu\")(pool)\n","    pool = Dense(128, activation=\"relu\")(pool)\n","    \n","    output = Dense(2, activation='softmax', name='output')(pool)\n","\n","    opt = get_opt(num_example=cfg[\"num_example\"], lr=cfg[\"lr\"], min_lr=cfg['min_lr'])\n","    model = Model(inputs=[inp_token1, inp_segm1, \n","                          inp_image, inp_image_mask,\n","                          inp_pos, inp_image_char], outputs=[output])#\n","    \n","    model.compile(optimizer=opt, loss={\n","                'output': 'sparse_categorical_crossentropy'\n","            }, metrics=['accuracy'])\n","    if summary:\n","        model.summary()\n","    \n","    return model\n","\n","# cfg[\"num_example\"] = 32\n","# model = build_model(cfg, summary=True, word_embedding_matrix=word_embedding_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWGkWTgbAr48"},"outputs":[],"source":["def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n","\n","    # This is a simple heuristic which will always truncate the longer sequence\n","    # one token at a time. This makes more sense than truncating an equal percent\n","    # of tokens from each, since if one sequence is very short then each token\n","    # that's truncated likely contains more information than a longer sequence.\n","\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b)\n","        if total_length <= max_length:\n","            break\n","        if len(tokens_a) > len(tokens_b):\n","            tokens_a.pop()\n","        else:\n","            print(len(tokens_a))\n","            tokens_b.pop()\n","\n","\n","def token2id_X(X, x_dict, maxlen=None):\n","    x = tokenizer.tokenize(X)\n","    if maxlen:\n","        x = x[: 1] + list(x)[1: maxlen - 1] + x[-1: ]     \n","    seg = [0 for _ in x]\n","    token = list(x)\n","    x = [x_dict[e] if e in x_dict else x_dict[\"[UNK]\"] for e in token]\n","    assert len(x) == len(seg)\n","    return x, seg\n","\n","\n","def seq_padding(X, maxlen=None, padding_value=None, debug=False):\n","    L = [len(x) for x in X]\n","    if maxlen is None:\n","        maxlen = max(L)\n","\n","    pad_X = np.array([\n","        np.concatenate([x, [padding_value] * (maxlen - len(x))]) if len(x) < maxlen else x[: maxlen] for x in X\n","    ])\n","    if debug:\n","        print(\"[!] before pading {}\\n\".format(X))\n","        print(\"[!] after pading {}\\n\".format(pad_X))\n","    return pad_X\n","    \n","\n","def MyChoice(Myset):\n","    result = []\n","    for i in Myset:\n","        temp_set = set()\n","        temp_set.add(i)\n","        cho = choice(list(Myset - temp_set))\n","        result.append(cho)\n","    return result\n","\n","\n","class data_generator:\n","    \n","    def __init__(self, data, batch_size=B_SIZE, shuffle=SHUFFLE):\n","        self.data = data\n","        self.batch_size = batch_size\n","        self.steps = len(self.data) // self.batch_size\n","        self.shuffle = shuffle\n","        if len(self.data) % self.batch_size != 0:\n","            self.steps += 1\n","\n","    def __len__(self):\n","        return self.steps\n","    \n","    def __iter__(self):\n","        \"\"\"\n","        inp_token1,\n","        inp_segm1,\n","        inp_image,\n","        inp_image_mask,\n","        inp_pos, \n","        inp_image_char\n","        \"\"\"\n","        while True:\n","            idxs = list(range(len(self.data)))\n","            if self.shuffle:\n","                np.random.shuffle(idxs)\n","            T1, T2, Image1, Pos1, label_word_list, image1_mask, image1_char = [], [], [], [], [], [], []\n","            S1, S2, Image2, Pos2, image2_mask, image2_char = [], [], [], [], [], [] # 负样本\n","            Id_set = set()\n","\n","            for i in idxs:\n","                d = self.data.iloc[i]\n","                text = d['words']\n","                label_words = d['label_words']\n","                \n","                t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n","                image = np.array(d['features'], dtype=\"float32\")\n","                image = image[: cfg[\"max_box\"]]\n","                img_mask = [1 for _ in image[: cfg[\"max_box\"]]]\n","                \n","                pos = np.array(d['pos'], dtype=\"float32\")\n","                pos = pos[: cfg[\"max_box\"]]\n","                \n","                image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n","                image_char = image_char[: cfg[\"max_box\"]]\n","                # print(\"image_char\", len(image_char))\n","                image_char = pad_sequences(image_char, \n","                                           maxlen=cfg[\"max_char\"], \n","                                           dtype='int32',\n","                                           padding='post',\n","                                           truncating='post',\n","                                           value=cfg[\"x_pad\"])\n","                \n","                assert image.shape[0] == pos.shape[0]\n","                assert image.shape[0] == cfg[\"max_box\"] or image.shape[0] == len(label_words.split(IMAGE_LABEM_CONCAT_TOKEN))\n","                assert image_char.shape == (image.shape[0], cfg[\"max_char\"])\n","\n","                T1.append(t1)\n","                T2.append(t2)\n","                Image1.append(image)\n","                image1_mask.append(img_mask)  \n","                Pos1.append(pos)\n","                image1_char.append(image_char)\n","                Id_set.add(i)\n","\n","                if len(T1) == self.batch_size//2 or i == idxs[-1]:\n","                    ## 加入负样本\n","                    Id_new = MyChoice(Id_set)\n","#                     print(Id_set, Id_new)\n","                    for i, id_ in enumerate(Id_new):\n","                        d_new = self.data.iloc[id_]\n","                        text = d_new['words']\n","                        t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n","                        S1.append(t1)\n","                        S2.append(t2)\n","                        \n","                        image = Image1[i]\n","                        img_mask = image1_mask[i]\n","                        pos = Pos1[i]\n","                        image_char = image1_char[i]\n","                        \n","                        Image2.append(image)\n","                        Pos2.append(pos)\n","                        image2_mask.append(img_mask)\n","                        image2_char.append(image_char)\n","                    \n","                    Y = [1] * len(T1) + [0] * len(S1)\n","                   \n","                    T1 = seq_padding(T1 + S1, padding_value=cfg[\"x_pad\"]) \n","                    T2 = seq_padding(T2 + S2, padding_value=cfg[\"x_pad\"])\n","                    \n","                    Image1 = seq_padding(Image1 + Image2, \n","                                         padding_value=np.zeros(shape=(2048, ))\n","                                        )\n","                                                         \n","                    Pos1 = seq_padding(Pos1 + Pos2,\n","                                       padding_value=np.zeros(shape=(5, ))\n","                                      )\n","                    image1_mask = seq_padding(image1_mask + image2_mask,\n","                                             padding_value=0)\n","                    \n","                    image1_char = seq_padding(image1_char + image2_char,\n","                                             padding_value=np.zeros(shape=(cfg[\"max_char\"])), debug=False)\n","                    \n","                    Y = np.array(Y).reshape((len(T1), -1))\n","                    \n","                    idx = np.arange(len(T1))\n","                    np.random.shuffle(idx)\n","        \n","                    T1 = T1[idx]\n","                    T2 = T2[idx]\n","                    Image1 = Image1[idx]\n","                    image1_mask = image1_mask[idx]\n","                    Pos1 = Pos1[idx]\n","                    image1_char = image1_char[idx]\n","                    Y = Y[idx]\n","                    \n","                    yield [T1, T2, Image1, image1_mask, Pos1, image1_char], Y\n","                    T1, T2, Image1, Pos1, label_word_list, image1_mask, image1_char = [], [], [], [], [], [], []\n","                    S1, S2, Image2, Pos2, image2_mask, image2_char = [], [], [], [], [], [] # 负样本\n","                    Id_set = set()\n","\n","                        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cSFjbRg6Ar5A"},"outputs":[],"source":["# train_D = data_generator(train_data)\n","# _i  = 0\n","# for d in train_D:\n","#     _i += 1\n","#     if  _i > 100:\n","#         break\n","#     # print('x',d[0][0].shape, d[0][1].shape,d[0][2].shape, d[0][3].shape, d[0][4].shape, d[0][5].shape, d[1].shape)\n","#     # print(d[0][5].sum(axis=-1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wK6_y8irAr5C"},"outputs":[],"source":["class Evaluate(Callback):\n","    def __init__(self, filename=None):\n","        self.score = []\n","        self.best = 0.\n","        self.filename = filename\n","       \n","    def on_epoch_begin(self, epoch, logs=None):\n","        if epoch ==  0:\n","            print(\"[!] test load&save model\")\n","            f = self.filename + \".h5\"\n","            custom_objects = get_custom_objects()\n","            self.model.save(f, include_optimizer=False, overwrite=True)\n","            if \"bert\" in cfg[\"verbose\"]:\n","                model_ = load_model(f, custom_objects=custom_objects)  \n","            else:\n","                model_ = load_model(f) \n","    \n","    def on_epoch_end(self, epoch, logs=None):\n","#         if epoch + 1 < 5:\n","#             return\n","        score = self.evaluate(self.model)\n","        self.score.append((epoch, score))\n","        \n","        if epoch + 1 in SAVE_EPOCHS:\n","            self.model.save(self.filename + \"_{}.h5\".format(epoch + 1), include_optimizer=False)             \n","        if score > self.best:\n","            self.model.save(self.filename + \".h5\", include_optimizer=False)\n","            \n","        if score > self.best:\n","            self.best = score\n","            print(\"[!] epoch = {}, new best score = {}\".format(epoch + 1,  score))\n","        print('[!] epoch = {}, score = {}, best score: {}\\n'.format(epoch + 1, score, self.best))\n","\n","    def evaluate(self, model):\n","        result = defaultdict(list)\n","        for i in trange(len(val_data)):\n","            d = val_data.iloc[i]\n","            qid = d['query_id']\n","            pid = d['product_id']\n","            text = d['query']\n","            label_words = d['label_words']\n","            t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n","            \n","            image = np.array(d['feature_convert'], dtype=\"float32\")\n","            image = image[: cfg[\"max_box\"]]\n","            img_mask = [1 for _ in image[: cfg[\"max_box\"]]]                   \n","            pos = np.array(d['pos'], dtype=\"float32\")\n","            pos = pos[: cfg[\"max_box\"]]\n","            \n","            image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n","            image_char = image_char[: cfg[\"max_box\"]]\n","            image_char = pad_sequences(image_char, \n","                                       maxlen=cfg[\"max_char\"], \n","                                       dtype='int32',\n","                                       padding='post',\n","                                       truncating='post',\n","                                       value=cfg[\"x_pad\"]) \n","            output = model.predict([[t1], [t2], [image], [img_mask], [pos], [image_char]])\n","            result[qid].append((pid, output[0][1]))\n","            \n","        query_id,product1,product2,product3,product4,product5 = [],[],[],[],[],[]\n","        for key in result.keys():\n","            rlist = result[key]\n","            rlist.sort(key=lambda x: x[1], reverse=True)\n","            query_id.append(key)\n","            product1.append(rlist[0][0])\n","            product2.append(rlist[1][0])\n","            product3.append(rlist[2][0])\n","            product4.append(rlist[3][0])\n","            product5.append(rlist[4][0])\n","        sub = pd.DataFrame({'query-id':query_id,\n","                            'product1':product1,\n","                            'product2':product2,\n","                            'product3':product3,\n","                            'product4':product4,\n","                            'product5':product5,\n","\n","        })\n","        sub.to_csv('../result/val_submission.csv',index=0)\n","        \n","        reference = json.load(open(VAL_ANS_PATH))\n","        \n","        # read predictions\n","        k = 5\n","        predictions = read_submission('../result/val_submission.csv', reference, k)\n","\n","        # compute score for each query\n","        score_sum = 0.\n","        for qid in reference.keys():\n","            ground_truth_ids = set([str(pid) for pid in reference[qid]])\n","            ref_vec = [1.0] * len(ground_truth_ids)\n","            pred_vec = [1.0 if pid in ground_truth_ids else 0.0 for pid in predictions[qid]]\n","            score_sum += get_ndcg(pred_vec, ref_vec, k)\n","        # the higher score, the better\n","        score = score_sum / len(reference)\n","        \n","        return score"]},{"cell_type":"markdown","metadata":{"id":"G0U5XAi6Ar5D"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10148921,"status":"ok","timestamp":1636219971941,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"-8khJgNZAr5F","outputId":"a957f6b0-64b7-4ed2-98e0-788e46c9bf66","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","[!] fold_id = -1 starting\n","{'verbose': '[image-bert-concat-query]-wwm_uncased_L12-768_v3_quart', 'base_dir': '/content/drive/MyDrive/Study/Passau/Applied AI/Experiment/ayman_path/data/uncased_L-12_H-768_A-12/', 'maxlen': 20, 'max_box': 10, 'max_char': 8, 'lr': 0.0001, 'min_lr': 6e-08, 'opt': 'nadam', 'loss_w': 20.0, 'trainable': True, 'bert_trainable': True, 'mix_mode': '', 'unit1_1': 128, 'accum_step': 1, 'cls_num': 4, 'raw_filename': '{}_{}oof{}', 'x_pad': 0, 'filename': '[image-bert-concat-query]-wwm_uncased_L12-768_v3_quart_20oof-1', 'num_example': 10000}\n","/content/drive/MyDrive/Study/Passau/Applied AI/Experiment/ayman_path/data/uncased_L-12_H-768_A-12/bert_config.json /content/drive/MyDrive/Study/Passau/Applied AI/Experiment/ayman_path/data/uncased_L-12_H-768_A-12/bert_model.ckpt\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","image_char_input (InputLayer)   (None, None, 8)      0                                            \n","__________________________________________________________________________________________________\n","CharEmbedding (TimeDistributed) (None, None, 128)    18544928    image_char_input[0][0]           \n","__________________________________________________________________________________________________\n","image_input (InputLayer)        (None, None, 2048)   0                                            \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, None, 2176)   0           CharEmbedding[0][0]              \n","                                                                 image_input[0][0]                \n","__________________________________________________________________________________________________\n","image_pos_input (InputLayer)    (None, None, 5)      0                                            \n","__________________________________________________________________________________________________\n","query_token_input (InputLayer)  (None, None)         0                                            \n","__________________________________________________________________________________________________\n","image_embed (Dense)             (None, None, 512)    1114624     concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","image_mask_input (InputLayer)   (None, None)         0                                            \n","__________________________________________________________________________________________________\n","pos_embed (Dense)               (None, None, 512)    3072        image_pos_input[0][0]            \n","__________________________________________________________________________________________________\n","embed_layer (Embedding)         (None, None, 600)    18314400    query_token_input[0][0]          \n","__________________________________________________________________________________________________\n","token_mask (Lambda)             (None, None)         0           query_token_input[0][0]          \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, None, 512)    0           image_embed[0][0]                \n","                                                                 image_mask_input[0][0]           \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, None, 512)    0           pos_embed[0][0]                  \n","                                                                 image_mask_input[0][0]           \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, None, 600)    0           embed_layer[0][0]                \n","                                                                 token_mask[0][0]                 \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, None, 512)    0           lambda_4[0][0]                   \n","                                                                 lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","query_segm_input (InputLayer)   (None, None)         0                                            \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, None, 128)    747520      lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","bidirectional_2 (Bidirectional) (None, None, 1152)   15353856    add_1[0][0]                      \n","__________________________________________________________________________________________________\n","model_3 (Model)                 multiple             103788288   query_token_input[0][0]          \n","                                                                 query_segm_input[0][0]           \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, None, 128)    0           bidirectional_1[0][0]            \n","                                                                 token_mask[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, None, 1152)   0           bidirectional_2[0][0]            \n","                                                                 image_mask_input[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, None, 896)    0           model_3[1][0]                    \n","                                                                 lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 1152)         0           lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 896)          0           concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 2048)         0           lambda_7[0][0]                   \n","                                                                 lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 2048)         4196352     concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 512)          1049088     dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 128)          65664       dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","output (Dense)                  (None, 2)            258         dense_3[0][0]                    \n","==================================================================================================\n","Total params: 144,863,650\n","Trainable params: 144,863,650\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","Epoch 1/20\n","[!] test load&save model\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n","  warnings.warn('No training configuration found in save file: '\n"]},{"name":"stdout","output_type":"stream","text":["79/79 [==============================] - 141s 2s/step - loss: 0.6714 - acc: 0.5926\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [07:01<00:00, 34.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 1, new best score = 0.23344427797321105\n","[!] epoch = 1, score = 0.23344427797321105, best score: 0.23344427797321105\n","\n","Epoch 2/20\n","79/79 [==============================] - 74s 933ms/step - loss: 0.5024 - acc: 0.7549\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:55<00:00, 35.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 2, new best score = 0.28126164589183095\n","[!] epoch = 2, score = 0.28126164589183095, best score: 0.28126164589183095\n","\n","Epoch 3/20\n","79/79 [==============================] - 73s 930ms/step - loss: 0.4418 - acc: 0.8016\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:52<00:00, 35.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 3, new best score = 0.322651953281555\n","[!] epoch = 3, score = 0.322651953281555, best score: 0.322651953281555\n","\n","Epoch 4/20\n","79/79 [==============================] - 73s 924ms/step - loss: 0.4211 - acc: 0.8112\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:51<00:00, 35.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 4, score = 0.29663134997703294, best score: 0.322651953281555\n","\n","Epoch 5/20\n","79/79 [==============================] - 73s 926ms/step - loss: 0.3825 - acc: 0.8333\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:52<00:00, 35.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 5, score = 0.30925439195012683, best score: 0.322651953281555\n","\n","Epoch 6/20\n","79/79 [==============================] - 73s 930ms/step - loss: 0.3881 - acc: 0.8286\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:54<00:00, 35.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 6, score = 0.29878714739136086, best score: 0.322651953281555\n","\n","Epoch 7/20\n","79/79 [==============================] - 74s 931ms/step - loss: 0.4488 - acc: 0.7977\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:53<00:00, 35.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 7, score = 0.21046336736795773, best score: 0.322651953281555\n","\n","Epoch 8/20\n","79/79 [==============================] - 73s 920ms/step - loss: 0.5162 - acc: 0.7435\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:55<00:00, 35.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 8, score = 0.2867049684304188, best score: 0.322651953281555\n","\n","Epoch 9/20\n","79/79 [==============================] - 73s 929ms/step - loss: 0.4440 - acc: 0.7931\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:58<00:00, 35.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 9, score = 0.30022683295498603, best score: 0.322651953281555\n","\n","Epoch 10/20\n","79/79 [==============================] - 72s 916ms/step - loss: 0.4188 - acc: 0.8100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:58<00:00, 35.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 10, score = 0.2930959717669475, best score: 0.322651953281555\n","\n","Epoch 11/20\n","79/79 [==============================] - 73s 927ms/step - loss: 0.3895 - acc: 0.8329\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:58<00:00, 35.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 11, new best score = 0.33391332180895283\n","[!] epoch = 11, score = 0.33391332180895283, best score: 0.33391332180895283\n","\n","Epoch 12/20\n","79/79 [==============================] - 73s 924ms/step - loss: 0.3745 - acc: 0.8404\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:56<00:00, 35.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 12, score = 0.3274415923778711, best score: 0.33391332180895283\n","\n","Epoch 13/20\n","79/79 [==============================] - 73s 924ms/step - loss: 0.3643 - acc: 0.8425\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:54<00:00, 35.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 13, score = 0.3125878456621289, best score: 0.33391332180895283\n","\n","Epoch 14/20\n","79/79 [==============================] - 74s 934ms/step - loss: 0.3441 - acc: 0.8528\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:59<00:00, 35.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 14, new best score = 0.33977999115081237\n","[!] epoch = 14, score = 0.33977999115081237, best score: 0.33977999115081237\n","\n","Epoch 15/20\n","79/79 [==============================] - 74s 931ms/step - loss: 0.3300 - acc: 0.8597\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:58<00:00, 35.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 15, new best score = 0.3436428914312111\n","[!] epoch = 15, score = 0.3436428914312111, best score: 0.3436428914312111\n","\n","Epoch 16/20\n","79/79 [==============================] - 73s 929ms/step - loss: 0.3432 - acc: 0.8579\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:58<00:00, 35.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 16, score = 0.3404840418772803, best score: 0.3436428914312111\n","\n","Epoch 17/20\n","79/79 [==============================] - 72s 915ms/step - loss: 0.3256 - acc: 0.8618\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [07:01<00:00, 34.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 17, new best score = 0.35075597311053835\n","[!] epoch = 17, score = 0.35075597311053835, best score: 0.35075597311053835\n","\n","Epoch 18/20\n","79/79 [==============================] - 75s 943ms/step - loss: 0.3211 - acc: 0.8705\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [07:04<00:00, 34.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 18, score = 0.336990166335901, best score: 0.35075597311053835\n","\n","Epoch 19/20\n","79/79 [==============================] - 74s 940ms/step - loss: 0.3044 - acc: 0.8771\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [07:04<00:00, 34.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 19, score = 0.33531540683827, best score: 0.35075597311053835\n","\n","Epoch 20/20\n","79/79 [==============================] - 74s 934ms/step - loss: 0.3120 - acc: 0.8701\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14720/14720 [06:58<00:00, 35.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[!] epoch = 20, score = 0.34270632859419414, best score: 0.35075597311053835\n","\n","\n","\n","[!] fold_id = -1 finish\n"]}],"source":["\n","gc.collect()\n","fold_id = -1\n","print(\"\\n\\n[!] fold_id = {} starting\".format(fold_id))\n","cfg[\"filename\"] = cfg[\"raw_filename\"].format(cfg[\"verbose\"], FOLD_NUM, fold_id)\n","cfg[\"num_example\"] = len(train_data)\n","\n","K.clear_session()\n","gc.collect()\n","seed(SEED - fold_id)\n","np.random.seed(SEED - fold_id)\n","tf.random.set_random_seed(SEED - fold_id)\n","train_D = data_generator(train_data)\n","print(cfg)\n","model = build_model(cfg, summary=True, \n","                    word_embedding_matrix=word_embedding_matrix,\n","                    )\n","keras.utils.plot_model(model, to_file=\"../models/model1.png\", show_shapes=True)\n","#     model.load_weights('[image-concat-query]-wwm_uncased_L24-1024_20oof0')\n","evaluator = Evaluate(filename=cfg[\"filename\"])\n","#     checkpoint= ModelCheckpoint(cfg[\"filename\"], monitor='acc', verbose=1, save_best_only=False, mode='max') \n"]},{"cell_type":"markdown","metadata":{"id":"0OvOGGA_tP8F"},"source":["### Model Fitting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U73CNxpCtVUY"},"outputs":[],"source":["model.fit_generator(train_D.__iter__(),\n","                          steps_per_epoch=len(train_D),\n","                          epochs=MAX_EPOCH,\n","                          callbacks=[evaluator],\n","                          shuffle=True\n","                          )\n","print(\"\\n\\n[!] fold_id = {} finish\".format(fold_id))\n","del model, evaluator"]},{"cell_type":"markdown","metadata":{"id":"fUo7uyS6Ar5G","scrolled":true},"source":["# Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73205,"status":"ok","timestamp":1636220046397,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"8yAEZS7dAr5G","outputId":"ff7ac5dd-b2e5-4095-ef2e-f206020b4592"},"outputs":[{"name":"stdout","output_type":"stream","text":["finish\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n","  warnings.warn('No training configuration found in save file: '\n"]}],"source":["with open('../data/test_data.pkl', 'rb') as outp:\n","    test_data = pickle.load(outp)\n","\n","f = cfg[\"filename\"] + \".h5\"\n","if \"bert\" in cfg[\"verbose\"]:\n","    custom_objects = get_custom_objects()\n","    model = load_model(f, custom_objects=custom_objects)  \n","else:\n","    model = load_model(f)\n","print(\"finish\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ct2eCmYhAr5H"},"outputs":[],"source":["gc.collect()\n","result = defaultdict(list)\n","for i in trange(len(test_data)):\n","    d = test_data.iloc[i]\n","    qid = d['query_id']\n","    pid = d['product_id']\n","    text = d['query']\n","    label_words = d['label_words']\n","    t1, t2 = token2id_X(text, x_dict=word_index, maxlen=cfg[\"maxlen\"])\n","\n","    image = np.array(d['feature_convert'], dtype=\"float32\")\n","    image = image[: cfg[\"max_box\"]]\n","    img_mask = [1 for _ in image[: cfg[\"max_box\"]]]                   \n","    pos = np.array(d['pos'], dtype=\"float32\")\n","    pos = pos[: cfg[\"max_box\"]]\n","\n","    image_char = [token2id_X(ent, x_dict=word_index)[0] for ent in label_words.split(IMAGE_LABEM_CONCAT_TOKEN)]\n","    image_char = image_char[: cfg[\"max_box\"]]\n","    image_char = pad_sequences(image_char, \n","                               maxlen=cfg[\"max_char\"], \n","                               dtype='int32',\n","                               padding='post',\n","                               truncating='post',\n","                               value=cfg[\"x_pad\"]) \n","    output = model.predict([[t1], [t2], [image], [img_mask], [pos], [image_char]])\n","    result[qid].append((pid, output[0][1]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOWqYUaXAr5H"},"outputs":[],"source":["query_id,product1,product2,product3,product4,product5 = [],[],[],[],[],[]\n","for key in result.keys():\n","    rlist = result[key]\n","    rlist.sort(key=lambda x: x[1], reverse=True)\n","    query_id.append(key)\n","    product1.append(rlist[0][0])\n","    product2.append(rlist[1][0])\n","    product3.append(rlist[2][0])\n","    product4.append(rlist[3][0])\n","    product5.append(rlist[4][0])\n","\n","sub = pd.DataFrame({'query-id':query_id,\n","                    'product1':product1,\n","                    'product2':product2,\n","                    'product3':product3,\n","                    'product4':product4,\n","                    'product5':product5,\n","\n","})\n","\n","sub.to_csv('../result/submission.csv',index=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hjq_AYpAAr5I"},"outputs":[],"source":["sub.head(5)"]},{"cell_type":"markdown","metadata":{"id":"ecQVcr2zXytP"},"source":["## Eval"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":630,"status":"ok","timestamp":1636222703249,"user":{"displayName":"Yasser Otiefy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH8nT7s1o73eNNJPavJleQKJePFH0HS80Pv_-tmQ=s64","userId":"11606645386995589698"},"user_tz":-60},"id":"RR5AV6DQXyGN","outputId":"938ec73d-ba80-493f-f6c5-2b6f41fb6faf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Read standard from ../data/testA_answer.json\n","Read user submit file from ../result/submission.csv\n","The evaluation finished successfully.\n"]}],"source":["!python eval.py ../data/testA_answer.json ../result/submission.csv ../result/test_result.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nfArcyPlAr5J"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"[image-concat-query]-wwm_uncased_L12-768_v3_quart.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}
